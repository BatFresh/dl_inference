/**
 * Copyright (c) 2020-present, Wuba, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

package com.bj58.ailab.dlpredictonline.grpc.tis;

/**
 * @author 58
 */
public final class ModelConfigOuterClass {
  private ModelConfigOuterClass() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:enum:: DataType
   *&#64;&#64;
   *&#64;&#64;   Data types supported for input and output tensors.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf enum {@code inference.DataType}
   */
  public enum DataType
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INVALID = 0
     * </pre>
     *
     * <code>TYPE_INVALID = 0;</code>
     */
    TYPE_INVALID(0),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::BOOL = 1
     * </pre>
     *
     * <code>TYPE_BOOL = 1;</code>
     */
    TYPE_BOOL(1),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT8 = 2
     * </pre>
     *
     * <code>TYPE_UINT8 = 2;</code>
     */
    TYPE_UINT8(2),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT16 = 3
     * </pre>
     *
     * <code>TYPE_UINT16 = 3;</code>
     */
    TYPE_UINT16(3),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT32 = 4
     * </pre>
     *
     * <code>TYPE_UINT32 = 4;</code>
     */
    TYPE_UINT32(4),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT64 = 5
     * </pre>
     *
     * <code>TYPE_UINT64 = 5;</code>
     */
    TYPE_UINT64(5),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT8 = 6
     * </pre>
     *
     * <code>TYPE_INT8 = 6;</code>
     */
    TYPE_INT8(6),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT16 = 7
     * </pre>
     *
     * <code>TYPE_INT16 = 7;</code>
     */
    TYPE_INT16(7),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT32 = 8
     * </pre>
     *
     * <code>TYPE_INT32 = 8;</code>
     */
    TYPE_INT32(8),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT64 = 9
     * </pre>
     *
     * <code>TYPE_INT64 = 9;</code>
     */
    TYPE_INT64(9),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP16 = 10
     * </pre>
     *
     * <code>TYPE_FP16 = 10;</code>
     */
    TYPE_FP16(10),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP32 = 11
     * </pre>
     *
     * <code>TYPE_FP32 = 11;</code>
     */
    TYPE_FP32(11),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP64 = 12
     * </pre>
     *
     * <code>TYPE_FP64 = 12;</code>
     */
    TYPE_FP64(12),
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::STRING = 13
     * </pre>
     *
     * <code>TYPE_STRING = 13;</code>
     */
    TYPE_STRING(13),
    UNRECOGNIZED(-1),
    ;

    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INVALID = 0
     * </pre>
     *
     * <code>TYPE_INVALID = 0;</code>
     */
    public static final int TYPE_INVALID_VALUE = 0;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::BOOL = 1
     * </pre>
     *
     * <code>TYPE_BOOL = 1;</code>
     */
    public static final int TYPE_BOOL_VALUE = 1;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT8 = 2
     * </pre>
     *
     * <code>TYPE_UINT8 = 2;</code>
     */
    public static final int TYPE_UINT8_VALUE = 2;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT16 = 3
     * </pre>
     *
     * <code>TYPE_UINT16 = 3;</code>
     */
    public static final int TYPE_UINT16_VALUE = 3;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT32 = 4
     * </pre>
     *
     * <code>TYPE_UINT32 = 4;</code>
     */
    public static final int TYPE_UINT32_VALUE = 4;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::UINT64 = 5
     * </pre>
     *
     * <code>TYPE_UINT64 = 5;</code>
     */
    public static final int TYPE_UINT64_VALUE = 5;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT8 = 6
     * </pre>
     *
     * <code>TYPE_INT8 = 6;</code>
     */
    public static final int TYPE_INT8_VALUE = 6;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT16 = 7
     * </pre>
     *
     * <code>TYPE_INT16 = 7;</code>
     */
    public static final int TYPE_INT16_VALUE = 7;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT32 = 8
     * </pre>
     *
     * <code>TYPE_INT32 = 8;</code>
     */
    public static final int TYPE_INT32_VALUE = 8;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::INT64 = 9
     * </pre>
     *
     * <code>TYPE_INT64 = 9;</code>
     */
    public static final int TYPE_INT64_VALUE = 9;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP16 = 10
     * </pre>
     *
     * <code>TYPE_FP16 = 10;</code>
     */
    public static final int TYPE_FP16_VALUE = 10;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP32 = 11
     * </pre>
     *
     * <code>TYPE_FP32 = 11;</code>
     */
    public static final int TYPE_FP32_VALUE = 11;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::FP64 = 12
     * </pre>
     *
     * <code>TYPE_FP64 = 12;</code>
     */
    public static final int TYPE_FP64_VALUE = 12;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:enumerator:: DataType::STRING = 13
     * </pre>
     *
     * <code>TYPE_STRING = 13;</code>
     */
    public static final int TYPE_STRING_VALUE = 13;


    public final int getNumber() {
      if (this == UNRECOGNIZED) {
        throw new IllegalArgumentException(
            "Can't get the number of an unknown enum value.");
      }
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @Deprecated
    public static DataType valueOf(int value) {
      return forNumber(value);
    }

    public static DataType forNumber(int value) {
      switch (value) {
        case 0: return TYPE_INVALID;
        case 1: return TYPE_BOOL;
        case 2: return TYPE_UINT8;
        case 3: return TYPE_UINT16;
        case 4: return TYPE_UINT32;
        case 5: return TYPE_UINT64;
        case 6: return TYPE_INT8;
        case 7: return TYPE_INT16;
        case 8: return TYPE_INT32;
        case 9: return TYPE_INT64;
        case 10: return TYPE_FP16;
        case 11: return TYPE_FP32;
        case 12: return TYPE_FP64;
        case 13: return TYPE_STRING;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<DataType>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        DataType> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<DataType>() {
            public DataType findValueByNumber(int number) {
              return DataType.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return ModelConfigOuterClass.getDescriptor().getEnumTypes().get(0);
    }

    private static final DataType[] VALUES = values();

    public static DataType valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      if (desc.getIndex() == -1) {
        return UNRECOGNIZED;
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private DataType(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:inference.DataType)
  }

  public interface ModelInstanceGroupOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelInstanceGroup)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    String getName();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    int getKindValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    ModelConfigOuterClass.ModelInstanceGroup.Kind getKind();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 count
     *&#64;&#64;
     *&#64;&#64;     For a group assigned to GPU, the number of instances created for
     *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *&#64;&#64;     of instances created. Default is 1.
     * </pre>
     *
     * <code>optional int32 count = 2;</code>
     */
    int getCount();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    java.util.List<Integer> getGpusList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    int getGpusCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    int getGpus(int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    java.util.List<String>
        getProfileList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    int getProfileCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    String getProfile(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    com.google.protobuf.ByteString
        getProfileBytes(int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelInstanceGroup
   *&#64;&#64;
   *&#64;&#64;   A group of one or more instances of a model and resources made
   *&#64;&#64;   available for those instances.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelInstanceGroup}
   */
  public  static final class ModelInstanceGroup extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelInstanceGroup)
      ModelInstanceGroupOrBuilder {
    // Use ModelInstanceGroup.newBuilder() to construct.
    private ModelInstanceGroup(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelInstanceGroup() {
      name_ = "";
      kind_ = 0;
      count_ = 0;
      gpus_ = java.util.Collections.emptyList();
      profile_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelInstanceGroup(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 16: {

              count_ = input.readInt32();
              break;
            }
            case 24: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                gpus_ = new java.util.ArrayList<Integer>();
                mutable_bitField0_ |= 0x00000008;
              }
              gpus_.add(input.readInt32());
              break;
            }
            case 26: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008) && input.getBytesUntilLimit() > 0) {
                gpus_ = new java.util.ArrayList<Integer>();
                mutable_bitField0_ |= 0x00000008;
              }
              while (input.getBytesUntilLimit() > 0) {
                gpus_.add(input.readInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 32: {
              int rawValue = input.readEnum();

              kind_ = rawValue;
              break;
            }
            case 42: {
              String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                profile_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000010;
              }
              profile_.add(s);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          gpus_ = java.util.Collections.unmodifiableList(gpus_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          profile_ = profile_.getUnmodifiableView();
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelInstanceGroup_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelInstanceGroup_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelInstanceGroup.class, ModelConfigOuterClass.ModelInstanceGroup.Builder.class);
    }

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:enum:: Kind
     *&#64;&#64;
     *&#64;&#64;     Kind of this instance group.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf enum {@code inference.ModelInstanceGroup.Kind}
     */
    public enum Kind
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_AUTO = 0
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that can run on either
       *&#64;&#64;       CPU or GPU. If all GPUs listed in 'gpus' are available then
       *&#64;&#64;       instances will be created on GPU(s), otherwise instances will
       *&#64;&#64;       be created on CPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_AUTO = 0;</code>
       */
      KIND_AUTO(0),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_GPU = 1
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that must run on the
       *&#64;&#64;       GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_GPU = 1;</code>
       */
      KIND_GPU(1),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_CPU = 2
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that must run on the
       *&#64;&#64;       CPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_CPU = 2;</code>
       */
      KIND_CPU(2),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_MODEL = 3
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that should run on the
       *&#64;&#64;       CPU and/or GPU(s) as specified by the model or backend itself.
       *&#64;&#64;       The inference server will not override the model/backend
       *&#64;&#64;       settings.
       *&#64;&#64;       Currently, this option is supported only for Tensorflow models.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_MODEL = 3;</code>
       */
      KIND_MODEL(3),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_AUTO = 0
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that can run on either
       *&#64;&#64;       CPU or GPU. If all GPUs listed in 'gpus' are available then
       *&#64;&#64;       instances will be created on GPU(s), otherwise instances will
       *&#64;&#64;       be created on CPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_AUTO = 0;</code>
       */
      public static final int KIND_AUTO_VALUE = 0;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_GPU = 1
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that must run on the
       *&#64;&#64;       GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_GPU = 1;</code>
       */
      public static final int KIND_GPU_VALUE = 1;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_CPU = 2
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that must run on the
       *&#64;&#64;       CPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_CPU = 2;</code>
       */
      public static final int KIND_CPU_VALUE = 2;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Kind::KIND_MODEL = 3
       *&#64;&#64;
       *&#64;&#64;       This instance group represents instances that should run on the
       *&#64;&#64;       CPU and/or GPU(s) as specified by the model or backend itself.
       *&#64;&#64;       The inference server will not override the model/backend
       *&#64;&#64;       settings.
       *&#64;&#64;       Currently, this option is supported only for Tensorflow models.
       *&#64;&#64;
       * </pre>
       *
       * <code>KIND_MODEL = 3;</code>
       */
      public static final int KIND_MODEL_VALUE = 3;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static Kind valueOf(int value) {
        return forNumber(value);
      }

      public static Kind forNumber(int value) {
        switch (value) {
          case 0: return KIND_AUTO;
          case 1: return KIND_GPU;
          case 2: return KIND_CPU;
          case 3: return KIND_MODEL;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Kind>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Kind> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Kind>() {
              public Kind findValueByNumber(int number) {
                return Kind.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return ModelConfigOuterClass.ModelInstanceGroup.getDescriptor().getEnumTypes().get(0);
      }

      private static final Kind[] VALUES = values();

      public static Kind valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Kind(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:inference.ModelInstanceGroup.Kind)
    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    private volatile Object name_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     Optional name of this group of instances. If not specified the
     *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
     *&#64;&#64;     individual instances will be further formed by a unique instance
     *&#64;&#64;     number and GPU index:
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int KIND_FIELD_NUMBER = 4;
    private int kind_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    public int getKindValue() {
      return kind_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Kind kind
     *&#64;&#64;
     *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
     *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
     *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
     *&#64;&#64;     and 'gpu' cannot be specified.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
     */
    public ModelConfigOuterClass.ModelInstanceGroup.Kind getKind() {
      ModelConfigOuterClass.ModelInstanceGroup.Kind result = ModelConfigOuterClass.ModelInstanceGroup.Kind.valueOf(kind_);
      return result == null ? ModelConfigOuterClass.ModelInstanceGroup.Kind.UNRECOGNIZED : result;
    }

    public static final int COUNT_FIELD_NUMBER = 2;
    private int count_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 count
     *&#64;&#64;
     *&#64;&#64;     For a group assigned to GPU, the number of instances created for
     *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
     *&#64;&#64;     of instances created. Default is 1.
     * </pre>
     *
     * <code>optional int32 count = 2;</code>
     */
    public int getCount() {
      return count_;
    }

    public static final int GPUS_FIELD_NUMBER = 3;
    private java.util.List<Integer> gpus_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    public java.util.List<Integer>
        getGpusList() {
      return gpus_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    public int getGpusCount() {
      return gpus_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
     *&#64;&#64;
     *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
     *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
     *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
     *&#64;&#64;     available GPUs.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 gpus = 3;</code>
     */
    public int getGpus(int index) {
      return gpus_.get(index);
    }
    private int gpusMemoizedSerializedSize = -1;

    public static final int PROFILE_FIELD_NUMBER = 5;
    private com.google.protobuf.LazyStringList profile_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getProfileList() {
      return profile_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    public int getProfileCount() {
      return profile_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    public String getProfile(int index) {
      return profile_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string profile (repeated)
     *&#64;&#64;
     *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
     *&#64;&#64;     parameter specifies a set of optimization profiles available to this
     *&#64;&#64;     instance group. The inference server will choose the optimal profile
     *&#64;&#64;     based on the shapes of the input tensors. This field should lie
     *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
     *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
     *&#64;&#64;     be generated.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string profile = 5;</code>
     */
    public com.google.protobuf.ByteString
        getProfileBytes(int index) {
      return profile_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (count_ != 0) {
        output.writeInt32(2, count_);
      }
      if (getGpusList().size() > 0) {
        output.writeUInt32NoTag(26);
        output.writeUInt32NoTag(gpusMemoizedSerializedSize);
      }
      for (int i = 0; i < gpus_.size(); i++) {
        output.writeInt32NoTag(gpus_.get(i));
      }
      if (kind_ != ModelConfigOuterClass.ModelInstanceGroup.Kind.KIND_AUTO.getNumber()) {
        output.writeEnum(4, kind_);
      }
      for (int i = 0; i < profile_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, profile_.getRaw(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (count_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, count_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < gpus_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt32SizeNoTag(gpus_.get(i));
        }
        size += dataSize;
        if (!getGpusList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        gpusMemoizedSerializedSize = dataSize;
      }
      if (kind_ != ModelConfigOuterClass.ModelInstanceGroup.Kind.KIND_AUTO.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, kind_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < profile_.size(); i++) {
          dataSize += computeStringSizeNoTag(profile_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getProfileList().size();
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelInstanceGroup)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelInstanceGroup other = (ModelConfigOuterClass.ModelInstanceGroup) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && kind_ == other.kind_;
      result = result && (getCount()
          == other.getCount());
      result = result && getGpusList()
          .equals(other.getGpusList());
      result = result && getProfileList()
          .equals(other.getProfileList());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + KIND_FIELD_NUMBER;
      hash = (53 * hash) + kind_;
      hash = (37 * hash) + COUNT_FIELD_NUMBER;
      hash = (53 * hash) + getCount();
      if (getGpusCount() > 0) {
        hash = (37 * hash) + GPUS_FIELD_NUMBER;
        hash = (53 * hash) + getGpusList().hashCode();
      }
      if (getProfileCount() > 0) {
        hash = (37 * hash) + PROFILE_FIELD_NUMBER;
        hash = (53 * hash) + getProfileList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInstanceGroup parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelInstanceGroup prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelInstanceGroup
     *&#64;&#64;
     *&#64;&#64;   A group of one or more instances of a model and resources made
     *&#64;&#64;   available for those instances.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelInstanceGroup}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelInstanceGroup)
        ModelConfigOuterClass.ModelInstanceGroupOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelInstanceGroup_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelInstanceGroup_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelInstanceGroup.class, ModelConfigOuterClass.ModelInstanceGroup.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelInstanceGroup.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        name_ = "";

        kind_ = 0;

        count_ = 0;

        gpus_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        profile_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelInstanceGroup_descriptor;
      }

      public ModelConfigOuterClass.ModelInstanceGroup getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelInstanceGroup.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelInstanceGroup build() {
        ModelConfigOuterClass.ModelInstanceGroup result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelInstanceGroup buildPartial() {
        ModelConfigOuterClass.ModelInstanceGroup result = new ModelConfigOuterClass.ModelInstanceGroup(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.name_ = name_;
        result.kind_ = kind_;
        result.count_ = count_;
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          gpus_ = java.util.Collections.unmodifiableList(gpus_);
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.gpus_ = gpus_;
        if (((bitField0_ & 0x00000010) == 0x00000010)) {
          profile_ = profile_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000010);
        }
        result.profile_ = profile_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelInstanceGroup) {
          return mergeFrom((ModelConfigOuterClass.ModelInstanceGroup)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelInstanceGroup other) {
        if (other == ModelConfigOuterClass.ModelInstanceGroup.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.kind_ != 0) {
          setKindValue(other.getKindValue());
        }
        if (other.getCount() != 0) {
          setCount(other.getCount());
        }
        if (!other.gpus_.isEmpty()) {
          if (gpus_.isEmpty()) {
            gpus_ = other.gpus_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureGpusIsMutable();
            gpus_.addAll(other.gpus_);
          }
          onChanged();
        }
        if (!other.profile_.isEmpty()) {
          if (profile_.isEmpty()) {
            profile_ = other.profile_;
            bitField0_ = (bitField0_ & ~0x00000010);
          } else {
            ensureProfileIsMutable();
            profile_.addAll(other.profile_);
          }
          onChanged();
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelInstanceGroup parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelInstanceGroup) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     Optional name of this group of instances. If not specified the
       *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
       *&#64;&#64;     individual instances will be further formed by a unique instance
       *&#64;&#64;     number and GPU index:
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     Optional name of this group of instances. If not specified the
       *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
       *&#64;&#64;     individual instances will be further formed by a unique instance
       *&#64;&#64;     number and GPU index:
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     Optional name of this group of instances. If not specified the
       *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
       *&#64;&#64;     individual instances will be further formed by a unique instance
       *&#64;&#64;     number and GPU index:
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     Optional name of this group of instances. If not specified the
       *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
       *&#64;&#64;     individual instances will be further formed by a unique instance
       *&#64;&#64;     number and GPU index:
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {

        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     Optional name of this group of instances. If not specified the
       *&#64;&#64;     name will be formed as &lt;model name&gt;_&lt;group number&gt;. The name of
       *&#64;&#64;     individual instances will be further formed by a unique instance
       *&#64;&#64;     number and GPU index:
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        name_ = value;
        onChanged();
        return this;
      }

      private int kind_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
       *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
       *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
       *&#64;&#64;     and 'gpu' cannot be specified.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
       */
      public int getKindValue() {
        return kind_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
       *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
       *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
       *&#64;&#64;     and 'gpu' cannot be specified.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
       */
      public Builder setKindValue(int value) {
        kind_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
       *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
       *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
       *&#64;&#64;     and 'gpu' cannot be specified.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroup.Kind getKind() {
        ModelConfigOuterClass.ModelInstanceGroup.Kind result = ModelConfigOuterClass.ModelInstanceGroup.Kind.valueOf(kind_);
        return result == null ? ModelConfigOuterClass.ModelInstanceGroup.Kind.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
       *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
       *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
       *&#64;&#64;     and 'gpu' cannot be specified.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
       */
      public Builder setKind(ModelConfigOuterClass.ModelInstanceGroup.Kind value) {
        if (value == null) {
          throw new NullPointerException();
        }

        kind_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;     The kind of this instance group. Default is KIND_AUTO. If
       *&#64;&#64;     KIND_AUTO or KIND_GPU then both 'count' and 'gpu' are valid and
       *&#64;&#64;     may be specified. If KIND_CPU or KIND_MODEL only 'count' is valid
       *&#64;&#64;     and 'gpu' cannot be specified.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInstanceGroup.Kind kind = 4;</code>
       */
      public Builder clearKind() {

        kind_ = 0;
        onChanged();
        return this;
      }

      private int count_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 count
       *&#64;&#64;
       *&#64;&#64;     For a group assigned to GPU, the number of instances created for
       *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
       *&#64;&#64;     of instances created. Default is 1.
       * </pre>
       *
       * <code>optional int32 count = 2;</code>
       */
      public int getCount() {
        return count_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 count
       *&#64;&#64;
       *&#64;&#64;     For a group assigned to GPU, the number of instances created for
       *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
       *&#64;&#64;     of instances created. Default is 1.
       * </pre>
       *
       * <code>optional int32 count = 2;</code>
       */
      public Builder setCount(int value) {

        count_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 count
       *&#64;&#64;
       *&#64;&#64;     For a group assigned to GPU, the number of instances created for
       *&#64;&#64;     each GPU listed in 'gpus'. For a group assigned to CPU the number
       *&#64;&#64;     of instances created. Default is 1.
       * </pre>
       *
       * <code>optional int32 count = 2;</code>
       */
      public Builder clearCount() {

        count_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<Integer> gpus_ = java.util.Collections.emptyList();
      private void ensureGpusIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          gpus_ = new java.util.ArrayList<Integer>(gpus_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public java.util.List<Integer>
          getGpusList() {
        return java.util.Collections.unmodifiableList(gpus_);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public int getGpusCount() {
        return gpus_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public int getGpus(int index) {
        return gpus_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public Builder setGpus(
          int index, int value) {
        ensureGpusIsMutable();
        gpus_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public Builder addGpus(int value) {
        ensureGpusIsMutable();
        gpus_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public Builder addAllGpus(
          Iterable<? extends Integer> values) {
        ensureGpusIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, gpus_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 gpus (repeated)
       *&#64;&#64;
       *&#64;&#64;     GPU(s) where instances should be available. For each GPU listed,
       *&#64;&#64;     'count' instances of the model will be available. Setting 'gpus'
       *&#64;&#64;     to empty (or not specifying at all) is eqivalent to listing all
       *&#64;&#64;     available GPUs.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 gpus = 3;</code>
       */
      public Builder clearGpus() {
        gpus_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList profile_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureProfileIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          profile_ = new com.google.protobuf.LazyStringArrayList(profile_);
          bitField0_ |= 0x00000010;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getProfileList() {
        return profile_.getUnmodifiableView();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public int getProfileCount() {
        return profile_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public String getProfile(int index) {
        return profile_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public com.google.protobuf.ByteString
          getProfileBytes(int index) {
        return profile_.getByteString(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public Builder setProfile(
          int index, String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureProfileIsMutable();
        profile_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public Builder addProfile(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureProfileIsMutable();
        profile_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public Builder addAllProfile(
          Iterable<String> values) {
        ensureProfileIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, profile_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public Builder clearProfile() {
        profile_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string profile (repeated)
       *&#64;&#64;
       *&#64;&#64;     For TensorRT models, using inputs with dynamic shape, this
       *&#64;&#64;     parameter specifies a set of optimization profiles available to this
       *&#64;&#64;     instance group. The inference server will choose the optimal profile
       *&#64;&#64;     based on the shapes of the input tensors. This field should lie
       *&#64;&#64;     between 0 and &lt;TotalNumberOfOptimizationProfilesInPlanModel&gt; - 1
       *&#64;&#64;     and be specified only for TensorRT backend, otherwise an error will
       *&#64;&#64;     be generated.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string profile = 5;</code>
       */
      public Builder addProfileBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureProfileIsMutable();
        profile_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelInstanceGroup)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelInstanceGroup)
    private static final ModelConfigOuterClass.ModelInstanceGroup DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelInstanceGroup();
    }

    public static ModelConfigOuterClass.ModelInstanceGroup getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelInstanceGroup>
        PARSER = new com.google.protobuf.AbstractParser<ModelInstanceGroup>() {
      public ModelInstanceGroup parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelInstanceGroup(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelInstanceGroup> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelInstanceGroup> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelInstanceGroup getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelTensorReshapeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelTensorReshape)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    java.util.List<Long> getShapeList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    int getShapeCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    long getShape(int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelTensorReshape
   *&#64;&#64;
   *&#64;&#64;   Reshape specification for input and output tensors.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelTensorReshape}
   */
  public  static final class ModelTensorReshape extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelTensorReshape)
      ModelTensorReshapeOrBuilder {
    // Use ModelTensorReshape.newBuilder() to construct.
    private ModelTensorReshape(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelTensorReshape() {
      shape_ = java.util.Collections.emptyList();
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelTensorReshape(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                shape_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000001;
              }
              shape_.add(input.readInt64());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001) && input.getBytesUntilLimit() > 0) {
                shape_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000001;
              }
              while (input.getBytesUntilLimit() > 0) {
                shape_.add(input.readInt64());
              }
              input.popLimit(limit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          shape_ = java.util.Collections.unmodifiableList(shape_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelTensorReshape_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelTensorReshape_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelTensorReshape.class, ModelConfigOuterClass.ModelTensorReshape.Builder.class);
    }

    public static final int SHAPE_FIELD_NUMBER = 1;
    private java.util.List<Long> shape_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    public java.util.List<Long>
        getShapeList() {
      return shape_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    public int getShapeCount() {
      return shape_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
     *&#64;&#64;
     *&#64;&#64;     The shape to use for reshaping.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 shape = 1;</code>
     */
    public long getShape(int index) {
      return shape_.get(index);
    }
    private int shapeMemoizedSerializedSize = -1;

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (getShapeList().size() > 0) {
        output.writeUInt32NoTag(10);
        output.writeUInt32NoTag(shapeMemoizedSerializedSize);
      }
      for (int i = 0; i < shape_.size(); i++) {
        output.writeInt64NoTag(shape_.get(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < shape_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt64SizeNoTag(shape_.get(i));
        }
        size += dataSize;
        if (!getShapeList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        shapeMemoizedSerializedSize = dataSize;
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelTensorReshape)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelTensorReshape other = (ModelConfigOuterClass.ModelTensorReshape) obj;

      boolean result = true;
      result = result && getShapeList()
          .equals(other.getShapeList());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getShapeCount() > 0) {
        hash = (37 * hash) + SHAPE_FIELD_NUMBER;
        hash = (53 * hash) + getShapeList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTensorReshape parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelTensorReshape prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelTensorReshape
     *&#64;&#64;
     *&#64;&#64;   Reshape specification for input and output tensors.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelTensorReshape}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelTensorReshape)
        ModelConfigOuterClass.ModelTensorReshapeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelTensorReshape_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelTensorReshape_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelTensorReshape.class, ModelConfigOuterClass.ModelTensorReshape.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelTensorReshape.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        shape_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelTensorReshape_descriptor;
      }

      public ModelConfigOuterClass.ModelTensorReshape getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelTensorReshape build() {
        ModelConfigOuterClass.ModelTensorReshape result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelTensorReshape buildPartial() {
        ModelConfigOuterClass.ModelTensorReshape result = new ModelConfigOuterClass.ModelTensorReshape(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          shape_ = java.util.Collections.unmodifiableList(shape_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.shape_ = shape_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelTensorReshape) {
          return mergeFrom((ModelConfigOuterClass.ModelTensorReshape)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelTensorReshape other) {
        if (other == ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance()) return this;
        if (!other.shape_.isEmpty()) {
          if (shape_.isEmpty()) {
            shape_ = other.shape_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureShapeIsMutable();
            shape_.addAll(other.shape_);
          }
          onChanged();
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelTensorReshape parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelTensorReshape) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<Long> shape_ = java.util.Collections.emptyList();
      private void ensureShapeIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          shape_ = new java.util.ArrayList<Long>(shape_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public java.util.List<Long>
          getShapeList() {
        return java.util.Collections.unmodifiableList(shape_);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public int getShapeCount() {
        return shape_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public long getShape(int index) {
        return shape_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public Builder setShape(
          int index, long value) {
        ensureShapeIsMutable();
        shape_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public Builder addShape(long value) {
        ensureShapeIsMutable();
        shape_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public Builder addAllShape(
          Iterable<? extends Long> values) {
        ensureShapeIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, shape_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 shape (repeated)
       *&#64;&#64;
       *&#64;&#64;     The shape to use for reshaping.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 shape = 1;</code>
       */
      public Builder clearShape() {
        shape_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelTensorReshape)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelTensorReshape)
    private static final ModelConfigOuterClass.ModelTensorReshape DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelTensorReshape();
    }

    public static ModelConfigOuterClass.ModelTensorReshape getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelTensorReshape>
        PARSER = new com.google.protobuf.AbstractParser<ModelTensorReshape>() {
      public ModelTensorReshape parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelTensorReshape(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelTensorReshape> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelTensorReshape> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelTensorReshape getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelInputOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelInput)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    String getName();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    int getDataTypeValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    ModelConfigOuterClass.DataType getDataType();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Format format
     *&#64;&#64;
     *&#64;&#64;     The format of the input. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInput.Format format = 3;</code>
     */
    int getFormatValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Format format
     *&#64;&#64;
     *&#64;&#64;     The format of the input. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInput.Format format = 3;</code>
     */
    ModelConfigOuterClass.ModelInput.Format getFormat();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    java.util.List<Long> getDimsList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    int getDimsCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    long getDims(int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    boolean hasReshape();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    ModelConfigOuterClass.ModelTensorReshape getReshape();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
     *&#64;&#64;
     *&#64;&#64;     Whether or not the input is a shape tensor to the model. This field
     *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
     *&#64;&#64;     generated if this specification does not comply with underlying
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool is_shape_tensor = 6;</code>
     */
    boolean getIsShapeTensor();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool allow_ragged_batch
     *&#64;&#64;
     *&#64;&#64;     Whether or not the input is allowed to be "ragged" in a dynamically
     *&#64;&#64;     created batch. Default is false indicating that two requests will
     *&#64;&#64;     only be batched if this tensor has the same shape in both requests.
     *&#64;&#64;     True indicates that two requests can be batched even if this tensor
     *&#64;&#64;     has a different shape in each request. A true value is currently
     *&#64;&#64;     supported only for custom models.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool allow_ragged_batch = 7;</code>
     */
    boolean getAllowRaggedBatch();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelInput
   *&#64;&#64;
   *&#64;&#64;   An input required by the model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelInput}
   */
  public  static final class ModelInput extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelInput)
      ModelInputOrBuilder {
    // Use ModelInput.newBuilder() to construct.
    private ModelInput(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelInput() {
      name_ = "";
      dataType_ = 0;
      format_ = 0;
      dims_ = java.util.Collections.emptyList();
      isShapeTensor_ = false;
      allowRaggedBatch_ = false;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelInput(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();

              dataType_ = rawValue;
              break;
            }
            case 24: {
              int rawValue = input.readEnum();

              format_ = rawValue;
              break;
            }
            case 32: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                dims_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000008;
              }
              dims_.add(input.readInt64());
              break;
            }
            case 34: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008) && input.getBytesUntilLimit() > 0) {
                dims_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000008;
              }
              while (input.getBytesUntilLimit() > 0) {
                dims_.add(input.readInt64());
              }
              input.popLimit(limit);
              break;
            }
            case 42: {
              ModelConfigOuterClass.ModelTensorReshape.Builder subBuilder = null;
              if (reshape_ != null) {
                subBuilder = reshape_.toBuilder();
              }
              reshape_ = input.readMessage(ModelConfigOuterClass.ModelTensorReshape.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reshape_);
                reshape_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {

              isShapeTensor_ = input.readBool();
              break;
            }
            case 56: {

              allowRaggedBatch_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          dims_ = java.util.Collections.unmodifiableList(dims_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelInput_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelInput_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelInput.class, ModelConfigOuterClass.ModelInput.Builder.class);
    }

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:enum:: Format
     *&#64;&#64;
     *&#64;&#64;     The format for the input.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf enum {@code inference.ModelInput.Format}
     */
    public enum Format
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NONE = 0
       *&#64;&#64;
       *&#64;&#64;       The input has no specific format. This is the default.
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NONE = 0;</code>
       */
      FORMAT_NONE(0),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NHWC = 1
       *&#64;&#64;
       *&#64;&#64;       HWC image format. Tensors with this format require 3 dimensions
       *&#64;&#64;       if the model does not support batching (max_batch_size = 0) or 4
       *&#64;&#64;       dimensions if the model does support batching (max_batch_size
       *&#64;&#64;       &gt;= 1). In either case the 'dims' below should only specify the
       *&#64;&#64;       3 non-batch dimensions (i.e. HWC or CHW).
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NHWC = 1;</code>
       */
      FORMAT_NHWC(1),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NCHW = 2
       *&#64;&#64;
       *&#64;&#64;       CHW image format. Tensors with this format require 3 dimensions
       *&#64;&#64;       if the model does not support batching (max_batch_size = 0) or 4
       *&#64;&#64;       dimensions if the model does support batching (max_batch_size
       *&#64;&#64;       &gt;= 1). In either case the 'dims' below should only specify the
       *&#64;&#64;       3 non-batch dimensions (i.e. HWC or CHW).
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NCHW = 2;</code>
       */
      FORMAT_NCHW(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NONE = 0
       *&#64;&#64;
       *&#64;&#64;       The input has no specific format. This is the default.
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NONE = 0;</code>
       */
      public static final int FORMAT_NONE_VALUE = 0;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NHWC = 1
       *&#64;&#64;
       *&#64;&#64;       HWC image format. Tensors with this format require 3 dimensions
       *&#64;&#64;       if the model does not support batching (max_batch_size = 0) or 4
       *&#64;&#64;       dimensions if the model does support batching (max_batch_size
       *&#64;&#64;       &gt;= 1). In either case the 'dims' below should only specify the
       *&#64;&#64;       3 non-batch dimensions (i.e. HWC or CHW).
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NHWC = 1;</code>
       */
      public static final int FORMAT_NHWC_VALUE = 1;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Format::FORMAT_NCHW = 2
       *&#64;&#64;
       *&#64;&#64;       CHW image format. Tensors with this format require 3 dimensions
       *&#64;&#64;       if the model does not support batching (max_batch_size = 0) or 4
       *&#64;&#64;       dimensions if the model does support batching (max_batch_size
       *&#64;&#64;       &gt;= 1). In either case the 'dims' below should only specify the
       *&#64;&#64;       3 non-batch dimensions (i.e. HWC or CHW).
       *&#64;&#64;
       * </pre>
       *
       * <code>FORMAT_NCHW = 2;</code>
       */
      public static final int FORMAT_NCHW_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static Format valueOf(int value) {
        return forNumber(value);
      }

      public static Format forNumber(int value) {
        switch (value) {
          case 0: return FORMAT_NONE;
          case 1: return FORMAT_NHWC;
          case 2: return FORMAT_NCHW;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<Format>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          Format> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<Format>() {
              public Format findValueByNumber(int number) {
                return Format.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return ModelConfigOuterClass.ModelInput.getDescriptor().getEnumTypes().get(0);
      }

      private static final Format[] VALUES = values();

      public static Format valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private Format(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:inference.ModelInput.Format)
    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    private volatile Object name_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DATA_TYPE_FIELD_NUMBER = 2;
    private int dataType_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    public int getDataTypeValue() {
      return dataType_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the input.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    public ModelConfigOuterClass.DataType getDataType() {
      ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
      return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
    }

    public static final int FORMAT_FIELD_NUMBER = 3;
    private int format_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Format format
     *&#64;&#64;
     *&#64;&#64;     The format of the input. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInput.Format format = 3;</code>
     */
    public int getFormatValue() {
      return format_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Format format
     *&#64;&#64;
     *&#64;&#64;     The format of the input. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelInput.Format format = 3;</code>
     */
    public ModelConfigOuterClass.ModelInput.Format getFormat() {
      ModelConfigOuterClass.ModelInput.Format result = ModelConfigOuterClass.ModelInput.Format.valueOf(format_);
      return result == null ? ModelConfigOuterClass.ModelInput.Format.UNRECOGNIZED : result;
    }

    public static final int DIMS_FIELD_NUMBER = 4;
    private java.util.List<Long> dims_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    public java.util.List<Long>
        getDimsList() {
      return dims_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    public int getDimsCount() {
      return dims_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
     *&#64;&#64;     when invoking the inference API for this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 4;</code>
     */
    public long getDims(int index) {
      return dims_.get(index);
    }
    private int dimsMemoizedSerializedSize = -1;

    public static final int RESHAPE_FIELD_NUMBER = 5;
    private ModelConfigOuterClass.ModelTensorReshape reshape_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public boolean hasReshape() {
      return reshape_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public ModelConfigOuterClass.ModelTensorReshape getReshape() {
      return reshape_ == null ? ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape expected for this input by the backend. The input will
     *&#64;&#64;     be reshaped to this before being presented to the backend. The
     *&#64;&#64;     reshape must have the same number of elements as the input shape
     *&#64;&#64;     specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder() {
      return getReshape();
    }

    public static final int IS_SHAPE_TENSOR_FIELD_NUMBER = 6;
    private boolean isShapeTensor_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
     *&#64;&#64;
     *&#64;&#64;     Whether or not the input is a shape tensor to the model. This field
     *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
     *&#64;&#64;     generated if this specification does not comply with underlying
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool is_shape_tensor = 6;</code>
     */
    public boolean getIsShapeTensor() {
      return isShapeTensor_;
    }

    public static final int ALLOW_RAGGED_BATCH_FIELD_NUMBER = 7;
    private boolean allowRaggedBatch_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool allow_ragged_batch
     *&#64;&#64;
     *&#64;&#64;     Whether or not the input is allowed to be "ragged" in a dynamically
     *&#64;&#64;     created batch. Default is false indicating that two requests will
     *&#64;&#64;     only be batched if this tensor has the same shape in both requests.
     *&#64;&#64;     True indicates that two requests can be batched even if this tensor
     *&#64;&#64;     has a different shape in each request. A true value is currently
     *&#64;&#64;     supported only for custom models.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool allow_ragged_batch = 7;</code>
     */
    public boolean getAllowRaggedBatch() {
      return allowRaggedBatch_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
        output.writeEnum(2, dataType_);
      }
      if (format_ != ModelConfigOuterClass.ModelInput.Format.FORMAT_NONE.getNumber()) {
        output.writeEnum(3, format_);
      }
      if (getDimsList().size() > 0) {
        output.writeUInt32NoTag(34);
        output.writeUInt32NoTag(dimsMemoizedSerializedSize);
      }
      for (int i = 0; i < dims_.size(); i++) {
        output.writeInt64NoTag(dims_.get(i));
      }
      if (reshape_ != null) {
        output.writeMessage(5, getReshape());
      }
      if (isShapeTensor_ != false) {
        output.writeBool(6, isShapeTensor_);
      }
      if (allowRaggedBatch_ != false) {
        output.writeBool(7, allowRaggedBatch_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, dataType_);
      }
      if (format_ != ModelConfigOuterClass.ModelInput.Format.FORMAT_NONE.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(3, format_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < dims_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt64SizeNoTag(dims_.get(i));
        }
        size += dataSize;
        if (!getDimsList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        dimsMemoizedSerializedSize = dataSize;
      }
      if (reshape_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getReshape());
      }
      if (isShapeTensor_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, isShapeTensor_);
      }
      if (allowRaggedBatch_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, allowRaggedBatch_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelInput)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelInput other = (ModelConfigOuterClass.ModelInput) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && dataType_ == other.dataType_;
      result = result && format_ == other.format_;
      result = result && getDimsList()
          .equals(other.getDimsList());
      result = result && (hasReshape() == other.hasReshape());
      if (hasReshape()) {
        result = result && getReshape()
            .equals(other.getReshape());
      }
      result = result && (getIsShapeTensor()
          == other.getIsShapeTensor());
      result = result && (getAllowRaggedBatch()
          == other.getAllowRaggedBatch());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DATA_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + dataType_;
      hash = (37 * hash) + FORMAT_FIELD_NUMBER;
      hash = (53 * hash) + format_;
      if (getDimsCount() > 0) {
        hash = (37 * hash) + DIMS_FIELD_NUMBER;
        hash = (53 * hash) + getDimsList().hashCode();
      }
      if (hasReshape()) {
        hash = (37 * hash) + RESHAPE_FIELD_NUMBER;
        hash = (53 * hash) + getReshape().hashCode();
      }
      hash = (37 * hash) + IS_SHAPE_TENSOR_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsShapeTensor());
      hash = (37 * hash) + ALLOW_RAGGED_BATCH_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAllowRaggedBatch());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelInput parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInput parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInput parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelInput parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelInput prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelInput
     *&#64;&#64;
     *&#64;&#64;   An input required by the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelInput}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelInput)
        ModelConfigOuterClass.ModelInputOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelInput_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelInput_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelInput.class, ModelConfigOuterClass.ModelInput.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelInput.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        name_ = "";

        dataType_ = 0;

        format_ = 0;

        dims_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        if (reshapeBuilder_ == null) {
          reshape_ = null;
        } else {
          reshape_ = null;
          reshapeBuilder_ = null;
        }
        isShapeTensor_ = false;

        allowRaggedBatch_ = false;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelInput_descriptor;
      }

      public ModelConfigOuterClass.ModelInput getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelInput.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelInput build() {
        ModelConfigOuterClass.ModelInput result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelInput buildPartial() {
        ModelConfigOuterClass.ModelInput result = new ModelConfigOuterClass.ModelInput(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.name_ = name_;
        result.dataType_ = dataType_;
        result.format_ = format_;
        if (((bitField0_ & 0x00000008) == 0x00000008)) {
          dims_ = java.util.Collections.unmodifiableList(dims_);
          bitField0_ = (bitField0_ & ~0x00000008);
        }
        result.dims_ = dims_;
        if (reshapeBuilder_ == null) {
          result.reshape_ = reshape_;
        } else {
          result.reshape_ = reshapeBuilder_.build();
        }
        result.isShapeTensor_ = isShapeTensor_;
        result.allowRaggedBatch_ = allowRaggedBatch_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelInput) {
          return mergeFrom((ModelConfigOuterClass.ModelInput)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelInput other) {
        if (other == ModelConfigOuterClass.ModelInput.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.dataType_ != 0) {
          setDataTypeValue(other.getDataTypeValue());
        }
        if (other.format_ != 0) {
          setFormatValue(other.getFormatValue());
        }
        if (!other.dims_.isEmpty()) {
          if (dims_.isEmpty()) {
            dims_ = other.dims_;
            bitField0_ = (bitField0_ & ~0x00000008);
          } else {
            ensureDimsIsMutable();
            dims_.addAll(other.dims_);
          }
          onChanged();
        }
        if (other.hasReshape()) {
          mergeReshape(other.getReshape());
        }
        if (other.getIsShapeTensor() != false) {
          setIsShapeTensor(other.getIsShapeTensor());
        }
        if (other.getAllowRaggedBatch() != false) {
          setAllowRaggedBatch(other.getAllowRaggedBatch());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelInput parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelInput) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {

        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        name_ = value;
        onChanged();
        return this;
      }

      private int dataType_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public int getDataTypeValue() {
        return dataType_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder setDataTypeValue(int value) {
        dataType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public ModelConfigOuterClass.DataType getDataType() {
        ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
        return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder setDataType(ModelConfigOuterClass.DataType value) {
        if (value == null) {
          throw new NullPointerException();
        }

        dataType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder clearDataType() {

        dataType_ = 0;
        onChanged();
        return this;
      }

      private int format_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Format format
       *&#64;&#64;
       *&#64;&#64;     The format of the input. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInput.Format format = 3;</code>
       */
      public int getFormatValue() {
        return format_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Format format
       *&#64;&#64;
       *&#64;&#64;     The format of the input. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInput.Format format = 3;</code>
       */
      public Builder setFormatValue(int value) {
        format_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Format format
       *&#64;&#64;
       *&#64;&#64;     The format of the input. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInput.Format format = 3;</code>
       */
      public ModelConfigOuterClass.ModelInput.Format getFormat() {
        ModelConfigOuterClass.ModelInput.Format result = ModelConfigOuterClass.ModelInput.Format.valueOf(format_);
        return result == null ? ModelConfigOuterClass.ModelInput.Format.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Format format
       *&#64;&#64;
       *&#64;&#64;     The format of the input. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInput.Format format = 3;</code>
       */
      public Builder setFormat(ModelConfigOuterClass.ModelInput.Format value) {
        if (value == null) {
          throw new NullPointerException();
        }

        format_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Format format
       *&#64;&#64;
       *&#64;&#64;     The format of the input. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelInput.Format format = 3;</code>
       */
      public Builder clearFormat() {

        format_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<Long> dims_ = java.util.Collections.emptyList();
      private void ensureDimsIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          dims_ = new java.util.ArrayList<Long>(dims_);
          bitField0_ |= 0x00000008;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public java.util.List<Long>
          getDimsList() {
        return java.util.Collections.unmodifiableList(dims_);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public int getDimsCount() {
        return dims_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public long getDims(int index) {
        return dims_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public Builder setDims(
          int index, long value) {
        ensureDimsIsMutable();
        dims_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public Builder addDims(long value) {
        ensureDimsIsMutable();
        dims_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public Builder addAllDims(
          Iterable<? extends Long> values) {
        ensureDimsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, dims_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the input tensor that must be provided
       *&#64;&#64;     when invoking the inference API for this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 4;</code>
       */
      public Builder clearDims() {
        dims_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000008);
        onChanged();
        return this;
      }

      private ModelConfigOuterClass.ModelTensorReshape reshape_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder> reshapeBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public boolean hasReshape() {
        return reshapeBuilder_ != null || reshape_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshape getReshape() {
        if (reshapeBuilder_ == null) {
          return reshape_ == null ? ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
        } else {
          return reshapeBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder setReshape(ModelConfigOuterClass.ModelTensorReshape value) {
        if (reshapeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reshape_ = value;
          onChanged();
        } else {
          reshapeBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder setReshape(
          ModelConfigOuterClass.ModelTensorReshape.Builder builderForValue) {
        if (reshapeBuilder_ == null) {
          reshape_ = builderForValue.build();
          onChanged();
        } else {
          reshapeBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder mergeReshape(ModelConfigOuterClass.ModelTensorReshape value) {
        if (reshapeBuilder_ == null) {
          if (reshape_ != null) {
            reshape_ =
              ModelConfigOuterClass.ModelTensorReshape.newBuilder(reshape_).mergeFrom(value).buildPartial();
          } else {
            reshape_ = value;
          }
          onChanged();
        } else {
          reshapeBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder clearReshape() {
        if (reshapeBuilder_ == null) {
          reshape_ = null;
          onChanged();
        } else {
          reshape_ = null;
          reshapeBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshape.Builder getReshapeBuilder() {

        onChanged();
        return getReshapeFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder() {
        if (reshapeBuilder_ != null) {
          return reshapeBuilder_.getMessageOrBuilder();
        } else {
          return reshape_ == null ?
              ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape expected for this input by the backend. The input will
       *&#64;&#64;     be reshaped to this before being presented to the backend. The
       *&#64;&#64;     reshape must have the same number of elements as the input shape
       *&#64;&#64;     specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder>
          getReshapeFieldBuilder() {
        if (reshapeBuilder_ == null) {
          reshapeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder>(
                  getReshape(),
                  getParentForChildren(),
                  isClean());
          reshape_ = null;
        }
        return reshapeBuilder_;
      }

      private boolean isShapeTensor_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public boolean getIsShapeTensor() {
        return isShapeTensor_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public Builder setIsShapeTensor(boolean value) {

        isShapeTensor_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public Builder clearIsShapeTensor() {

        isShapeTensor_ = false;
        onChanged();
        return this;
      }

      private boolean allowRaggedBatch_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool allow_ragged_batch
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is allowed to be "ragged" in a dynamically
       *&#64;&#64;     created batch. Default is false indicating that two requests will
       *&#64;&#64;     only be batched if this tensor has the same shape in both requests.
       *&#64;&#64;     True indicates that two requests can be batched even if this tensor
       *&#64;&#64;     has a different shape in each request. A true value is currently
       *&#64;&#64;     supported only for custom models.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_ragged_batch = 7;</code>
       */
      public boolean getAllowRaggedBatch() {
        return allowRaggedBatch_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool allow_ragged_batch
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is allowed to be "ragged" in a dynamically
       *&#64;&#64;     created batch. Default is false indicating that two requests will
       *&#64;&#64;     only be batched if this tensor has the same shape in both requests.
       *&#64;&#64;     True indicates that two requests can be batched even if this tensor
       *&#64;&#64;     has a different shape in each request. A true value is currently
       *&#64;&#64;     supported only for custom models.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_ragged_batch = 7;</code>
       */
      public Builder setAllowRaggedBatch(boolean value) {

        allowRaggedBatch_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool allow_ragged_batch
       *&#64;&#64;
       *&#64;&#64;     Whether or not the input is allowed to be "ragged" in a dynamically
       *&#64;&#64;     created batch. Default is false indicating that two requests will
       *&#64;&#64;     only be batched if this tensor has the same shape in both requests.
       *&#64;&#64;     True indicates that two requests can be batched even if this tensor
       *&#64;&#64;     has a different shape in each request. A true value is currently
       *&#64;&#64;     supported only for custom models.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_ragged_batch = 7;</code>
       */
      public Builder clearAllowRaggedBatch() {

        allowRaggedBatch_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelInput)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelInput)
    private static final ModelConfigOuterClass.ModelInput DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelInput();
    }

    public static ModelConfigOuterClass.ModelInput getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelInput>
        PARSER = new com.google.protobuf.AbstractParser<ModelInput>() {
      public ModelInput parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelInput(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelInput> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelInput> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelInput getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelOutputOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelOutput)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    String getName();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    int getDataTypeValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    ModelConfigOuterClass.DataType getDataType();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    java.util.List<Long> getDimsList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    int getDimsCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    long getDims(int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    boolean hasReshape();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    ModelConfigOuterClass.ModelTensorReshape getReshape();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string label_filename
     *&#64;&#64;
     *&#64;&#64;     The label file associated with this output. Should be specified only
     *&#64;&#64;     for outputs that represent classifications. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string label_filename = 4;</code>
     */
    String getLabelFilename();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string label_filename
     *&#64;&#64;
     *&#64;&#64;     The label file associated with this output. Should be specified only
     *&#64;&#64;     for outputs that represent classifications. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string label_filename = 4;</code>
     */
    com.google.protobuf.ByteString
        getLabelFilenameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
     *&#64;&#64;
     *&#64;&#64;     Whether or not the output is a shape tensor to the model. This field
     *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
     *&#64;&#64;     generated if this specification does not comply with underlying
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool is_shape_tensor = 6;</code>
     */
    boolean getIsShapeTensor();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelOutput
   *&#64;&#64;
   *&#64;&#64;   An output produced by the model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelOutput}
   */
  public  static final class ModelOutput extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelOutput)
      ModelOutputOrBuilder {
    // Use ModelOutput.newBuilder() to construct.
    private ModelOutput(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelOutput() {
      name_ = "";
      dataType_ = 0;
      dims_ = java.util.Collections.emptyList();
      labelFilename_ = "";
      isShapeTensor_ = false;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelOutput(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();

              dataType_ = rawValue;
              break;
            }
            case 24: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                dims_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000004;
              }
              dims_.add(input.readInt64());
              break;
            }
            case 26: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004) && input.getBytesUntilLimit() > 0) {
                dims_ = new java.util.ArrayList<Long>();
                mutable_bitField0_ |= 0x00000004;
              }
              while (input.getBytesUntilLimit() > 0) {
                dims_.add(input.readInt64());
              }
              input.popLimit(limit);
              break;
            }
            case 34: {
              String s = input.readStringRequireUtf8();

              labelFilename_ = s;
              break;
            }
            case 42: {
              ModelConfigOuterClass.ModelTensorReshape.Builder subBuilder = null;
              if (reshape_ != null) {
                subBuilder = reshape_.toBuilder();
              }
              reshape_ = input.readMessage(ModelConfigOuterClass.ModelTensorReshape.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reshape_);
                reshape_ = subBuilder.buildPartial();
              }

              break;
            }
            case 48: {

              isShapeTensor_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          dims_ = java.util.Collections.unmodifiableList(dims_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelOutput_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelOutput_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelOutput.class, ModelConfigOuterClass.ModelOutput.Builder.class);
    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    private volatile Object name_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DATA_TYPE_FIELD_NUMBER = 2;
    private int dataType_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    public int getDataTypeValue() {
      return dataType_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: DataType data_type
     *&#64;&#64;
     *&#64;&#64;     The data-type of the output.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.DataType data_type = 2;</code>
     */
    public ModelConfigOuterClass.DataType getDataType() {
      ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
      return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
    }

    public static final int DIMS_FIELD_NUMBER = 3;
    private java.util.List<Long> dims_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    public java.util.List<Long>
        getDimsList() {
      return dims_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    public int getDimsCount() {
      return dims_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
     *&#64;&#64;
     *&#64;&#64;     The dimensions/shape of the output tensor.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int64 dims = 3;</code>
     */
    public long getDims(int index) {
      return dims_.get(index);
    }
    private int dimsMemoizedSerializedSize = -1;

    public static final int RESHAPE_FIELD_NUMBER = 5;
    private ModelConfigOuterClass.ModelTensorReshape reshape_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public boolean hasReshape() {
      return reshape_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public ModelConfigOuterClass.ModelTensorReshape getReshape() {
      return reshape_ == null ? ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
     *&#64;&#64;
     *&#64;&#64;     The shape produced for this output by the backend. The output will
     *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
     *&#64;&#64;     returned in the inference response. The reshape must have the same
     *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
     */
    public ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder() {
      return getReshape();
    }

    public static final int LABEL_FILENAME_FIELD_NUMBER = 4;
    private volatile Object labelFilename_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string label_filename
     *&#64;&#64;
     *&#64;&#64;     The label file associated with this output. Should be specified only
     *&#64;&#64;     for outputs that represent classifications. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string label_filename = 4;</code>
     */
    public String getLabelFilename() {
      Object ref = labelFilename_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        labelFilename_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string label_filename
     *&#64;&#64;
     *&#64;&#64;     The label file associated with this output. Should be specified only
     *&#64;&#64;     for outputs that represent classifications. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string label_filename = 4;</code>
     */
    public com.google.protobuf.ByteString
        getLabelFilenameBytes() {
      Object ref = labelFilename_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        labelFilename_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int IS_SHAPE_TENSOR_FIELD_NUMBER = 6;
    private boolean isShapeTensor_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
     *&#64;&#64;
     *&#64;&#64;     Whether or not the output is a shape tensor to the model. This field
     *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
     *&#64;&#64;     generated if this specification does not comply with underlying
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool is_shape_tensor = 6;</code>
     */
    public boolean getIsShapeTensor() {
      return isShapeTensor_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
        output.writeEnum(2, dataType_);
      }
      if (getDimsList().size() > 0) {
        output.writeUInt32NoTag(26);
        output.writeUInt32NoTag(dimsMemoizedSerializedSize);
      }
      for (int i = 0; i < dims_.size(); i++) {
        output.writeInt64NoTag(dims_.get(i));
      }
      if (!getLabelFilenameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, labelFilename_);
      }
      if (reshape_ != null) {
        output.writeMessage(5, getReshape());
      }
      if (isShapeTensor_ != false) {
        output.writeBool(6, isShapeTensor_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, dataType_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < dims_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt64SizeNoTag(dims_.get(i));
        }
        size += dataSize;
        if (!getDimsList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        dimsMemoizedSerializedSize = dataSize;
      }
      if (!getLabelFilenameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, labelFilename_);
      }
      if (reshape_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getReshape());
      }
      if (isShapeTensor_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, isShapeTensor_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelOutput)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelOutput other = (ModelConfigOuterClass.ModelOutput) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && dataType_ == other.dataType_;
      result = result && getDimsList()
          .equals(other.getDimsList());
      result = result && (hasReshape() == other.hasReshape());
      if (hasReshape()) {
        result = result && getReshape()
            .equals(other.getReshape());
      }
      result = result && getLabelFilename()
          .equals(other.getLabelFilename());
      result = result && (getIsShapeTensor()
          == other.getIsShapeTensor());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + DATA_TYPE_FIELD_NUMBER;
      hash = (53 * hash) + dataType_;
      if (getDimsCount() > 0) {
        hash = (37 * hash) + DIMS_FIELD_NUMBER;
        hash = (53 * hash) + getDimsList().hashCode();
      }
      if (hasReshape()) {
        hash = (37 * hash) + RESHAPE_FIELD_NUMBER;
        hash = (53 * hash) + getReshape().hashCode();
      }
      hash = (37 * hash) + LABEL_FILENAME_FIELD_NUMBER;
      hash = (53 * hash) + getLabelFilename().hashCode();
      hash = (37 * hash) + IS_SHAPE_TENSOR_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsShapeTensor());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelOutput parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOutput parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOutput parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOutput parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelOutput prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelOutput
     *&#64;&#64;
     *&#64;&#64;   An output produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOutput}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelOutput)
        ModelConfigOuterClass.ModelOutputOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOutput_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOutput_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOutput.class, ModelConfigOuterClass.ModelOutput.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelOutput.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        name_ = "";

        dataType_ = 0;

        dims_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        if (reshapeBuilder_ == null) {
          reshape_ = null;
        } else {
          reshape_ = null;
          reshapeBuilder_ = null;
        }
        labelFilename_ = "";

        isShapeTensor_ = false;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelOutput_descriptor;
      }

      public ModelConfigOuterClass.ModelOutput getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelOutput.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelOutput build() {
        ModelConfigOuterClass.ModelOutput result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelOutput buildPartial() {
        ModelConfigOuterClass.ModelOutput result = new ModelConfigOuterClass.ModelOutput(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.name_ = name_;
        result.dataType_ = dataType_;
        if (((bitField0_ & 0x00000004) == 0x00000004)) {
          dims_ = java.util.Collections.unmodifiableList(dims_);
          bitField0_ = (bitField0_ & ~0x00000004);
        }
        result.dims_ = dims_;
        if (reshapeBuilder_ == null) {
          result.reshape_ = reshape_;
        } else {
          result.reshape_ = reshapeBuilder_.build();
        }
        result.labelFilename_ = labelFilename_;
        result.isShapeTensor_ = isShapeTensor_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelOutput) {
          return mergeFrom((ModelConfigOuterClass.ModelOutput)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelOutput other) {
        if (other == ModelConfigOuterClass.ModelOutput.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.dataType_ != 0) {
          setDataTypeValue(other.getDataTypeValue());
        }
        if (!other.dims_.isEmpty()) {
          if (dims_.isEmpty()) {
            dims_ = other.dims_;
            bitField0_ = (bitField0_ & ~0x00000004);
          } else {
            ensureDimsIsMutable();
            dims_.addAll(other.dims_);
          }
          onChanged();
        }
        if (other.hasReshape()) {
          mergeReshape(other.getReshape());
        }
        if (!other.getLabelFilename().isEmpty()) {
          labelFilename_ = other.labelFilename_;
          onChanged();
        }
        if (other.getIsShapeTensor() != false) {
          setIsShapeTensor(other.getIsShapeTensor());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelOutput parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelOutput) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {

        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        name_ = value;
        onChanged();
        return this;
      }

      private int dataType_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public int getDataTypeValue() {
        return dataType_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder setDataTypeValue(int value) {
        dataType_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public ModelConfigOuterClass.DataType getDataType() {
        ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
        return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder setDataType(ModelConfigOuterClass.DataType value) {
        if (value == null) {
          throw new NullPointerException();
        }

        dataType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;     The data-type of the output.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 2;</code>
       */
      public Builder clearDataType() {

        dataType_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<Long> dims_ = java.util.Collections.emptyList();
      private void ensureDimsIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          dims_ = new java.util.ArrayList<Long>(dims_);
          bitField0_ |= 0x00000004;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public java.util.List<Long>
          getDimsList() {
        return java.util.Collections.unmodifiableList(dims_);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public int getDimsCount() {
        return dims_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public long getDims(int index) {
        return dims_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public Builder setDims(
          int index, long value) {
        ensureDimsIsMutable();
        dims_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public Builder addDims(long value) {
        ensureDimsIsMutable();
        dims_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public Builder addAllDims(
          Iterable<? extends Long> values) {
        ensureDimsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, dims_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;     The dimensions/shape of the output tensor.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 3;</code>
       */
      public Builder clearDims() {
        dims_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000004);
        onChanged();
        return this;
      }

      private ModelConfigOuterClass.ModelTensorReshape reshape_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder> reshapeBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public boolean hasReshape() {
        return reshapeBuilder_ != null || reshape_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshape getReshape() {
        if (reshapeBuilder_ == null) {
          return reshape_ == null ? ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
        } else {
          return reshapeBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder setReshape(ModelConfigOuterClass.ModelTensorReshape value) {
        if (reshapeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reshape_ = value;
          onChanged();
        } else {
          reshapeBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder setReshape(
          ModelConfigOuterClass.ModelTensorReshape.Builder builderForValue) {
        if (reshapeBuilder_ == null) {
          reshape_ = builderForValue.build();
          onChanged();
        } else {
          reshapeBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder mergeReshape(ModelConfigOuterClass.ModelTensorReshape value) {
        if (reshapeBuilder_ == null) {
          if (reshape_ != null) {
            reshape_ =
              ModelConfigOuterClass.ModelTensorReshape.newBuilder(reshape_).mergeFrom(value).buildPartial();
          } else {
            reshape_ = value;
          }
          onChanged();
        } else {
          reshapeBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public Builder clearReshape() {
        if (reshapeBuilder_ == null) {
          reshape_ = null;
          onChanged();
        } else {
          reshape_ = null;
          reshapeBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshape.Builder getReshapeBuilder() {

        onChanged();
        return getReshapeFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      public ModelConfigOuterClass.ModelTensorReshapeOrBuilder getReshapeOrBuilder() {
        if (reshapeBuilder_ != null) {
          return reshapeBuilder_.getMessageOrBuilder();
        } else {
          return reshape_ == null ?
              ModelConfigOuterClass.ModelTensorReshape.getDefaultInstance() : reshape_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTensorReshape reshape
       *&#64;&#64;
       *&#64;&#64;     The shape produced for this output by the backend. The output will
       *&#64;&#64;     be reshaped from this to the shape specifed in 'dims' before being
       *&#64;&#64;     returned in the inference response. The reshape must have the same
       *&#64;&#64;     number of elements as the output shape specified by 'dims'. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTensorReshape reshape = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder>
          getReshapeFieldBuilder() {
        if (reshapeBuilder_ == null) {
          reshapeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelTensorReshape, ModelConfigOuterClass.ModelTensorReshape.Builder, ModelConfigOuterClass.ModelTensorReshapeOrBuilder>(
                  getReshape(),
                  getParentForChildren(),
                  isClean());
          reshape_ = null;
        }
        return reshapeBuilder_;
      }

      private Object labelFilename_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string label_filename
       *&#64;&#64;
       *&#64;&#64;     The label file associated with this output. Should be specified only
       *&#64;&#64;     for outputs that represent classifications. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string label_filename = 4;</code>
       */
      public String getLabelFilename() {
        Object ref = labelFilename_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          labelFilename_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string label_filename
       *&#64;&#64;
       *&#64;&#64;     The label file associated with this output. Should be specified only
       *&#64;&#64;     for outputs that represent classifications. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string label_filename = 4;</code>
       */
      public com.google.protobuf.ByteString
          getLabelFilenameBytes() {
        Object ref = labelFilename_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          labelFilename_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string label_filename
       *&#64;&#64;
       *&#64;&#64;     The label file associated with this output. Should be specified only
       *&#64;&#64;     for outputs that represent classifications. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string label_filename = 4;</code>
       */
      public Builder setLabelFilename(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        labelFilename_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string label_filename
       *&#64;&#64;
       *&#64;&#64;     The label file associated with this output. Should be specified only
       *&#64;&#64;     for outputs that represent classifications. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string label_filename = 4;</code>
       */
      public Builder clearLabelFilename() {

        labelFilename_ = getDefaultInstance().getLabelFilename();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string label_filename
       *&#64;&#64;
       *&#64;&#64;     The label file associated with this output. Should be specified only
       *&#64;&#64;     for outputs that represent classifications. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string label_filename = 4;</code>
       */
      public Builder setLabelFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        labelFilename_ = value;
        onChanged();
        return this;
      }

      private boolean isShapeTensor_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the output is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public boolean getIsShapeTensor() {
        return isShapeTensor_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the output is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public Builder setIsShapeTensor(boolean value) {

        isShapeTensor_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool is_shape_tensor
       *&#64;&#64;
       *&#64;&#64;     Whether or not the output is a shape tensor to the model. This field
       *&#64;&#64;     is currently supported only for the TensorRT model. An error will be
       *&#64;&#64;     generated if this specification does not comply with underlying
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool is_shape_tensor = 6;</code>
       */
      public Builder clearIsShapeTensor() {

        isShapeTensor_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelOutput)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelOutput)
    private static final ModelConfigOuterClass.ModelOutput DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOutput();
    }

    public static ModelConfigOuterClass.ModelOutput getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelOutput>
        PARSER = new com.google.protobuf.AbstractParser<ModelOutput>() {
      public ModelOutput parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelOutput(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelOutput> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelOutput> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelOutput getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelVersionPolicyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelVersionPolicy)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Latest latest
     *&#64;&#64;
     *&#64;&#64;       Serve only latest version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.Latest getLatest();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Latest latest
     *&#64;&#64;
     *&#64;&#64;       Serve only latest version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder getLatestOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: All all
     *&#64;&#64;
     *&#64;&#64;       Serve all versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.All getAll();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: All all
     *&#64;&#64;
     *&#64;&#64;       Serve all versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder getAllOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Specific specific
     *&#64;&#64;
     *&#64;&#64;       Serve only specific version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.Specific getSpecific();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Specific specific
     *&#64;&#64;
     *&#64;&#64;       Serve only specific version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder getSpecificOrBuilder();

    public ModelConfigOuterClass.ModelVersionPolicy.PolicyChoiceCase getPolicyChoiceCase();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelVersionPolicy
   *&#64;&#64;
   *&#64;&#64;   Policy indicating which versions of a model should be made
   *&#64;&#64;   available by the inference server.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelVersionPolicy}
   */
  public  static final class ModelVersionPolicy extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelVersionPolicy)
      ModelVersionPolicyOrBuilder {
    // Use ModelVersionPolicy.newBuilder() to construct.
    private ModelVersionPolicy(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelVersionPolicy() {
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelVersionPolicy(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder subBuilder = null;
              if (policyChoiceCase_ == 1) {
                subBuilder = ((ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_).toBuilder();
              }
              policyChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelVersionPolicy.Latest.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_);
                policyChoice_ = subBuilder.buildPartial();
              }
              policyChoiceCase_ = 1;
              break;
            }
            case 18: {
              ModelConfigOuterClass.ModelVersionPolicy.All.Builder subBuilder = null;
              if (policyChoiceCase_ == 2) {
                subBuilder = ((ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_).toBuilder();
              }
              policyChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelVersionPolicy.All.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_);
                policyChoice_ = subBuilder.buildPartial();
              }
              policyChoiceCase_ = 2;
              break;
            }
            case 26: {
              ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder subBuilder = null;
              if (policyChoiceCase_ == 3) {
                subBuilder = ((ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_).toBuilder();
              }
              policyChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelVersionPolicy.Specific.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_);
                policyChoice_ = subBuilder.buildPartial();
              }
              policyChoiceCase_ = 3;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelVersionPolicy.class, ModelConfigOuterClass.ModelVersionPolicy.Builder.class);
    }

    public interface LatestOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelVersionPolicy.Latest)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: uint32 num_versions
       *&#64;&#64;
       *&#64;&#64;       Serve only the 'num_versions' highest-numbered versions. T
       *&#64;&#64;       The default value of 'num_versions' is 1, indicating that by
       *&#64;&#64;       default only the single highest-number version of a
       *&#64;&#64;       model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 num_versions = 1;</code>
       */
      int getNumVersions();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message Latest
     *&#64;&#64;
     *&#64;&#64;     Serve only the latest version(s) of a model. This is
     *&#64;&#64;     the default policy.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelVersionPolicy.Latest}
     */
    public  static final class Latest extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelVersionPolicy.Latest)
        LatestOrBuilder {
      // Use Latest.newBuilder() to construct.
      private Latest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Latest() {
        numVersions_ = 0;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Latest(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {

                numVersions_ = input.readUInt32();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Latest_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Latest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelVersionPolicy.Latest.class, ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder.class);
      }

      public static final int NUM_VERSIONS_FIELD_NUMBER = 1;
      private int numVersions_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: uint32 num_versions
       *&#64;&#64;
       *&#64;&#64;       Serve only the 'num_versions' highest-numbered versions. T
       *&#64;&#64;       The default value of 'num_versions' is 1, indicating that by
       *&#64;&#64;       default only the single highest-number version of a
       *&#64;&#64;       model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 num_versions = 1;</code>
       */
      public int getNumVersions() {
        return numVersions_;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (numVersions_ != 0) {
          output.writeUInt32(1, numVersions_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (numVersions_ != 0) {
          size += com.google.protobuf.CodedOutputStream
            .computeUInt32Size(1, numVersions_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelVersionPolicy.Latest)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelVersionPolicy.Latest other = (ModelConfigOuterClass.ModelVersionPolicy.Latest) obj;

        boolean result = true;
        result = result && (getNumVersions()
            == other.getNumVersions());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + NUM_VERSIONS_FIELD_NUMBER;
        hash = (53 * hash) + getNumVersions();
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Latest parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelVersionPolicy.Latest prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message Latest
       *&#64;&#64;
       *&#64;&#64;     Serve only the latest version(s) of a model. This is
       *&#64;&#64;     the default policy.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelVersionPolicy.Latest}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelVersionPolicy.Latest)
          ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Latest_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Latest_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelVersionPolicy.Latest.class, ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelVersionPolicy.Latest.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          numVersions_ = 0;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Latest_descriptor;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Latest getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Latest build() {
          ModelConfigOuterClass.ModelVersionPolicy.Latest result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Latest buildPartial() {
          ModelConfigOuterClass.ModelVersionPolicy.Latest result = new ModelConfigOuterClass.ModelVersionPolicy.Latest(this);
          result.numVersions_ = numVersions_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelVersionPolicy.Latest) {
            return mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.Latest)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelVersionPolicy.Latest other) {
          if (other == ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance()) return this;
          if (other.getNumVersions() != 0) {
            setNumVersions(other.getNumVersions());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelVersionPolicy.Latest parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelVersionPolicy.Latest) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private int numVersions_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint32 num_versions
         *&#64;&#64;
         *&#64;&#64;       Serve only the 'num_versions' highest-numbered versions. T
         *&#64;&#64;       The default value of 'num_versions' is 1, indicating that by
         *&#64;&#64;       default only the single highest-number version of a
         *&#64;&#64;       model will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint32 num_versions = 1;</code>
         */
        public int getNumVersions() {
          return numVersions_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint32 num_versions
         *&#64;&#64;
         *&#64;&#64;       Serve only the 'num_versions' highest-numbered versions. T
         *&#64;&#64;       The default value of 'num_versions' is 1, indicating that by
         *&#64;&#64;       default only the single highest-number version of a
         *&#64;&#64;       model will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint32 num_versions = 1;</code>
         */
        public Builder setNumVersions(int value) {

          numVersions_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint32 num_versions
         *&#64;&#64;
         *&#64;&#64;       Serve only the 'num_versions' highest-numbered versions. T
         *&#64;&#64;       The default value of 'num_versions' is 1, indicating that by
         *&#64;&#64;       default only the single highest-number version of a
         *&#64;&#64;       model will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint32 num_versions = 1;</code>
         */
        public Builder clearNumVersions() {

          numVersions_ = 0;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelVersionPolicy.Latest)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.Latest)
      private static final ModelConfigOuterClass.ModelVersionPolicy.Latest DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelVersionPolicy.Latest();
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.Latest getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Latest>
          PARSER = new com.google.protobuf.AbstractParser<Latest>() {
        public Latest parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Latest(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Latest> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Latest> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelVersionPolicy.Latest getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface AllOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelVersionPolicy.All)
        com.google.protobuf.MessageOrBuilder {
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message All
     *&#64;&#64;
     *&#64;&#64;     Serve all versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelVersionPolicy.All}
     */
    public  static final class All extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelVersionPolicy.All)
        AllOrBuilder {
      // Use All.newBuilder() to construct.
      private All(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private All() {
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private All(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_All_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_All_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelVersionPolicy.All.class, ModelConfigOuterClass.ModelVersionPolicy.All.Builder.class);
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelVersionPolicy.All)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelVersionPolicy.All other = (ModelConfigOuterClass.ModelVersionPolicy.All) obj;

        boolean result = true;
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.All parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelVersionPolicy.All prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message All
       *&#64;&#64;
       *&#64;&#64;     Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelVersionPolicy.All}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelVersionPolicy.All)
          ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_All_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_All_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelVersionPolicy.All.class, ModelConfigOuterClass.ModelVersionPolicy.All.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelVersionPolicy.All.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_All_descriptor;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.All getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelVersionPolicy.All build() {
          ModelConfigOuterClass.ModelVersionPolicy.All result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.All buildPartial() {
          ModelConfigOuterClass.ModelVersionPolicy.All result = new ModelConfigOuterClass.ModelVersionPolicy.All(this);
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelVersionPolicy.All) {
            return mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.All)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelVersionPolicy.All other) {
          if (other == ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance()) return this;
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelVersionPolicy.All parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelVersionPolicy.All) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelVersionPolicy.All)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.All)
      private static final ModelConfigOuterClass.ModelVersionPolicy.All DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelVersionPolicy.All();
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.All getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<All>
          PARSER = new com.google.protobuf.AbstractParser<All>() {
        public All parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new All(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<All> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<All> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelVersionPolicy.All getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface SpecificOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelVersionPolicy.Specific)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      java.util.List<Long> getVersionsList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      int getVersionsCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      long getVersions(int index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message Specific
     *&#64;&#64;
     *&#64;&#64;     Serve only specific versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelVersionPolicy.Specific}
     */
    public  static final class Specific extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelVersionPolicy.Specific)
        SpecificOrBuilder {
      // Use Specific.newBuilder() to construct.
      private Specific(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Specific() {
        versions_ = java.util.Collections.emptyList();
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Specific(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {
                if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                  versions_ = new java.util.ArrayList<Long>();
                  mutable_bitField0_ |= 0x00000001;
                }
                versions_.add(input.readInt64());
                break;
              }
              case 10: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                if (!((mutable_bitField0_ & 0x00000001) == 0x00000001) && input.getBytesUntilLimit() > 0) {
                  versions_ = new java.util.ArrayList<Long>();
                  mutable_bitField0_ |= 0x00000001;
                }
                while (input.getBytesUntilLimit() > 0) {
                  versions_.add(input.readInt64());
                }
                input.popLimit(limit);
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
            versions_ = java.util.Collections.unmodifiableList(versions_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Specific_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Specific_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelVersionPolicy.Specific.class, ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder.class);
      }

      public static final int VERSIONS_FIELD_NUMBER = 1;
      private java.util.List<Long> versions_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      public java.util.List<Long>
          getVersionsList() {
        return versions_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      public int getVersionsCount() {
        return versions_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
       *&#64;&#64;
       *&#64;&#64;       The specific versions of the model that will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 versions = 1;</code>
       */
      public long getVersions(int index) {
        return versions_.get(index);
      }
      private int versionsMemoizedSerializedSize = -1;

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (getVersionsList().size() > 0) {
          output.writeUInt32NoTag(10);
          output.writeUInt32NoTag(versionsMemoizedSerializedSize);
        }
        for (int i = 0; i < versions_.size(); i++) {
          output.writeInt64NoTag(versions_.get(i));
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        {
          int dataSize = 0;
          for (int i = 0; i < versions_.size(); i++) {
            dataSize += com.google.protobuf.CodedOutputStream
              .computeInt64SizeNoTag(versions_.get(i));
          }
          size += dataSize;
          if (!getVersionsList().isEmpty()) {
            size += 1;
            size += com.google.protobuf.CodedOutputStream
                .computeInt32SizeNoTag(dataSize);
          }
          versionsMemoizedSerializedSize = dataSize;
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelVersionPolicy.Specific)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelVersionPolicy.Specific other = (ModelConfigOuterClass.ModelVersionPolicy.Specific) obj;

        boolean result = true;
        result = result && getVersionsList()
            .equals(other.getVersionsList());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (getVersionsCount() > 0) {
          hash = (37 * hash) + VERSIONS_FIELD_NUMBER;
          hash = (53 * hash) + getVersionsList().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelVersionPolicy.Specific parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelVersionPolicy.Specific prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message Specific
       *&#64;&#64;
       *&#64;&#64;     Serve only specific versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelVersionPolicy.Specific}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelVersionPolicy.Specific)
          ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Specific_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Specific_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelVersionPolicy.Specific.class, ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelVersionPolicy.Specific.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          versions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_Specific_descriptor;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Specific getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Specific build() {
          ModelConfigOuterClass.ModelVersionPolicy.Specific result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelVersionPolicy.Specific buildPartial() {
          ModelConfigOuterClass.ModelVersionPolicy.Specific result = new ModelConfigOuterClass.ModelVersionPolicy.Specific(this);
          int from_bitField0_ = bitField0_;
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            versions_ = java.util.Collections.unmodifiableList(versions_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.versions_ = versions_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelVersionPolicy.Specific) {
            return mergeFrom((ModelConfigOuterClass.ModelVersionPolicy.Specific)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelVersionPolicy.Specific other) {
          if (other == ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance()) return this;
          if (!other.versions_.isEmpty()) {
            if (versions_.isEmpty()) {
              versions_ = other.versions_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureVersionsIsMutable();
              versions_.addAll(other.versions_);
            }
            onChanged();
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelVersionPolicy.Specific parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelVersionPolicy.Specific) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private java.util.List<Long> versions_ = java.util.Collections.emptyList();
        private void ensureVersionsIsMutable() {
          if (!((bitField0_ & 0x00000001) == 0x00000001)) {
            versions_ = new java.util.ArrayList<Long>(versions_);
            bitField0_ |= 0x00000001;
           }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public java.util.List<Long>
            getVersionsList() {
          return java.util.Collections.unmodifiableList(versions_);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public int getVersionsCount() {
          return versions_.size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public long getVersions(int index) {
          return versions_.get(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public Builder setVersions(
            int index, long value) {
          ensureVersionsIsMutable();
          versions_.set(index, value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public Builder addVersions(long value) {
          ensureVersionsIsMutable();
          versions_.add(value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public Builder addAllVersions(
            Iterable<? extends Long> values) {
          ensureVersionsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, versions_);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 versions (repeated)
         *&#64;&#64;
         *&#64;&#64;       The specific versions of the model that will be served.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 versions = 1;</code>
         */
        public Builder clearVersions() {
          versions_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelVersionPolicy.Specific)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy.Specific)
      private static final ModelConfigOuterClass.ModelVersionPolicy.Specific DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelVersionPolicy.Specific();
      }

      public static ModelConfigOuterClass.ModelVersionPolicy.Specific getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Specific>
          PARSER = new com.google.protobuf.AbstractParser<Specific>() {
        public Specific parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Specific(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Specific> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Specific> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelVersionPolicy.Specific getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int policyChoiceCase_ = 0;
    private Object policyChoice_;
    public enum PolicyChoiceCase
        implements com.google.protobuf.Internal.EnumLite {
      LATEST(1),
      ALL(2),
      SPECIFIC(3),
      POLICYCHOICE_NOT_SET(0);
      private final int value;
      private PolicyChoiceCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static PolicyChoiceCase valueOf(int value) {
        return forNumber(value);
      }

      public static PolicyChoiceCase forNumber(int value) {
        switch (value) {
          case 1: return LATEST;
          case 2: return ALL;
          case 3: return SPECIFIC;
          case 0: return POLICYCHOICE_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public PolicyChoiceCase
    getPolicyChoiceCase() {
      return PolicyChoiceCase.forNumber(
          policyChoiceCase_);
    }

    public static final int LATEST_FIELD_NUMBER = 1;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Latest latest
     *&#64;&#64;
     *&#64;&#64;       Serve only latest version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.Latest getLatest() {
      if (policyChoiceCase_ == 1) {
         return (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Latest latest
     *&#64;&#64;
     *&#64;&#64;       Serve only latest version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder getLatestOrBuilder() {
      if (policyChoiceCase_ == 1) {
         return (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
    }

    public static final int ALL_FIELD_NUMBER = 2;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: All all
     *&#64;&#64;
     *&#64;&#64;       Serve all versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.All getAll() {
      if (policyChoiceCase_ == 2) {
         return (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: All all
     *&#64;&#64;
     *&#64;&#64;       Serve all versions of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder getAllOrBuilder() {
      if (policyChoiceCase_ == 2) {
         return (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
    }

    public static final int SPECIFIC_FIELD_NUMBER = 3;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Specific specific
     *&#64;&#64;
     *&#64;&#64;       Serve only specific version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.Specific getSpecific() {
      if (policyChoiceCase_ == 3) {
         return (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: Specific specific
     *&#64;&#64;
     *&#64;&#64;       Serve only specific version(s) of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder getSpecificOrBuilder() {
      if (policyChoiceCase_ == 3) {
         return (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_;
      }
      return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (policyChoiceCase_ == 1) {
        output.writeMessage(1, (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_);
      }
      if (policyChoiceCase_ == 2) {
        output.writeMessage(2, (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_);
      }
      if (policyChoiceCase_ == 3) {
        output.writeMessage(3, (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (policyChoiceCase_ == 1) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_);
      }
      if (policyChoiceCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_);
      }
      if (policyChoiceCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelVersionPolicy)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelVersionPolicy other = (ModelConfigOuterClass.ModelVersionPolicy) obj;

      boolean result = true;
      result = result && getPolicyChoiceCase().equals(
          other.getPolicyChoiceCase());
      if (!result) return false;
      switch (policyChoiceCase_) {
        case 1:
          result = result && getLatest()
              .equals(other.getLatest());
          break;
        case 2:
          result = result && getAll()
              .equals(other.getAll());
          break;
        case 3:
          result = result && getSpecific()
              .equals(other.getSpecific());
          break;
        case 0:
        default:
      }
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      switch (policyChoiceCase_) {
        case 1:
          hash = (37 * hash) + LATEST_FIELD_NUMBER;
          hash = (53 * hash) + getLatest().hashCode();
          break;
        case 2:
          hash = (37 * hash) + ALL_FIELD_NUMBER;
          hash = (53 * hash) + getAll().hashCode();
          break;
        case 3:
          hash = (37 * hash) + SPECIFIC_FIELD_NUMBER;
          hash = (53 * hash) + getSpecific().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelVersionPolicy parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelVersionPolicy prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelVersionPolicy
     *&#64;&#64;
     *&#64;&#64;   Policy indicating which versions of a model should be made
     *&#64;&#64;   available by the inference server.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelVersionPolicy}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelVersionPolicy)
        ModelConfigOuterClass.ModelVersionPolicyOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelVersionPolicy.class, ModelConfigOuterClass.ModelVersionPolicy.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelVersionPolicy.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        policyChoiceCase_ = 0;
        policyChoice_ = null;
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelVersionPolicy_descriptor;
      }

      public ModelConfigOuterClass.ModelVersionPolicy getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelVersionPolicy.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelVersionPolicy build() {
        ModelConfigOuterClass.ModelVersionPolicy result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelVersionPolicy buildPartial() {
        ModelConfigOuterClass.ModelVersionPolicy result = new ModelConfigOuterClass.ModelVersionPolicy(this);
        if (policyChoiceCase_ == 1) {
          if (latestBuilder_ == null) {
            result.policyChoice_ = policyChoice_;
          } else {
            result.policyChoice_ = latestBuilder_.build();
          }
        }
        if (policyChoiceCase_ == 2) {
          if (allBuilder_ == null) {
            result.policyChoice_ = policyChoice_;
          } else {
            result.policyChoice_ = allBuilder_.build();
          }
        }
        if (policyChoiceCase_ == 3) {
          if (specificBuilder_ == null) {
            result.policyChoice_ = policyChoice_;
          } else {
            result.policyChoice_ = specificBuilder_.build();
          }
        }
        result.policyChoiceCase_ = policyChoiceCase_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelVersionPolicy) {
          return mergeFrom((ModelConfigOuterClass.ModelVersionPolicy)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelVersionPolicy other) {
        if (other == ModelConfigOuterClass.ModelVersionPolicy.getDefaultInstance()) return this;
        switch (other.getPolicyChoiceCase()) {
          case LATEST: {
            mergeLatest(other.getLatest());
            break;
          }
          case ALL: {
            mergeAll(other.getAll());
            break;
          }
          case SPECIFIC: {
            mergeSpecific(other.getSpecific());
            break;
          }
          case POLICYCHOICE_NOT_SET: {
            break;
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelVersionPolicy parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelVersionPolicy) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int policyChoiceCase_ = 0;
      private Object policyChoice_;
      public PolicyChoiceCase
          getPolicyChoiceCase() {
        return PolicyChoiceCase.forNumber(
            policyChoiceCase_);
      }

      public Builder clearPolicyChoice() {
        policyChoiceCase_ = 0;
        policyChoice_ = null;
        onChanged();
        return this;
      }


      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.Latest, ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder, ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder> latestBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.Latest getLatest() {
        if (latestBuilder_ == null) {
          if (policyChoiceCase_ == 1) {
            return (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
        } else {
          if (policyChoiceCase_ == 1) {
            return latestBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public Builder setLatest(ModelConfigOuterClass.ModelVersionPolicy.Latest value) {
        if (latestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          policyChoice_ = value;
          onChanged();
        } else {
          latestBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 1;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public Builder setLatest(
          ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder builderForValue) {
        if (latestBuilder_ == null) {
          policyChoice_ = builderForValue.build();
          onChanged();
        } else {
          latestBuilder_.setMessage(builderForValue.build());
        }
        policyChoiceCase_ = 1;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public Builder mergeLatest(ModelConfigOuterClass.ModelVersionPolicy.Latest value) {
        if (latestBuilder_ == null) {
          if (policyChoiceCase_ == 1 &&
              policyChoice_ != ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance()) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.Latest.newBuilder((ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            policyChoice_ = value;
          }
          onChanged();
        } else {
          if (policyChoiceCase_ == 1) {
            latestBuilder_.mergeFrom(value);
          }
          latestBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 1;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public Builder clearLatest() {
        if (latestBuilder_ == null) {
          if (policyChoiceCase_ == 1) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
            onChanged();
          }
        } else {
          if (policyChoiceCase_ == 1) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
          }
          latestBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder getLatestBuilder() {
        return getLatestFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder getLatestOrBuilder() {
        if ((policyChoiceCase_ == 1) && (latestBuilder_ != null)) {
          return latestBuilder_.getMessageOrBuilder();
        } else {
          if (policyChoiceCase_ == 1) {
            return (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Latest latest
       *&#64;&#64;
       *&#64;&#64;       Serve only latest version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Latest latest = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.Latest, ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder, ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder>
          getLatestFieldBuilder() {
        if (latestBuilder_ == null) {
          if (!(policyChoiceCase_ == 1)) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.Latest.getDefaultInstance();
          }
          latestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelVersionPolicy.Latest, ModelConfigOuterClass.ModelVersionPolicy.Latest.Builder, ModelConfigOuterClass.ModelVersionPolicy.LatestOrBuilder>(
                  (ModelConfigOuterClass.ModelVersionPolicy.Latest) policyChoice_,
                  getParentForChildren(),
                  isClean());
          policyChoice_ = null;
        }
        policyChoiceCase_ = 1;
        onChanged();;
        return latestBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.All, ModelConfigOuterClass.ModelVersionPolicy.All.Builder, ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder> allBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.All getAll() {
        if (allBuilder_ == null) {
          if (policyChoiceCase_ == 2) {
            return (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
        } else {
          if (policyChoiceCase_ == 2) {
            return allBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public Builder setAll(ModelConfigOuterClass.ModelVersionPolicy.All value) {
        if (allBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          policyChoice_ = value;
          onChanged();
        } else {
          allBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public Builder setAll(
          ModelConfigOuterClass.ModelVersionPolicy.All.Builder builderForValue) {
        if (allBuilder_ == null) {
          policyChoice_ = builderForValue.build();
          onChanged();
        } else {
          allBuilder_.setMessage(builderForValue.build());
        }
        policyChoiceCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public Builder mergeAll(ModelConfigOuterClass.ModelVersionPolicy.All value) {
        if (allBuilder_ == null) {
          if (policyChoiceCase_ == 2 &&
              policyChoice_ != ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance()) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.All.newBuilder((ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            policyChoice_ = value;
          }
          onChanged();
        } else {
          if (policyChoiceCase_ == 2) {
            allBuilder_.mergeFrom(value);
          }
          allBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 2;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public Builder clearAll() {
        if (allBuilder_ == null) {
          if (policyChoiceCase_ == 2) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
            onChanged();
          }
        } else {
          if (policyChoiceCase_ == 2) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
          }
          allBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.All.Builder getAllBuilder() {
        return getAllFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder getAllOrBuilder() {
        if ((policyChoiceCase_ == 2) && (allBuilder_ != null)) {
          return allBuilder_.getMessageOrBuilder();
        } else {
          if (policyChoiceCase_ == 2) {
            return (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: All all
       *&#64;&#64;
       *&#64;&#64;       Serve all versions of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.All all = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.All, ModelConfigOuterClass.ModelVersionPolicy.All.Builder, ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder>
          getAllFieldBuilder() {
        if (allBuilder_ == null) {
          if (!(policyChoiceCase_ == 2)) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.All.getDefaultInstance();
          }
          allBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelVersionPolicy.All, ModelConfigOuterClass.ModelVersionPolicy.All.Builder, ModelConfigOuterClass.ModelVersionPolicy.AllOrBuilder>(
                  (ModelConfigOuterClass.ModelVersionPolicy.All) policyChoice_,
                  getParentForChildren(),
                  isClean());
          policyChoice_ = null;
        }
        policyChoiceCase_ = 2;
        onChanged();;
        return allBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.Specific, ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder, ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder> specificBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.Specific getSpecific() {
        if (specificBuilder_ == null) {
          if (policyChoiceCase_ == 3) {
            return (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
        } else {
          if (policyChoiceCase_ == 3) {
            return specificBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public Builder setSpecific(ModelConfigOuterClass.ModelVersionPolicy.Specific value) {
        if (specificBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          policyChoice_ = value;
          onChanged();
        } else {
          specificBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public Builder setSpecific(
          ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder builderForValue) {
        if (specificBuilder_ == null) {
          policyChoice_ = builderForValue.build();
          onChanged();
        } else {
          specificBuilder_.setMessage(builderForValue.build());
        }
        policyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public Builder mergeSpecific(ModelConfigOuterClass.ModelVersionPolicy.Specific value) {
        if (specificBuilder_ == null) {
          if (policyChoiceCase_ == 3 &&
              policyChoice_ != ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance()) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.Specific.newBuilder((ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            policyChoice_ = value;
          }
          onChanged();
        } else {
          if (policyChoiceCase_ == 3) {
            specificBuilder_.mergeFrom(value);
          }
          specificBuilder_.setMessage(value);
        }
        policyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public Builder clearSpecific() {
        if (specificBuilder_ == null) {
          if (policyChoiceCase_ == 3) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
            onChanged();
          }
        } else {
          if (policyChoiceCase_ == 3) {
            policyChoiceCase_ = 0;
            policyChoice_ = null;
          }
          specificBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder getSpecificBuilder() {
        return getSpecificFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder getSpecificOrBuilder() {
        if ((policyChoiceCase_ == 3) && (specificBuilder_ != null)) {
          return specificBuilder_.getMessageOrBuilder();
        } else {
          if (policyChoiceCase_ == 3) {
            return (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_;
          }
          return ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Specific specific
       *&#64;&#64;
       *&#64;&#64;       Serve only specific version(s) of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy.Specific specific = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy.Specific, ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder, ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder>
          getSpecificFieldBuilder() {
        if (specificBuilder_ == null) {
          if (!(policyChoiceCase_ == 3)) {
            policyChoice_ = ModelConfigOuterClass.ModelVersionPolicy.Specific.getDefaultInstance();
          }
          specificBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelVersionPolicy.Specific, ModelConfigOuterClass.ModelVersionPolicy.Specific.Builder, ModelConfigOuterClass.ModelVersionPolicy.SpecificOrBuilder>(
                  (ModelConfigOuterClass.ModelVersionPolicy.Specific) policyChoice_,
                  getParentForChildren(),
                  isClean());
          policyChoice_ = null;
        }
        policyChoiceCase_ = 3;
        onChanged();;
        return specificBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelVersionPolicy)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelVersionPolicy)
    private static final ModelConfigOuterClass.ModelVersionPolicy DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelVersionPolicy();
    }

    public static ModelConfigOuterClass.ModelVersionPolicy getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelVersionPolicy>
        PARSER = new com.google.protobuf.AbstractParser<ModelVersionPolicy>() {
      public ModelVersionPolicy parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelVersionPolicy(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelVersionPolicy> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelVersionPolicy> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelVersionPolicy getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelOptimizationPolicyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    boolean hasGraph();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.Graph getGraph();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder getGraphOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelPriority priority
     *&#64;&#64;
     *&#64;&#64;     The priority setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
     */
    int getPriorityValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelPriority priority
     *&#64;&#64;
     *&#64;&#64;     The priority setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority getPriority();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    boolean hasCuda();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getCuda();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder getCudaOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    boolean hasExecutionAccelerators();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getExecutionAccelerators();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder getExecutionAcceleratorsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    boolean hasInputPinnedMemory();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getInputPinnedMemory();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getInputPinnedMemoryOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    boolean hasOutputPinnedMemory();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getOutputPinnedMemory();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getOutputPinnedMemoryOrBuilder();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelOptimizationPolicy
   *&#64;&#64;
   *&#64;&#64;   Optimization settings for a model. These settings control if/how a
   *&#64;&#64;   model is optimized and prioritized by the backend framework when
   *&#64;&#64;   it is loaded.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelOptimizationPolicy}
   */
  public  static final class ModelOptimizationPolicy extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy)
      ModelOptimizationPolicyOrBuilder {
    // Use ModelOptimizationPolicy.newBuilder() to construct.
    private ModelOptimizationPolicy(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelOptimizationPolicy() {
      priority_ = 0;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelOptimizationPolicy(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder subBuilder = null;
              if (graph_ != null) {
                subBuilder = graph_.toBuilder();
              }
              graph_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.Graph.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(graph_);
                graph_ = subBuilder.buildPartial();
              }

              break;
            }
            case 16: {
              int rawValue = input.readEnum();

              priority_ = rawValue;
              break;
            }
            case 26: {
              ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder subBuilder = null;
              if (cuda_ != null) {
                subBuilder = cuda_.toBuilder();
              }
              cuda_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(cuda_);
                cuda_ = subBuilder.buildPartial();
              }

              break;
            }
            case 34: {
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder subBuilder = null;
              if (executionAccelerators_ != null) {
                subBuilder = executionAccelerators_.toBuilder();
              }
              executionAccelerators_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(executionAccelerators_);
                executionAccelerators_ = subBuilder.buildPartial();
              }

              break;
            }
            case 42: {
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder subBuilder = null;
              if (inputPinnedMemory_ != null) {
                subBuilder = inputPinnedMemory_.toBuilder();
              }
              inputPinnedMemory_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(inputPinnedMemory_);
                inputPinnedMemory_ = subBuilder.buildPartial();
              }

              break;
            }
            case 50: {
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder subBuilder = null;
              if (outputPinnedMemory_ != null) {
                subBuilder = outputPinnedMemory_.toBuilder();
              }
              outputPinnedMemory_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(outputPinnedMemory_);
                outputPinnedMemory_ = subBuilder.buildPartial();
              }

              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelOptimizationPolicy.class, ModelConfigOuterClass.ModelOptimizationPolicy.Builder.class);
    }

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:enum:: ModelPriority
     *&#64;&#64;
     *&#64;&#64;     Model priorities. A model will be given scheduling and execution
     *&#64;&#64;     preference over models at lower priorities. Current model
     *&#64;&#64;     priorities only work for TensorRT models.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf enum {@code inference.ModelOptimizationPolicy.ModelPriority}
     */
    public enum ModelPriority
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_DEFAULT = 0
       *&#64;&#64;
       *&#64;&#64;       The default model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_DEFAULT = 0;</code>
       */
      PRIORITY_DEFAULT(0),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_MAX = 1
       *&#64;&#64;
       *&#64;&#64;       The maximum model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_MAX = 1;</code>
       */
      PRIORITY_MAX(1),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_MIN = 2
       *&#64;&#64;
       *&#64;&#64;       The minimum model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_MIN = 2;</code>
       */
      PRIORITY_MIN(2),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_DEFAULT = 0
       *&#64;&#64;
       *&#64;&#64;       The default model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_DEFAULT = 0;</code>
       */
      public static final int PRIORITY_DEFAULT_VALUE = 0;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_MAX = 1
       *&#64;&#64;
       *&#64;&#64;       The maximum model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_MAX = 1;</code>
       */
      public static final int PRIORITY_MAX_VALUE = 1;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: ModelPriority::PRIORITY_MIN = 2
       *&#64;&#64;
       *&#64;&#64;       The minimum model priority.
       *&#64;&#64;
       * </pre>
       *
       * <code>PRIORITY_MIN = 2;</code>
       */
      public static final int PRIORITY_MIN_VALUE = 2;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static ModelPriority valueOf(int value) {
        return forNumber(value);
      }

      public static ModelPriority forNumber(int value) {
        switch (value) {
          case 0: return PRIORITY_DEFAULT;
          case 1: return PRIORITY_MAX;
          case 2: return PRIORITY_MIN;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<ModelPriority>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          ModelPriority> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<ModelPriority>() {
              public ModelPriority findValueByNumber(int number) {
                return ModelPriority.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return ModelConfigOuterClass.ModelOptimizationPolicy.getDescriptor().getEnumTypes().get(0);
      }

      private static final ModelPriority[] VALUES = values();

      public static ModelPriority valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private ModelPriority(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:inference.ModelOptimizationPolicy.ModelPriority)
    }

    public interface GraphOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy.Graph)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 level
       *&#64;&#64;
       *&#64;&#64;       The optimization level. Defaults to 0 (zero) if not specified.
       *&#64;&#64;
       *&#64;&#64;         - -1: Disabled
       *&#64;&#64;         -  0: Framework default
       *&#64;&#64;         -  1+: Enable optimization level (greater values indicate
       *&#64;&#64;            higher optimization levels)
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 level = 1;</code>
       */
      int getLevel();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message Graph
     *&#64;&#64;
     *&#64;&#64;     Enable generic graph optimization of the model. If not specified
     *&#64;&#64;     the framework's default level of optimization is used. Supports
     *&#64;&#64;     TensorFlow graphdef and savedmodel and Onnx models. For TensorFlow
     *&#64;&#64;     causes XLA to be enabled/disabled for the model. For Onnx defaults
     *&#64;&#64;     to enabling all optimizations, -1 enables only basic optimizations,
     *&#64;&#64;     +1 enables only basic and extended optimizations.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOptimizationPolicy.Graph}
     */
    public  static final class Graph extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy.Graph)
        GraphOrBuilder {
      // Use Graph.newBuilder() to construct.
      private Graph(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Graph() {
        level_ = 0;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Graph(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {

                level_ = input.readInt32();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Graph_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Graph_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOptimizationPolicy.Graph.class, ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder.class);
      }

      public static final int LEVEL_FIELD_NUMBER = 1;
      private int level_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 level
       *&#64;&#64;
       *&#64;&#64;       The optimization level. Defaults to 0 (zero) if not specified.
       *&#64;&#64;
       *&#64;&#64;         - -1: Disabled
       *&#64;&#64;         -  0: Framework default
       *&#64;&#64;         -  1+: Enable optimization level (greater values indicate
       *&#64;&#64;            higher optimization levels)
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 level = 1;</code>
       */
      public int getLevel() {
        return level_;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (level_ != 0) {
          output.writeInt32(1, level_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (level_ != 0) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(1, level_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy.Graph)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelOptimizationPolicy.Graph other = (ModelConfigOuterClass.ModelOptimizationPolicy.Graph) obj;

        boolean result = true;
        result = result && (getLevel()
            == other.getLevel());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + LEVEL_FIELD_NUMBER;
        hash = (53 * hash) + getLevel();
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy.Graph prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message Graph
       *&#64;&#64;
       *&#64;&#64;     Enable generic graph optimization of the model. If not specified
       *&#64;&#64;     the framework's default level of optimization is used. Supports
       *&#64;&#64;     TensorFlow graphdef and savedmodel and Onnx models. For TensorFlow
       *&#64;&#64;     causes XLA to be enabled/disabled for the model. For Onnx defaults
       *&#64;&#64;     to enabling all optimizations, -1 enables only basic optimizations,
       *&#64;&#64;     +1 enables only basic and extended optimizations.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelOptimizationPolicy.Graph}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy.Graph)
          ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Graph_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Graph_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelOptimizationPolicy.Graph.class, ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.Graph.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          level_ = 0;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Graph_descriptor;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Graph getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelOptimizationPolicy.Graph.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Graph build() {
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Graph buildPartial() {
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph result = new ModelConfigOuterClass.ModelOptimizationPolicy.Graph(this);
          result.level_ = level_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy.Graph) {
            return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy.Graph)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy.Graph other) {
          if (other == ModelConfigOuterClass.ModelOptimizationPolicy.Graph.getDefaultInstance()) return this;
          if (other.getLevel() != 0) {
            setLevel(other.getLevel());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy.Graph) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private int level_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 level
         *&#64;&#64;
         *&#64;&#64;       The optimization level. Defaults to 0 (zero) if not specified.
         *&#64;&#64;
         *&#64;&#64;         - -1: Disabled
         *&#64;&#64;         -  0: Framework default
         *&#64;&#64;         -  1+: Enable optimization level (greater values indicate
         *&#64;&#64;            higher optimization levels)
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 level = 1;</code>
         */
        public int getLevel() {
          return level_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 level
         *&#64;&#64;
         *&#64;&#64;       The optimization level. Defaults to 0 (zero) if not specified.
         *&#64;&#64;
         *&#64;&#64;         - -1: Disabled
         *&#64;&#64;         -  0: Framework default
         *&#64;&#64;         -  1+: Enable optimization level (greater values indicate
         *&#64;&#64;            higher optimization levels)
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 level = 1;</code>
         */
        public Builder setLevel(int value) {

          level_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 level
         *&#64;&#64;
         *&#64;&#64;       The optimization level. Defaults to 0 (zero) if not specified.
         *&#64;&#64;
         *&#64;&#64;         - -1: Disabled
         *&#64;&#64;         -  0: Framework default
         *&#64;&#64;         -  1+: Enable optimization level (greater values indicate
         *&#64;&#64;            higher optimization levels)
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 level = 1;</code>
         */
        public Builder clearLevel() {

          level_ = 0;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy.Graph)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Graph)
      private static final ModelConfigOuterClass.ModelOptimizationPolicy.Graph DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy.Graph();
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.Graph getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Graph>
          PARSER = new com.google.protobuf.AbstractParser<Graph>() {
        public Graph parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Graph(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Graph> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Graph> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy.Graph getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface CudaOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy.Cuda)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool graphs
       *&#64;&#64;
       *&#64;&#64;       Use CUDA graphs API to capture model operations and execute
       *&#64;&#64;       them more efficiently. Default value is false.
       *&#64;&#64;       Currently only recognized by TensorRT backend.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool graphs = 1;</code>
       */
      boolean getGraphs();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool busy_wait_events
       *&#64;&#64;
       *&#64;&#64;       Use busy-waiting to synchronize CUDA events to achieve minimum
       *&#64;&#64;       latency from event complete to host thread to be notified, with
       *&#64;&#64;       the cost of high CPU load. Default value is false.
       *&#64;&#64;       Currently only recognized by TensorRT backend.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool busy_wait_events = 2;</code>
       */
      boolean getBusyWaitEvents();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message Cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOptimizationPolicy.Cuda}
     */
    public  static final class Cuda extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy.Cuda)
        CudaOrBuilder {
      // Use Cuda.newBuilder() to construct.
      private Cuda(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Cuda() {
        graphs_ = false;
        busyWaitEvents_ = false;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Cuda(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {

                graphs_ = input.readBool();
                break;
              }
              case 16: {

                busyWaitEvents_ = input.readBool();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Cuda_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.class, ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder.class);
      }

      public static final int GRAPHS_FIELD_NUMBER = 1;
      private boolean graphs_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool graphs
       *&#64;&#64;
       *&#64;&#64;       Use CUDA graphs API to capture model operations and execute
       *&#64;&#64;       them more efficiently. Default value is false.
       *&#64;&#64;       Currently only recognized by TensorRT backend.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool graphs = 1;</code>
       */
      public boolean getGraphs() {
        return graphs_;
      }

      public static final int BUSY_WAIT_EVENTS_FIELD_NUMBER = 2;
      private boolean busyWaitEvents_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool busy_wait_events
       *&#64;&#64;
       *&#64;&#64;       Use busy-waiting to synchronize CUDA events to achieve minimum
       *&#64;&#64;       latency from event complete to host thread to be notified, with
       *&#64;&#64;       the cost of high CPU load. Default value is false.
       *&#64;&#64;       Currently only recognized by TensorRT backend.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool busy_wait_events = 2;</code>
       */
      public boolean getBusyWaitEvents() {
        return busyWaitEvents_;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (graphs_ != false) {
          output.writeBool(1, graphs_);
        }
        if (busyWaitEvents_ != false) {
          output.writeBool(2, busyWaitEvents_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (graphs_ != false) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(1, graphs_);
        }
        if (busyWaitEvents_ != false) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(2, busyWaitEvents_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy.Cuda)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelOptimizationPolicy.Cuda other = (ModelConfigOuterClass.ModelOptimizationPolicy.Cuda) obj;

        boolean result = true;
        result = result && (getGraphs()
            == other.getGraphs());
        result = result && (getBusyWaitEvents()
            == other.getBusyWaitEvents());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + GRAPHS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getGraphs());
        hash = (37 * hash) + BUSY_WAIT_EVENTS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getBusyWaitEvents());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy.Cuda prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message Cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelOptimizationPolicy.Cuda}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy.Cuda)
          ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Cuda_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.class, ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          graphs_ = false;

          busyWaitEvents_ = false;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda build() {
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda buildPartial() {
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda result = new ModelConfigOuterClass.ModelOptimizationPolicy.Cuda(this);
          result.graphs_ = graphs_;
          result.busyWaitEvents_ = busyWaitEvents_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy.Cuda) {
            return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy.Cuda)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy.Cuda other) {
          if (other == ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.getDefaultInstance()) return this;
          if (other.getGraphs() != false) {
            setGraphs(other.getGraphs());
          }
          if (other.getBusyWaitEvents() != false) {
            setBusyWaitEvents(other.getBusyWaitEvents());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy.Cuda) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private boolean graphs_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool graphs
         *&#64;&#64;
         *&#64;&#64;       Use CUDA graphs API to capture model operations and execute
         *&#64;&#64;       them more efficiently. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool graphs = 1;</code>
         */
        public boolean getGraphs() {
          return graphs_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool graphs
         *&#64;&#64;
         *&#64;&#64;       Use CUDA graphs API to capture model operations and execute
         *&#64;&#64;       them more efficiently. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool graphs = 1;</code>
         */
        public Builder setGraphs(boolean value) {

          graphs_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool graphs
         *&#64;&#64;
         *&#64;&#64;       Use CUDA graphs API to capture model operations and execute
         *&#64;&#64;       them more efficiently. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool graphs = 1;</code>
         */
        public Builder clearGraphs() {

          graphs_ = false;
          onChanged();
          return this;
        }

        private boolean busyWaitEvents_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool busy_wait_events
         *&#64;&#64;
         *&#64;&#64;       Use busy-waiting to synchronize CUDA events to achieve minimum
         *&#64;&#64;       latency from event complete to host thread to be notified, with
         *&#64;&#64;       the cost of high CPU load. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool busy_wait_events = 2;</code>
         */
        public boolean getBusyWaitEvents() {
          return busyWaitEvents_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool busy_wait_events
         *&#64;&#64;
         *&#64;&#64;       Use busy-waiting to synchronize CUDA events to achieve minimum
         *&#64;&#64;       latency from event complete to host thread to be notified, with
         *&#64;&#64;       the cost of high CPU load. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool busy_wait_events = 2;</code>
         */
        public Builder setBusyWaitEvents(boolean value) {

          busyWaitEvents_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool busy_wait_events
         *&#64;&#64;
         *&#64;&#64;       Use busy-waiting to synchronize CUDA events to achieve minimum
         *&#64;&#64;       latency from event complete to host thread to be notified, with
         *&#64;&#64;       the cost of high CPU load. Default value is false.
         *&#64;&#64;       Currently only recognized by TensorRT backend.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool busy_wait_events = 2;</code>
         */
        public Builder clearBusyWaitEvents() {

          busyWaitEvents_ = false;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy.Cuda)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.Cuda)
      private static final ModelConfigOuterClass.ModelOptimizationPolicy.Cuda DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy.Cuda();
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Cuda>
          PARSER = new com.google.protobuf.AbstractParser<Cuda>() {
        public Cuda parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Cuda(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Cuda> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Cuda> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface ExecutionAcceleratorsOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy.ExecutionAccelerators)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      java.util.List<ExecutionAccelerators.Accelerator>
          getGpuExecutionAcceleratorList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getGpuExecutionAccelerator(int index);
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      int getGpuExecutionAcceleratorCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      java.util.List<? extends ExecutionAccelerators.AcceleratorOrBuilder>
          getGpuExecutionAcceleratorOrBuilderList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getGpuExecutionAcceleratorOrBuilder(
          int index);

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      java.util.List<ExecutionAccelerators.Accelerator>
          getCpuExecutionAcceleratorList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getCpuExecutionAccelerator(int index);
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      int getCpuExecutionAcceleratorCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      java.util.List<? extends ExecutionAccelerators.AcceleratorOrBuilder>
          getCpuExecutionAcceleratorOrBuilderList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getCpuExecutionAcceleratorOrBuilder(
          int index);
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message ExecutionAccelerators
     *&#64;&#64;
     *&#64;&#64;     Specify the preferred execution accelerators to be used to execute
     *&#64;&#64;     the model. Currently only recognized by ONNX Runtime backend and
     *&#64;&#64;     TensorFlow backend.
     *&#64;&#64;
     *&#64;&#64;     For ONNX Runtime backend, it will deploy the model with the execution
     *&#64;&#64;     accelerators by priority, the priority is determined based on the
     *&#64;&#64;     order that they are set, i.e. the provider at the front has highest
     *&#64;&#64;     priority. Overall, the priority will be in the following order:
     *&#64;&#64;         &lt;gpu_execution_accelerator&gt; (if instance is on GPU)
     *&#64;&#64;         CUDA Execution Provider     (if instance is on GPU)
     *&#64;&#64;         &lt;cpu_execution_accelerator&gt;
     *&#64;&#64;         Default CPU Execution Provider
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOptimizationPolicy.ExecutionAccelerators}
     */
    public  static final class ExecutionAccelerators extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy.ExecutionAccelerators)
        ExecutionAcceleratorsOrBuilder {
      // Use ExecutionAccelerators.newBuilder() to construct.
      private ExecutionAccelerators(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private ExecutionAccelerators() {
        gpuExecutionAccelerator_ = java.util.Collections.emptyList();
        cpuExecutionAccelerator_ = java.util.Collections.emptyList();
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private ExecutionAccelerators(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                  gpuExecutionAccelerator_ = new java.util.ArrayList<Accelerator>();
                  mutable_bitField0_ |= 0x00000001;
                }
                gpuExecutionAccelerator_.add(
                    input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.parser(), extensionRegistry));
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  cpuExecutionAccelerator_ = new java.util.ArrayList<Accelerator>();
                  mutable_bitField0_ |= 0x00000002;
                }
                cpuExecutionAccelerator_.add(
                    input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.parser(), extensionRegistry));
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
            gpuExecutionAccelerator_ = java.util.Collections.unmodifiableList(gpuExecutionAccelerator_);
          }
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            cpuExecutionAccelerator_ = java.util.Collections.unmodifiableList(cpuExecutionAccelerator_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.class, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder.class);
      }

      public interface AcceleratorOrBuilder extends
          // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
          com.google.protobuf.MessageOrBuilder {

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the execution accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        String getName();
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the execution accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        com.google.protobuf.ByteString
            getNameBytes();

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */
        int getParametersCount();
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */
        boolean containsParameters(
            String key);
        /**
         * Use {@link #getParametersMap()} instead.
         */
        @Deprecated
        java.util.Map<String, String>
        getParameters();
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */
        java.util.Map<String, String>
        getParametersMap();
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        String getParametersOrDefault(
            String key,
            String defaultValue);
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        String getParametersOrThrow(
            String key);
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message Accelerator
       *&#64;&#64;
       *&#64;&#64;     Specify the accelerator to be used to execute the model.
       *&#64;&#64;     Accelerator with the same name may accept different parameters
       *&#64;&#64;     depending on the backends.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator}
       */
      public  static final class Accelerator extends
          com.google.protobuf.GeneratedMessageV3 implements
          // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
          AcceleratorOrBuilder {
        // Use Accelerator.newBuilder() to construct.
        private Accelerator(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
          super(builder);
        }
        private Accelerator() {
          name_ = "";
        }

        @Override
        public final com.google.protobuf.UnknownFieldSet
        getUnknownFields() {
          return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
        }
        private Accelerator(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          this();
          int mutable_bitField0_ = 0;
          try {
            boolean done = false;
            while (!done) {
              int tag = input.readTag();
              switch (tag) {
                case 0:
                  done = true;
                  break;
                default: {
                  if (!input.skipField(tag)) {
                    done = true;
                  }
                  break;
                }
                case 10: {
                  String s = input.readStringRequireUtf8();

                  name_ = s;
                  break;
                }
                case 18: {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    parameters_ = com.google.protobuf.MapField.newMapField(
                        ParametersDefaultEntryHolder.defaultEntry);
                    mutable_bitField0_ |= 0x00000002;
                  }
                  com.google.protobuf.MapEntry<String, String>
                  parameters = input.readMessage(
                      ParametersDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
                  parameters_.getMutableMap().put(parameters.getKey(), parameters.getValue());
                  break;
                }
              }
            }
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            throw e.setUnfinishedMessage(this);
          } catch (java.io.IOException e) {
            throw new com.google.protobuf.InvalidProtocolBufferException(
                e).setUnfinishedMessage(this);
          } finally {
            makeExtensionsImmutable();
          }
        }
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor;
        }

        @SuppressWarnings({"rawtypes"})
        protected com.google.protobuf.MapField internalGetMapField(
            int number) {
          switch (number) {
            case 2:
              return internalGetParameters();
            default:
              throw new RuntimeException(
                  "Invalid map field number: " + number);
          }
        }
        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.class, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder.class);
        }

        private int bitField0_;
        public static final int NAME_FIELD_NUMBER = 1;
        private volatile Object name_;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the execution accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public String getName() {
          Object ref = name_;
          if (ref instanceof String) {
            return (String) ref;
          } else {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            String s = bs.toStringUtf8();
            name_ = s;
            return s;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the execution accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public com.google.protobuf.ByteString
            getNameBytes() {
          Object ref = name_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8(
                    (String) ref);
            name_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }

        public static final int PARAMETERS_FIELD_NUMBER = 2;
        private static final class ParametersDefaultEntryHolder {
          static final com.google.protobuf.MapEntry<
              String, String> defaultEntry =
                  com.google.protobuf.MapEntry
                  .<String, String>newDefaultInstance(
                      ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_descriptor,
                      com.google.protobuf.WireFormat.FieldType.STRING,
                      "",
                      com.google.protobuf.WireFormat.FieldType.STRING,
                      "");
        }
        private com.google.protobuf.MapField<
            String, String> parameters_;
        private com.google.protobuf.MapField<String, String>
        internalGetParameters() {
          if (parameters_ == null) {
            return com.google.protobuf.MapField.emptyMapField(
                ParametersDefaultEntryHolder.defaultEntry);
          }
          return parameters_;
        }

        public int getParametersCount() {
          return internalGetParameters().getMap().size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        public boolean containsParameters(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          return internalGetParameters().getMap().containsKey(key);
        }
        /**
         * Use {@link #getParametersMap()} instead.
         */
        @Deprecated
        public java.util.Map<String, String> getParameters() {
          return getParametersMap();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        public java.util.Map<String, String> getParametersMap() {
          return internalGetParameters().getMap();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        public String getParametersOrDefault(
            String key,
            String defaultValue) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetParameters().getMap();
          return map.containsKey(key) ? map.get(key) : defaultValue;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
         *&#64;&#64;
         *&#64;&#64;       Additional paremeters used to configure the accelerator.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; parameters = 2;</code>
         */

        public String getParametersOrThrow(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetParameters().getMap();
          if (!map.containsKey(key)) {
            throw new IllegalArgumentException();
          }
          return map.get(key);
        }

        private byte memoizedIsInitialized = -1;
        public final boolean isInitialized() {
          byte isInitialized = memoizedIsInitialized;
          if (isInitialized == 1) return true;
          if (isInitialized == 0) return false;

          memoizedIsInitialized = 1;
          return true;
        }

        public void writeTo(com.google.protobuf.CodedOutputStream output)
                            throws java.io.IOException {
          if (!getNameBytes().isEmpty()) {
            com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
          }
          for (java.util.Map.Entry<String, String> entry
               : internalGetParameters().getMap().entrySet()) {
            com.google.protobuf.MapEntry<String, String>
            parameters = ParametersDefaultEntryHolder.defaultEntry.newBuilderForType()
                .setKey(entry.getKey())
                .setValue(entry.getValue())
                .build();
            output.writeMessage(2, parameters);
          }
        }

        public int getSerializedSize() {
          int size = memoizedSize;
          if (size != -1) return size;

          size = 0;
          if (!getNameBytes().isEmpty()) {
            size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
          }
          for (java.util.Map.Entry<String, String> entry
               : internalGetParameters().getMap().entrySet()) {
            com.google.protobuf.MapEntry<String, String>
            parameters = ParametersDefaultEntryHolder.defaultEntry.newBuilderForType()
                .setKey(entry.getKey())
                .setValue(entry.getValue())
                .build();
            size += com.google.protobuf.CodedOutputStream
                .computeMessageSize(2, parameters);
          }
          memoizedSize = size;
          return size;
        }

        private static final long serialVersionUID = 0L;
        @Override
        public boolean equals(final Object obj) {
          if (obj == this) {
           return true;
          }
          if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)) {
            return super.equals(obj);
          }
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator other = (ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator) obj;

          boolean result = true;
          result = result && getName()
              .equals(other.getName());
          result = result && internalGetParameters().equals(
              other.internalGetParameters());
          return result;
        }

        @Override
        public int hashCode() {
          if (memoizedHashCode != 0) {
            return memoizedHashCode;
          }
          int hash = 41;
          hash = (19 * hash) + getDescriptorForType().hashCode();
          hash = (37 * hash) + NAME_FIELD_NUMBER;
          hash = (53 * hash) + getName().hashCode();
          if (!internalGetParameters().getMap().isEmpty()) {
            hash = (37 * hash) + PARAMETERS_FIELD_NUMBER;
            hash = (53 * hash) + internalGetParameters().hashCode();
          }
          hash = (29 * hash) + unknownFields.hashCode();
          memoizedHashCode = hash;
          return hash;
        }

        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            com.google.protobuf.ByteString data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            com.google.protobuf.ByteString data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(byte[] data)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            byte[] data,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
          return PARSER.parseFrom(data, extensionRegistry);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(java.io.InputStream input)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input, extensionRegistry);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseDelimitedFrom(java.io.InputStream input)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseDelimitedWithIOException(PARSER, input);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseDelimitedFrom(
            java.io.InputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            com.google.protobuf.CodedInputStream input)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input);
        }
        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parseFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          return com.google.protobuf.GeneratedMessageV3
              .parseWithIOException(PARSER, input, extensionRegistry);
        }

        public Builder newBuilderForType() { return newBuilder(); }
        public static Builder newBuilder() {
          return DEFAULT_INSTANCE.toBuilder();
        }
        public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator prototype) {
          return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
        }
        public Builder toBuilder() {
          return this == DEFAULT_INSTANCE
              ? new Builder() : new Builder().mergeFrom(this);
        }

        @Override
        protected Builder newBuilderForType(
            BuilderParent parent) {
          Builder builder = new Builder(parent);
          return builder;
        }
        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;  .. cpp:var:: message Accelerator
         *&#64;&#64;
         *&#64;&#64;     Specify the accelerator to be used to execute the model.
         *&#64;&#64;     Accelerator with the same name may accept different parameters
         *&#64;&#64;     depending on the backends.
         *&#64;&#64;
         * </pre>
         *
         * Protobuf type {@code inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator}
         */
        public static final class Builder extends
            com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
            // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder {
          public static final com.google.protobuf.Descriptors.Descriptor
              getDescriptor() {
            return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor;
          }

          @SuppressWarnings({"rawtypes"})
          protected com.google.protobuf.MapField internalGetMapField(
              int number) {
            switch (number) {
              case 2:
                return internalGetParameters();
              default:
                throw new RuntimeException(
                    "Invalid map field number: " + number);
            }
          }
          @SuppressWarnings({"rawtypes"})
          protected com.google.protobuf.MapField internalGetMutableMapField(
              int number) {
            switch (number) {
              case 2:
                return internalGetMutableParameters();
              default:
                throw new RuntimeException(
                    "Invalid map field number: " + number);
            }
          }
          protected FieldAccessorTable
              internalGetFieldAccessorTable() {
            return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_fieldAccessorTable
                .ensureFieldAccessorsInitialized(
                    ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.class, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder.class);
          }

          // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.newBuilder()
          private Builder() {
            maybeForceBuilderInitialization();
          }

          private Builder(
              BuilderParent parent) {
            super(parent);
            maybeForceBuilderInitialization();
          }
          private void maybeForceBuilderInitialization() {
            if (com.google.protobuf.GeneratedMessageV3
                    .alwaysUseFieldBuilders) {
            }
          }
          public Builder clear() {
            super.clear();
            name_ = "";

            internalGetMutableParameters().clear();
            return this;
          }

          public com.google.protobuf.Descriptors.Descriptor
              getDescriptorForType() {
            return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor;
          }

          public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getDefaultInstanceForType() {
            return ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance();
          }

          public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator build() {
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator result = buildPartial();
            if (!result.isInitialized()) {
              throw newUninitializedMessageException(result);
            }
            return result;
          }

          public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator buildPartial() {
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator result = new ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator(this);
            int from_bitField0_ = bitField0_;
            int to_bitField0_ = 0;
            result.name_ = name_;
            result.parameters_ = internalGetParameters();
            result.parameters_.makeImmutable();
            result.bitField0_ = to_bitField0_;
            onBuilt();
            return result;
          }

          public Builder clone() {
            return (Builder) super.clone();
          }
          public Builder setField(
              com.google.protobuf.Descriptors.FieldDescriptor field,
              Object value) {
            return (Builder) super.setField(field, value);
          }
          public Builder clearField(
              com.google.protobuf.Descriptors.FieldDescriptor field) {
            return (Builder) super.clearField(field);
          }
          public Builder clearOneof(
              com.google.protobuf.Descriptors.OneofDescriptor oneof) {
            return (Builder) super.clearOneof(oneof);
          }
          public Builder setRepeatedField(
              com.google.protobuf.Descriptors.FieldDescriptor field,
              int index, Object value) {
            return (Builder) super.setRepeatedField(field, index, value);
          }
          public Builder addRepeatedField(
              com.google.protobuf.Descriptors.FieldDescriptor field,
              Object value) {
            return (Builder) super.addRepeatedField(field, value);
          }
          public Builder mergeFrom(com.google.protobuf.Message other) {
            if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator) {
              return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)other);
            } else {
              super.mergeFrom(other);
              return this;
            }
          }

          public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator other) {
            if (other == ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance()) return this;
            if (!other.getName().isEmpty()) {
              name_ = other.name_;
              onChanged();
            }
            internalGetMutableParameters().mergeFrom(
                other.internalGetParameters());
            onChanged();
            return this;
          }

          public final boolean isInitialized() {
            return true;
          }

          public Builder mergeFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws java.io.IOException {
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator parsedMessage = null;
            try {
              parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
            } catch (com.google.protobuf.InvalidProtocolBufferException e) {
              parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator) e.getUnfinishedMessage();
              throw e.unwrapIOException();
            } finally {
              if (parsedMessage != null) {
                mergeFrom(parsedMessage);
              }
            }
            return this;
          }
          private int bitField0_;

          private Object name_ = "";
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: string name
           *&#64;&#64;
           *&#64;&#64;       The name of the execution accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>optional string name = 1;</code>
           */
          public String getName() {
            Object ref = name_;
            if (!(ref instanceof String)) {
              com.google.protobuf.ByteString bs =
                  (com.google.protobuf.ByteString) ref;
              String s = bs.toStringUtf8();
              name_ = s;
              return s;
            } else {
              return (String) ref;
            }
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: string name
           *&#64;&#64;
           *&#64;&#64;       The name of the execution accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>optional string name = 1;</code>
           */
          public com.google.protobuf.ByteString
              getNameBytes() {
            Object ref = name_;
            if (ref instanceof String) {
              com.google.protobuf.ByteString b =
                  com.google.protobuf.ByteString.copyFromUtf8(
                      (String) ref);
              name_ = b;
              return b;
            } else {
              return (com.google.protobuf.ByteString) ref;
            }
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: string name
           *&#64;&#64;
           *&#64;&#64;       The name of the execution accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>optional string name = 1;</code>
           */
          public Builder setName(
              String value) {
            if (value == null) {
    throw new NullPointerException();
  }

            name_ = value;
            onChanged();
            return this;
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: string name
           *&#64;&#64;
           *&#64;&#64;       The name of the execution accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>optional string name = 1;</code>
           */
          public Builder clearName() {

            name_ = getDefaultInstance().getName();
            onChanged();
            return this;
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: string name
           *&#64;&#64;
           *&#64;&#64;       The name of the execution accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>optional string name = 1;</code>
           */
          public Builder setNameBytes(
              com.google.protobuf.ByteString value) {
            if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

            name_ = value;
            onChanged();
            return this;
          }

          private com.google.protobuf.MapField<
              String, String> parameters_;
          private com.google.protobuf.MapField<String, String>
          internalGetParameters() {
            if (parameters_ == null) {
              return com.google.protobuf.MapField.emptyMapField(
                  ParametersDefaultEntryHolder.defaultEntry);
            }
            return parameters_;
          }
          private com.google.protobuf.MapField<String, String>
          internalGetMutableParameters() {
            onChanged();;
            if (parameters_ == null) {
              parameters_ = com.google.protobuf.MapField.newMapField(
                  ParametersDefaultEntryHolder.defaultEntry);
            }
            if (!parameters_.isMutable()) {
              parameters_ = parameters_.copy();
            }
            return parameters_;
          }

          public int getParametersCount() {
            return internalGetParameters().getMap().size();
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public boolean containsParameters(
              String key) {
            if (key == null) { throw new NullPointerException(); }
            return internalGetParameters().getMap().containsKey(key);
          }
          /**
           * Use {@link #getParametersMap()} instead.
           */
          @Deprecated
          public java.util.Map<String, String> getParameters() {
            return getParametersMap();
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public java.util.Map<String, String> getParametersMap() {
            return internalGetParameters().getMap();
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public String getParametersOrDefault(
              String key,
              String defaultValue) {
            if (key == null) { throw new NullPointerException(); }
            java.util.Map<String, String> map =
                internalGetParameters().getMap();
            return map.containsKey(key) ? map.get(key) : defaultValue;
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public String getParametersOrThrow(
              String key) {
            if (key == null) { throw new NullPointerException(); }
            java.util.Map<String, String> map =
                internalGetParameters().getMap();
            if (!map.containsKey(key)) {
              throw new IllegalArgumentException();
            }
            return map.get(key);
          }

          public Builder clearParameters() {
            getMutableParameters().clear();
            return this;
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public Builder removeParameters(
              String key) {
            if (key == null) { throw new NullPointerException(); }
            getMutableParameters().remove(key);
            return this;
          }
          /**
           * Use alternate mutation accessors instead.
           */
          @Deprecated
          public java.util.Map<String, String>
          getMutableParameters() {
            return internalGetMutableParameters().getMutableMap();
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */
          public Builder putParameters(
              String key,
              String value) {
            if (key == null) { throw new NullPointerException(); }
            if (value == null) { throw new NullPointerException(); }
            getMutableParameters().put(key, value);
            return this;
          }
          /**
           * <pre>
           *&#64;&#64;    .. cpp:var:: map&lt;string, string&gt; parameters
           *&#64;&#64;
           *&#64;&#64;       Additional paremeters used to configure the accelerator.
           *&#64;&#64;
           * </pre>
           *
           * <code>map&lt;string, string&gt; parameters = 2;</code>
           */

          public Builder putAllParameters(
              java.util.Map<String, String> values) {
            getMutableParameters().putAll(values);
            return this;
          }
          public final Builder setUnknownFields(
              final com.google.protobuf.UnknownFieldSet unknownFields) {
            return this;
          }

          public final Builder mergeUnknownFields(
              final com.google.protobuf.UnknownFieldSet unknownFields) {
            return this;
          }


          // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
        }

        // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator)
        private static final ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator DEFAULT_INSTANCE;
        static {
          DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator();
        }

        public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getDefaultInstance() {
          return DEFAULT_INSTANCE;
        }

        private static final com.google.protobuf.Parser<Accelerator>
            PARSER = new com.google.protobuf.AbstractParser<Accelerator>() {
          public Accelerator parsePartialFrom(
              com.google.protobuf.CodedInputStream input,
              com.google.protobuf.ExtensionRegistryLite extensionRegistry)
              throws com.google.protobuf.InvalidProtocolBufferException {
              return new Accelerator(input, extensionRegistry);
          }
        };

        public static com.google.protobuf.Parser<Accelerator> parser() {
          return PARSER;
        }

        @Override
        public com.google.protobuf.Parser<Accelerator> getParserForType() {
          return PARSER;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getDefaultInstanceForType() {
          return DEFAULT_INSTANCE;
        }

      }

      public static final int GPU_EXECUTION_ACCELERATOR_FIELD_NUMBER = 1;
      private java.util.List<Accelerator> gpuExecutionAccelerator_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      public java.util.List<Accelerator> getGpuExecutionAcceleratorList() {
        return gpuExecutionAccelerator_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      public java.util.List<? extends AcceleratorOrBuilder>
          getGpuExecutionAcceleratorOrBuilderList() {
        return gpuExecutionAccelerator_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      public int getGpuExecutionAcceleratorCount() {
        return gpuExecutionAccelerator_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getGpuExecutionAccelerator(int index) {
        return gpuExecutionAccelerator_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on GPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
       *&#64;&#64;       "auto_mixed_precision", "gpu_io".
       *&#64;&#64;
       *&#64;&#64;       For "tensorrt", the following parameters can be specified:
       *&#64;&#64;         "precision_mode": The precision used for optimization.
       *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
       *&#64;&#64;
       *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
       *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
       *&#64;&#64;
       *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
       *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
       *&#64;&#64;
       *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
       *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
       *&#64;&#64;
       *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
       *&#64;&#64;       the model will try to use FP16 for better performance.
       *&#64;&#64;       This optimization can not be set with "tensorrt".
       *&#64;&#64;
       *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
       *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
       *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
       *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
       *&#64;&#64;       object will be created on model creation and it will request all
       *&#64;&#64;       outputs for every model execution, which may impact the
       *&#64;&#64;       performance if a request does not require all outputs. This
       *&#64;&#64;       optimization will only take affect if the model instance is
       *&#64;&#64;       created with KIND_GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getGpuExecutionAcceleratorOrBuilder(
          int index) {
        return gpuExecutionAccelerator_.get(index);
      }

      public static final int CPU_EXECUTION_ACCELERATOR_FIELD_NUMBER = 2;
      private java.util.List<Accelerator> cpuExecutionAccelerator_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      public java.util.List<Accelerator> getCpuExecutionAcceleratorList() {
        return cpuExecutionAccelerator_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      public java.util.List<? extends AcceleratorOrBuilder>
          getCpuExecutionAcceleratorOrBuilderList() {
        return cpuExecutionAccelerator_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      public int getCpuExecutionAcceleratorCount() {
        return cpuExecutionAccelerator_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getCpuExecutionAccelerator(int index) {
        return cpuExecutionAccelerator_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
       *&#64;&#64;
       *&#64;&#64;       The preferred execution provider to be used if the model instance
       *&#64;&#64;       is deployed on CPU.
       *&#64;&#64;
       *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
       *&#64;&#64;       and no parameters are required.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getCpuExecutionAcceleratorOrBuilder(
          int index) {
        return cpuExecutionAccelerator_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        for (int i = 0; i < gpuExecutionAccelerator_.size(); i++) {
          output.writeMessage(1, gpuExecutionAccelerator_.get(i));
        }
        for (int i = 0; i < cpuExecutionAccelerator_.size(); i++) {
          output.writeMessage(2, cpuExecutionAccelerator_.get(i));
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        for (int i = 0; i < gpuExecutionAccelerator_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(1, gpuExecutionAccelerator_.get(i));
        }
        for (int i = 0; i < cpuExecutionAccelerator_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, cpuExecutionAccelerator_.get(i));
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators other = (ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators) obj;

        boolean result = true;
        result = result && getGpuExecutionAcceleratorList()
            .equals(other.getGpuExecutionAcceleratorList());
        result = result && getCpuExecutionAcceleratorList()
            .equals(other.getCpuExecutionAcceleratorList());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        if (getGpuExecutionAcceleratorCount() > 0) {
          hash = (37 * hash) + GPU_EXECUTION_ACCELERATOR_FIELD_NUMBER;
          hash = (53 * hash) + getGpuExecutionAcceleratorList().hashCode();
        }
        if (getCpuExecutionAcceleratorCount() > 0) {
          hash = (37 * hash) + CPU_EXECUTION_ACCELERATOR_FIELD_NUMBER;
          hash = (53 * hash) + getCpuExecutionAcceleratorList().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message ExecutionAccelerators
       *&#64;&#64;
       *&#64;&#64;     Specify the preferred execution accelerators to be used to execute
       *&#64;&#64;     the model. Currently only recognized by ONNX Runtime backend and
       *&#64;&#64;     TensorFlow backend.
       *&#64;&#64;
       *&#64;&#64;     For ONNX Runtime backend, it will deploy the model with the execution
       *&#64;&#64;     accelerators by priority, the priority is determined based on the
       *&#64;&#64;     order that they are set, i.e. the provider at the front has highest
       *&#64;&#64;     priority. Overall, the priority will be in the following order:
       *&#64;&#64;         &lt;gpu_execution_accelerator&gt; (if instance is on GPU)
       *&#64;&#64;         CUDA Execution Provider     (if instance is on GPU)
       *&#64;&#64;         &lt;cpu_execution_accelerator&gt;
       *&#64;&#64;         Default CPU Execution Provider
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelOptimizationPolicy.ExecutionAccelerators}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy.ExecutionAccelerators)
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.class, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getGpuExecutionAcceleratorFieldBuilder();
            getCpuExecutionAcceleratorFieldBuilder();
          }
        }
        public Builder clear() {
          super.clear();
          if (gpuExecutionAcceleratorBuilder_ == null) {
            gpuExecutionAccelerator_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            gpuExecutionAcceleratorBuilder_.clear();
          }
          if (cpuExecutionAcceleratorBuilder_ == null) {
            cpuExecutionAccelerator_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            cpuExecutionAcceleratorBuilder_.clear();
          }
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators build() {
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators buildPartial() {
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators result = new ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators(this);
          int from_bitField0_ = bitField0_;
          if (gpuExecutionAcceleratorBuilder_ == null) {
            if (((bitField0_ & 0x00000001) == 0x00000001)) {
              gpuExecutionAccelerator_ = java.util.Collections.unmodifiableList(gpuExecutionAccelerator_);
              bitField0_ = (bitField0_ & ~0x00000001);
            }
            result.gpuExecutionAccelerator_ = gpuExecutionAccelerator_;
          } else {
            result.gpuExecutionAccelerator_ = gpuExecutionAcceleratorBuilder_.build();
          }
          if (cpuExecutionAcceleratorBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              cpuExecutionAccelerator_ = java.util.Collections.unmodifiableList(cpuExecutionAccelerator_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.cpuExecutionAccelerator_ = cpuExecutionAccelerator_;
          } else {
            result.cpuExecutionAccelerator_ = cpuExecutionAcceleratorBuilder_.build();
          }
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators) {
            return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators other) {
          if (other == ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.getDefaultInstance()) return this;
          if (gpuExecutionAcceleratorBuilder_ == null) {
            if (!other.gpuExecutionAccelerator_.isEmpty()) {
              if (gpuExecutionAccelerator_.isEmpty()) {
                gpuExecutionAccelerator_ = other.gpuExecutionAccelerator_;
                bitField0_ = (bitField0_ & ~0x00000001);
              } else {
                ensureGpuExecutionAcceleratorIsMutable();
                gpuExecutionAccelerator_.addAll(other.gpuExecutionAccelerator_);
              }
              onChanged();
            }
          } else {
            if (!other.gpuExecutionAccelerator_.isEmpty()) {
              if (gpuExecutionAcceleratorBuilder_.isEmpty()) {
                gpuExecutionAcceleratorBuilder_.dispose();
                gpuExecutionAcceleratorBuilder_ = null;
                gpuExecutionAccelerator_ = other.gpuExecutionAccelerator_;
                bitField0_ = (bitField0_ & ~0x00000001);
                gpuExecutionAcceleratorBuilder_ =
                  com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getGpuExecutionAcceleratorFieldBuilder() : null;
              } else {
                gpuExecutionAcceleratorBuilder_.addAllMessages(other.gpuExecutionAccelerator_);
              }
            }
          }
          if (cpuExecutionAcceleratorBuilder_ == null) {
            if (!other.cpuExecutionAccelerator_.isEmpty()) {
              if (cpuExecutionAccelerator_.isEmpty()) {
                cpuExecutionAccelerator_ = other.cpuExecutionAccelerator_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureCpuExecutionAcceleratorIsMutable();
                cpuExecutionAccelerator_.addAll(other.cpuExecutionAccelerator_);
              }
              onChanged();
            }
          } else {
            if (!other.cpuExecutionAccelerator_.isEmpty()) {
              if (cpuExecutionAcceleratorBuilder_.isEmpty()) {
                cpuExecutionAcceleratorBuilder_.dispose();
                cpuExecutionAcceleratorBuilder_ = null;
                cpuExecutionAccelerator_ = other.cpuExecutionAccelerator_;
                bitField0_ = (bitField0_ & ~0x00000002);
                cpuExecutionAcceleratorBuilder_ =
                  com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getCpuExecutionAcceleratorFieldBuilder() : null;
              } else {
                cpuExecutionAcceleratorBuilder_.addAllMessages(other.cpuExecutionAccelerator_);
              }
            }
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private java.util.List<Accelerator> gpuExecutionAccelerator_ =
          java.util.Collections.emptyList();
        private void ensureGpuExecutionAcceleratorIsMutable() {
          if (!((bitField0_ & 0x00000001) == 0x00000001)) {
            gpuExecutionAccelerator_ = new java.util.ArrayList<Accelerator>(gpuExecutionAccelerator_);
            bitField0_ |= 0x00000001;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder> gpuExecutionAcceleratorBuilder_;

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public java.util.List<Accelerator> getGpuExecutionAcceleratorList() {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            return java.util.Collections.unmodifiableList(gpuExecutionAccelerator_);
          } else {
            return gpuExecutionAcceleratorBuilder_.getMessageList();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public int getGpuExecutionAcceleratorCount() {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            return gpuExecutionAccelerator_.size();
          } else {
            return gpuExecutionAcceleratorBuilder_.getCount();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getGpuExecutionAccelerator(int index) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            return gpuExecutionAccelerator_.get(index);
          } else {
            return gpuExecutionAcceleratorBuilder_.getMessage(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder setGpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.set(index, value);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder setGpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.set(index, builderForValue.build());
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder addGpuExecutionAccelerator(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.add(value);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder addGpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.add(index, value);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder addGpuExecutionAccelerator(
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.add(builderForValue.build());
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder addGpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.add(index, builderForValue.build());
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder addAllGpuExecutionAccelerator(
            Iterable<? extends Accelerator> values) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            ensureGpuExecutionAcceleratorIsMutable();
            com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, gpuExecutionAccelerator_);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder clearGpuExecutionAccelerator() {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            gpuExecutionAccelerator_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000001);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.clear();
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public Builder removeGpuExecutionAccelerator(int index) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            ensureGpuExecutionAcceleratorIsMutable();
            gpuExecutionAccelerator_.remove(index);
            onChanged();
          } else {
            gpuExecutionAcceleratorBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder getGpuExecutionAcceleratorBuilder(
            int index) {
          return getGpuExecutionAcceleratorFieldBuilder().getBuilder(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getGpuExecutionAcceleratorOrBuilder(
            int index) {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            return gpuExecutionAccelerator_.get(index);  } else {
            return gpuExecutionAcceleratorBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public java.util.List<? extends AcceleratorOrBuilder>
             getGpuExecutionAcceleratorOrBuilderList() {
          if (gpuExecutionAcceleratorBuilder_ != null) {
            return gpuExecutionAcceleratorBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(gpuExecutionAccelerator_);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder addGpuExecutionAcceleratorBuilder() {
          return getGpuExecutionAcceleratorFieldBuilder().addBuilder(
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder addGpuExecutionAcceleratorBuilder(
            int index) {
          return getGpuExecutionAcceleratorFieldBuilder().addBuilder(
              index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator gpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on GPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "tensorrt" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         *&#64;&#64;       For TensorFlow backend, possible values are "tensorrt",
         *&#64;&#64;       "auto_mixed_precision", "gpu_io".
         *&#64;&#64;
         *&#64;&#64;       For "tensorrt", the following parameters can be specified:
         *&#64;&#64;         "precision_mode": The precision used for optimization.
         *&#64;&#64;         Allowed values are "FP32" and "FP16". Default value is "FP32".
         *&#64;&#64;
         *&#64;&#64;         "max_cached_engines": The maximum number of cached TensorRT
         *&#64;&#64;         engines in dynamic TensorRT ops. Default value is 100.
         *&#64;&#64;
         *&#64;&#64;         "minimum_segment_size": The smallest model subgraph that will
         *&#64;&#64;         be considered for optimization by TensorRT. Default value is 3.
         *&#64;&#64;
         *&#64;&#64;         "max_workspace_size_bytes": The maximum GPU memory the model
         *&#64;&#64;         can use temporarily during execution. Default value is 1GB.
         *&#64;&#64;
         *&#64;&#64;       For "auto_mixed_precision", no parameters are required. If set,
         *&#64;&#64;       the model will try to use FP16 for better performance.
         *&#64;&#64;       This optimization can not be set with "tensorrt".
         *&#64;&#64;
         *&#64;&#64;       For "gpu_io", no parameters are required. If set, the model will
         *&#64;&#64;       be executed using TensorFlow Callable API to set input and output
         *&#64;&#64;       tensors in GPU memory if possible, which can reduce data transfer
         *&#64;&#64;       overhead if the model is used in ensemble. However, the Callable
         *&#64;&#64;       object will be created on model creation and it will request all
         *&#64;&#64;       outputs for every model execution, which may impact the
         *&#64;&#64;       performance if a request does not require all outputs. This
         *&#64;&#64;       optimization will only take affect if the model instance is
         *&#64;&#64;       created with KIND_GPU.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator gpu_execution_accelerator = 1;</code>
         */
        public java.util.List<Accelerator.Builder>
             getGpuExecutionAcceleratorBuilderList() {
          return getGpuExecutionAcceleratorFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder>
            getGpuExecutionAcceleratorFieldBuilder() {
          if (gpuExecutionAcceleratorBuilder_ == null) {
            gpuExecutionAcceleratorBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
                ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder>(
                    gpuExecutionAccelerator_,
                    ((bitField0_ & 0x00000001) == 0x00000001),
                    getParentForChildren(),
                    isClean());
            gpuExecutionAccelerator_ = null;
          }
          return gpuExecutionAcceleratorBuilder_;
        }

        private java.util.List<Accelerator> cpuExecutionAccelerator_ =
          java.util.Collections.emptyList();
        private void ensureCpuExecutionAcceleratorIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            cpuExecutionAccelerator_ = new java.util.ArrayList<Accelerator>(cpuExecutionAccelerator_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder> cpuExecutionAcceleratorBuilder_;

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public java.util.List<Accelerator> getCpuExecutionAcceleratorList() {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            return java.util.Collections.unmodifiableList(cpuExecutionAccelerator_);
          } else {
            return cpuExecutionAcceleratorBuilder_.getMessageList();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public int getCpuExecutionAcceleratorCount() {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            return cpuExecutionAccelerator_.size();
          } else {
            return cpuExecutionAcceleratorBuilder_.getCount();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator getCpuExecutionAccelerator(int index) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            return cpuExecutionAccelerator_.get(index);
          } else {
            return cpuExecutionAcceleratorBuilder_.getMessage(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder setCpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.set(index, value);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder setCpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.set(index, builderForValue.build());
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder addCpuExecutionAccelerator(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.add(value);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder addCpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator value) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.add(index, value);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder addCpuExecutionAccelerator(
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.add(builderForValue.build());
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder addCpuExecutionAccelerator(
            int index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder builderForValue) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.add(index, builderForValue.build());
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder addAllCpuExecutionAccelerator(
            Iterable<? extends Accelerator> values) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            ensureCpuExecutionAcceleratorIsMutable();
            com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, cpuExecutionAccelerator_);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder clearCpuExecutionAccelerator() {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            cpuExecutionAccelerator_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.clear();
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public Builder removeCpuExecutionAccelerator(int index) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            ensureCpuExecutionAcceleratorIsMutable();
            cpuExecutionAccelerator_.remove(index);
            onChanged();
          } else {
            cpuExecutionAcceleratorBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder getCpuExecutionAcceleratorBuilder(
            int index) {
          return getCpuExecutionAcceleratorFieldBuilder().getBuilder(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder getCpuExecutionAcceleratorOrBuilder(
            int index) {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            return cpuExecutionAccelerator_.get(index);  } else {
            return cpuExecutionAcceleratorBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public java.util.List<? extends AcceleratorOrBuilder>
             getCpuExecutionAcceleratorOrBuilderList() {
          if (cpuExecutionAcceleratorBuilder_ != null) {
            return cpuExecutionAcceleratorBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(cpuExecutionAccelerator_);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder addCpuExecutionAcceleratorBuilder() {
          return getCpuExecutionAcceleratorFieldBuilder().addBuilder(
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder addCpuExecutionAcceleratorBuilder(
            int index) {
          return getCpuExecutionAcceleratorFieldBuilder().addBuilder(
              index, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Accelerator cpu_execution_accelerator (repeated)
         *&#64;&#64;
         *&#64;&#64;       The preferred execution provider to be used if the model instance
         *&#64;&#64;       is deployed on CPU.
         *&#64;&#64;
         *&#64;&#64;       For ONNX Runtime backend, possible value is "openvino" as name,
         *&#64;&#64;       and no parameters are required.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator cpu_execution_accelerator = 2;</code>
         */
        public java.util.List<Accelerator.Builder>
             getCpuExecutionAcceleratorBuilderList() {
          return getCpuExecutionAcceleratorFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder>
            getCpuExecutionAcceleratorFieldBuilder() {
          if (cpuExecutionAcceleratorBuilder_ == null) {
            cpuExecutionAcceleratorBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
                ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Accelerator.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.AcceleratorOrBuilder>(
                    cpuExecutionAccelerator_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            cpuExecutionAccelerator_ = null;
          }
          return cpuExecutionAcceleratorBuilder_;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.ExecutionAccelerators)
      private static final ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators();
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<ExecutionAccelerators>
          PARSER = new com.google.protobuf.AbstractParser<ExecutionAccelerators>() {
        public ExecutionAccelerators parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new ExecutionAccelerators(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<ExecutionAccelerators> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<ExecutionAccelerators> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface PinnedMemoryBufferOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool enable
       *&#64;&#64;
       *&#64;&#64;       Use pinned memory buffer. Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool enable = 1;</code>
       */
      boolean getEnable();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message PinnedMemoryBuffer
     *&#64;&#64;
     *&#64;&#64;     Specify whether to use a pinned memory buffer when transferring data
     *&#64;&#64;     between non-pinned system memory and GPU memory. Using a pinned
     *&#64;&#64;     memory buffer for system from/to GPU transfers will typically provide
     *&#64;&#64;     increased performance. For example, in the common use case where the
     *&#64;&#64;     request provides inputs and delivers outputs via non-pinned system
     *&#64;&#64;     memory, if the model instance accepts GPU IOs, the inputs will be
     *&#64;&#64;     processed by two copies: from non-pinned system memory to pinned
     *&#64;&#64;     memory, and from pinned memory to GPU memory. Similarly, pinned
     *&#64;&#64;     memory will be used for delivering the outputs.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOptimizationPolicy.PinnedMemoryBuffer}
     */
    public  static final class PinnedMemoryBuffer extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
        PinnedMemoryBufferOrBuilder {
      // Use PinnedMemoryBuffer.newBuilder() to construct.
      private PinnedMemoryBuffer(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private PinnedMemoryBuffer() {
        enable_ = false;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private PinnedMemoryBuffer(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {

                enable_ = input.readBool();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.class, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder.class);
      }

      public static final int ENABLE_FIELD_NUMBER = 1;
      private boolean enable_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: bool enable
       *&#64;&#64;
       *&#64;&#64;       Use pinned memory buffer. Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool enable = 1;</code>
       */
      public boolean getEnable() {
        return enable_;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (enable_ != false) {
          output.writeBool(1, enable_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (enable_ != false) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(1, enable_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer other = (ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer) obj;

        boolean result = true;
        result = result && (getEnable()
            == other.getEnable());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + ENABLE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getEnable());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message PinnedMemoryBuffer
       *&#64;&#64;
       *&#64;&#64;     Specify whether to use a pinned memory buffer when transferring data
       *&#64;&#64;     between non-pinned system memory and GPU memory. Using a pinned
       *&#64;&#64;     memory buffer for system from/to GPU transfers will typically provide
       *&#64;&#64;     increased performance. For example, in the common use case where the
       *&#64;&#64;     request provides inputs and delivers outputs via non-pinned system
       *&#64;&#64;     memory, if the model instance accepts GPU IOs, the inputs will be
       *&#64;&#64;     processed by two copies: from non-pinned system memory to pinned
       *&#64;&#64;     memory, and from pinned memory to GPU memory. Similarly, pinned
       *&#64;&#64;     memory will be used for delivering the outputs.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelOptimizationPolicy.PinnedMemoryBuffer}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.class, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          enable_ = false;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer build() {
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer buildPartial() {
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer result = new ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer(this);
          result.enable_ = enable_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer) {
            return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer other) {
          if (other == ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance()) return this;
          if (other.getEnable() != false) {
            setEnable(other.getEnable());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }

        private boolean enable_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool enable
         *&#64;&#64;
         *&#64;&#64;       Use pinned memory buffer. Default is true.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool enable = 1;</code>
         */
        public boolean getEnable() {
          return enable_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool enable
         *&#64;&#64;
         *&#64;&#64;       Use pinned memory buffer. Default is true.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool enable = 1;</code>
         */
        public Builder setEnable(boolean value) {

          enable_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: bool enable
         *&#64;&#64;
         *&#64;&#64;       Use pinned memory buffer. Default is true.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool enable = 1;</code>
         */
        public Builder clearEnable() {

          enable_ = false;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy.PinnedMemoryBuffer)
      private static final ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer();
      }

      public static ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<PinnedMemoryBuffer>
          PARSER = new com.google.protobuf.AbstractParser<PinnedMemoryBuffer>() {
        public PinnedMemoryBuffer parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new PinnedMemoryBuffer(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<PinnedMemoryBuffer> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<PinnedMemoryBuffer> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int GRAPH_FIELD_NUMBER = 1;
    private ModelConfigOuterClass.ModelOptimizationPolicy.Graph graph_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    public boolean hasGraph() {
      return graph_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.Graph getGraph() {
      return graph_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.Graph.getDefaultInstance() : graph_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Graph graph
     *&#64;&#64;
     *&#64;&#64;     The graph optimization setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder getGraphOrBuilder() {
      return getGraph();
    }

    public static final int PRIORITY_FIELD_NUMBER = 2;
    private int priority_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelPriority priority
     *&#64;&#64;
     *&#64;&#64;     The priority setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
     */
    public int getPriorityValue() {
      return priority_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelPriority priority
     *&#64;&#64;
     *&#64;&#64;     The priority setting for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority getPriority() {
      ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority result = ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.valueOf(priority_);
      return result == null ? ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.UNRECOGNIZED : result;
    }

    public static final int CUDA_FIELD_NUMBER = 3;
    private ModelConfigOuterClass.ModelOptimizationPolicy.Cuda cuda_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    public boolean hasCuda() {
      return cuda_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getCuda() {
      return cuda_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.getDefaultInstance() : cuda_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Cuda cuda
     *&#64;&#64;
     *&#64;&#64;     CUDA-specific optimization settings. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder getCudaOrBuilder() {
      return getCuda();
    }

    public static final int EXECUTION_ACCELERATORS_FIELD_NUMBER = 4;
    private ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators executionAccelerators_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    public boolean hasExecutionAccelerators() {
      return executionAccelerators_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getExecutionAccelerators() {
      return executionAccelerators_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.getDefaultInstance() : executionAccelerators_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
     *&#64;&#64;
     *&#64;&#64;     The accelerators used for the model. Optional.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder getExecutionAcceleratorsOrBuilder() {
      return getExecutionAccelerators();
    }

    public static final int INPUT_PINNED_MEMORY_FIELD_NUMBER = 5;
    private ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer inputPinnedMemory_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    public boolean hasInputPinnedMemory() {
      return inputPinnedMemory_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getInputPinnedMemory() {
      return inputPinnedMemory_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : inputPinnedMemory_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getInputPinnedMemoryOrBuilder() {
      return getInputPinnedMemory();
    }

    public static final int OUTPUT_PINNED_MEMORY_FIELD_NUMBER = 6;
    private ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer outputPinnedMemory_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    public boolean hasOutputPinnedMemory() {
      return outputPinnedMemory_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getOutputPinnedMemory() {
      return outputPinnedMemory_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : outputPinnedMemory_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
     *&#64;&#64;
     *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
     *&#64;&#64;     is between GPU memory and non-pinned system memory.
     *&#64;&#64;     Default is true.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getOutputPinnedMemoryOrBuilder() {
      return getOutputPinnedMemory();
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (graph_ != null) {
        output.writeMessage(1, getGraph());
      }
      if (priority_ != ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.PRIORITY_DEFAULT.getNumber()) {
        output.writeEnum(2, priority_);
      }
      if (cuda_ != null) {
        output.writeMessage(3, getCuda());
      }
      if (executionAccelerators_ != null) {
        output.writeMessage(4, getExecutionAccelerators());
      }
      if (inputPinnedMemory_ != null) {
        output.writeMessage(5, getInputPinnedMemory());
      }
      if (outputPinnedMemory_ != null) {
        output.writeMessage(6, getOutputPinnedMemory());
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (graph_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getGraph());
      }
      if (priority_ != ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.PRIORITY_DEFAULT.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, priority_);
      }
      if (cuda_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCuda());
      }
      if (executionAccelerators_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getExecutionAccelerators());
      }
      if (inputPinnedMemory_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getInputPinnedMemory());
      }
      if (outputPinnedMemory_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getOutputPinnedMemory());
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelOptimizationPolicy)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelOptimizationPolicy other = (ModelConfigOuterClass.ModelOptimizationPolicy) obj;

      boolean result = true;
      result = result && (hasGraph() == other.hasGraph());
      if (hasGraph()) {
        result = result && getGraph()
            .equals(other.getGraph());
      }
      result = result && priority_ == other.priority_;
      result = result && (hasCuda() == other.hasCuda());
      if (hasCuda()) {
        result = result && getCuda()
            .equals(other.getCuda());
      }
      result = result && (hasExecutionAccelerators() == other.hasExecutionAccelerators());
      if (hasExecutionAccelerators()) {
        result = result && getExecutionAccelerators()
            .equals(other.getExecutionAccelerators());
      }
      result = result && (hasInputPinnedMemory() == other.hasInputPinnedMemory());
      if (hasInputPinnedMemory()) {
        result = result && getInputPinnedMemory()
            .equals(other.getInputPinnedMemory());
      }
      result = result && (hasOutputPinnedMemory() == other.hasOutputPinnedMemory());
      if (hasOutputPinnedMemory()) {
        result = result && getOutputPinnedMemory()
            .equals(other.getOutputPinnedMemory());
      }
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasGraph()) {
        hash = (37 * hash) + GRAPH_FIELD_NUMBER;
        hash = (53 * hash) + getGraph().hashCode();
      }
      hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
      hash = (53 * hash) + priority_;
      if (hasCuda()) {
        hash = (37 * hash) + CUDA_FIELD_NUMBER;
        hash = (53 * hash) + getCuda().hashCode();
      }
      if (hasExecutionAccelerators()) {
        hash = (37 * hash) + EXECUTION_ACCELERATORS_FIELD_NUMBER;
        hash = (53 * hash) + getExecutionAccelerators().hashCode();
      }
      if (hasInputPinnedMemory()) {
        hash = (37 * hash) + INPUT_PINNED_MEMORY_FIELD_NUMBER;
        hash = (53 * hash) + getInputPinnedMemory().hashCode();
      }
      if (hasOutputPinnedMemory()) {
        hash = (37 * hash) + OUTPUT_PINNED_MEMORY_FIELD_NUMBER;
        hash = (53 * hash) + getOutputPinnedMemory().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOptimizationPolicy parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelOptimizationPolicy prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelOptimizationPolicy
     *&#64;&#64;
     *&#64;&#64;   Optimization settings for a model. These settings control if/how a
     *&#64;&#64;   model is optimized and prioritized by the backend framework when
     *&#64;&#64;   it is loaded.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOptimizationPolicy}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelOptimizationPolicy)
        ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOptimizationPolicy.class, ModelConfigOuterClass.ModelOptimizationPolicy.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelOptimizationPolicy.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        if (graphBuilder_ == null) {
          graph_ = null;
        } else {
          graph_ = null;
          graphBuilder_ = null;
        }
        priority_ = 0;

        if (cudaBuilder_ == null) {
          cuda_ = null;
        } else {
          cuda_ = null;
          cudaBuilder_ = null;
        }
        if (executionAcceleratorsBuilder_ == null) {
          executionAccelerators_ = null;
        } else {
          executionAccelerators_ = null;
          executionAcceleratorsBuilder_ = null;
        }
        if (inputPinnedMemoryBuilder_ == null) {
          inputPinnedMemory_ = null;
        } else {
          inputPinnedMemory_ = null;
          inputPinnedMemoryBuilder_ = null;
        }
        if (outputPinnedMemoryBuilder_ == null) {
          outputPinnedMemory_ = null;
        } else {
          outputPinnedMemory_ = null;
          outputPinnedMemoryBuilder_ = null;
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelOptimizationPolicy_descriptor;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelOptimizationPolicy.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy build() {
        ModelConfigOuterClass.ModelOptimizationPolicy result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelOptimizationPolicy buildPartial() {
        ModelConfigOuterClass.ModelOptimizationPolicy result = new ModelConfigOuterClass.ModelOptimizationPolicy(this);
        if (graphBuilder_ == null) {
          result.graph_ = graph_;
        } else {
          result.graph_ = graphBuilder_.build();
        }
        result.priority_ = priority_;
        if (cudaBuilder_ == null) {
          result.cuda_ = cuda_;
        } else {
          result.cuda_ = cudaBuilder_.build();
        }
        if (executionAcceleratorsBuilder_ == null) {
          result.executionAccelerators_ = executionAccelerators_;
        } else {
          result.executionAccelerators_ = executionAcceleratorsBuilder_.build();
        }
        if (inputPinnedMemoryBuilder_ == null) {
          result.inputPinnedMemory_ = inputPinnedMemory_;
        } else {
          result.inputPinnedMemory_ = inputPinnedMemoryBuilder_.build();
        }
        if (outputPinnedMemoryBuilder_ == null) {
          result.outputPinnedMemory_ = outputPinnedMemory_;
        } else {
          result.outputPinnedMemory_ = outputPinnedMemoryBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelOptimizationPolicy) {
          return mergeFrom((ModelConfigOuterClass.ModelOptimizationPolicy)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelOptimizationPolicy other) {
        if (other == ModelConfigOuterClass.ModelOptimizationPolicy.getDefaultInstance()) return this;
        if (other.hasGraph()) {
          mergeGraph(other.getGraph());
        }
        if (other.priority_ != 0) {
          setPriorityValue(other.getPriorityValue());
        }
        if (other.hasCuda()) {
          mergeCuda(other.getCuda());
        }
        if (other.hasExecutionAccelerators()) {
          mergeExecutionAccelerators(other.getExecutionAccelerators());
        }
        if (other.hasInputPinnedMemory()) {
          mergeInputPinnedMemory(other.getInputPinnedMemory());
        }
        if (other.hasOutputPinnedMemory()) {
          mergeOutputPinnedMemory(other.getOutputPinnedMemory());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelOptimizationPolicy parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelOptimizationPolicy) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy.Graph graph_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph, ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder> graphBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public boolean hasGraph() {
        return graphBuilder_ != null || graph_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.Graph getGraph() {
        if (graphBuilder_ == null) {
          return graph_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.Graph.getDefaultInstance() : graph_;
        } else {
          return graphBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public Builder setGraph(ModelConfigOuterClass.ModelOptimizationPolicy.Graph value) {
        if (graphBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          graph_ = value;
          onChanged();
        } else {
          graphBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public Builder setGraph(
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder builderForValue) {
        if (graphBuilder_ == null) {
          graph_ = builderForValue.build();
          onChanged();
        } else {
          graphBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public Builder mergeGraph(ModelConfigOuterClass.ModelOptimizationPolicy.Graph value) {
        if (graphBuilder_ == null) {
          if (graph_ != null) {
            graph_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.Graph.newBuilder(graph_).mergeFrom(value).buildPartial();
          } else {
            graph_ = value;
          }
          onChanged();
        } else {
          graphBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public Builder clearGraph() {
        if (graphBuilder_ == null) {
          graph_ = null;
          onChanged();
        } else {
          graph_ = null;
          graphBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder getGraphBuilder() {

        onChanged();
        return getGraphFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder getGraphOrBuilder() {
        if (graphBuilder_ != null) {
          return graphBuilder_.getMessageOrBuilder();
        } else {
          return graph_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.Graph.getDefaultInstance() : graph_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Graph graph
       *&#64;&#64;
       *&#64;&#64;     The graph optimization setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Graph graph = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.Graph, ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder>
          getGraphFieldBuilder() {
        if (graphBuilder_ == null) {
          graphBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy.Graph, ModelConfigOuterClass.ModelOptimizationPolicy.Graph.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.GraphOrBuilder>(
                  getGraph(),
                  getParentForChildren(),
                  isClean());
          graph_ = null;
        }
        return graphBuilder_;
      }

      private int priority_ = 0;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelPriority priority
       *&#64;&#64;
       *&#64;&#64;     The priority setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
       */
      public int getPriorityValue() {
        return priority_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelPriority priority
       *&#64;&#64;
       *&#64;&#64;     The priority setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
       */
      public Builder setPriorityValue(int value) {
        priority_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelPriority priority
       *&#64;&#64;
       *&#64;&#64;     The priority setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority getPriority() {
        ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority result = ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.valueOf(priority_);
        return result == null ? ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelPriority priority
       *&#64;&#64;
       *&#64;&#64;     The priority setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
       */
      public Builder setPriority(ModelConfigOuterClass.ModelOptimizationPolicy.ModelPriority value) {
        if (value == null) {
          throw new NullPointerException();
        }

        priority_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelPriority priority
       *&#64;&#64;
       *&#64;&#64;     The priority setting for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ModelPriority priority = 2;</code>
       */
      public Builder clearPriority() {

        priority_ = 0;
        onChanged();
        return this;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy.Cuda cuda_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda, ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder> cudaBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public boolean hasCuda() {
        return cudaBuilder_ != null || cuda_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda getCuda() {
        if (cudaBuilder_ == null) {
          return cuda_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.getDefaultInstance() : cuda_;
        } else {
          return cudaBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public Builder setCuda(ModelConfigOuterClass.ModelOptimizationPolicy.Cuda value) {
        if (cudaBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          cuda_ = value;
          onChanged();
        } else {
          cudaBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public Builder setCuda(
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder builderForValue) {
        if (cudaBuilder_ == null) {
          cuda_ = builderForValue.build();
          onChanged();
        } else {
          cudaBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public Builder mergeCuda(ModelConfigOuterClass.ModelOptimizationPolicy.Cuda value) {
        if (cudaBuilder_ == null) {
          if (cuda_ != null) {
            cuda_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.newBuilder(cuda_).mergeFrom(value).buildPartial();
          } else {
            cuda_ = value;
          }
          onChanged();
        } else {
          cudaBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public Builder clearCuda() {
        if (cudaBuilder_ == null) {
          cuda_ = null;
          onChanged();
        } else {
          cuda_ = null;
          cudaBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder getCudaBuilder() {

        onChanged();
        return getCudaFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder getCudaOrBuilder() {
        if (cudaBuilder_ != null) {
          return cudaBuilder_.getMessageOrBuilder();
        } else {
          return cuda_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.getDefaultInstance() : cuda_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Cuda cuda
       *&#64;&#64;
       *&#64;&#64;     CUDA-specific optimization settings. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.Cuda cuda = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.Cuda, ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder>
          getCudaFieldBuilder() {
        if (cudaBuilder_ == null) {
          cudaBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy.Cuda, ModelConfigOuterClass.ModelOptimizationPolicy.Cuda.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.CudaOrBuilder>(
                  getCuda(),
                  getParentForChildren(),
                  isClean());
          cuda_ = null;
        }
        return cudaBuilder_;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators executionAccelerators_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder> executionAcceleratorsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public boolean hasExecutionAccelerators() {
        return executionAcceleratorsBuilder_ != null || executionAccelerators_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators getExecutionAccelerators() {
        if (executionAcceleratorsBuilder_ == null) {
          return executionAccelerators_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.getDefaultInstance() : executionAccelerators_;
        } else {
          return executionAcceleratorsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public Builder setExecutionAccelerators(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators value) {
        if (executionAcceleratorsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          executionAccelerators_ = value;
          onChanged();
        } else {
          executionAcceleratorsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public Builder setExecutionAccelerators(
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder builderForValue) {
        if (executionAcceleratorsBuilder_ == null) {
          executionAccelerators_ = builderForValue.build();
          onChanged();
        } else {
          executionAcceleratorsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public Builder mergeExecutionAccelerators(ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators value) {
        if (executionAcceleratorsBuilder_ == null) {
          if (executionAccelerators_ != null) {
            executionAccelerators_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.newBuilder(executionAccelerators_).mergeFrom(value).buildPartial();
          } else {
            executionAccelerators_ = value;
          }
          onChanged();
        } else {
          executionAcceleratorsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public Builder clearExecutionAccelerators() {
        if (executionAcceleratorsBuilder_ == null) {
          executionAccelerators_ = null;
          onChanged();
        } else {
          executionAccelerators_ = null;
          executionAcceleratorsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder getExecutionAcceleratorsBuilder() {

        onChanged();
        return getExecutionAcceleratorsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder getExecutionAcceleratorsOrBuilder() {
        if (executionAcceleratorsBuilder_ != null) {
          return executionAcceleratorsBuilder_.getMessageOrBuilder();
        } else {
          return executionAccelerators_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.getDefaultInstance() : executionAccelerators_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ExecutionAccelerators execution_accelerators
       *&#64;&#64;
       *&#64;&#64;     The accelerators used for the model. Optional.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.ExecutionAccelerators execution_accelerators = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder>
          getExecutionAcceleratorsFieldBuilder() {
        if (executionAcceleratorsBuilder_ == null) {
          executionAcceleratorsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAccelerators.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.ExecutionAcceleratorsOrBuilder>(
                  getExecutionAccelerators(),
                  getParentForChildren(),
                  isClean());
          executionAccelerators_ = null;
        }
        return executionAcceleratorsBuilder_;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer inputPinnedMemory_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder> inputPinnedMemoryBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public boolean hasInputPinnedMemory() {
        return inputPinnedMemoryBuilder_ != null || inputPinnedMemory_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getInputPinnedMemory() {
        if (inputPinnedMemoryBuilder_ == null) {
          return inputPinnedMemory_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : inputPinnedMemory_;
        } else {
          return inputPinnedMemoryBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public Builder setInputPinnedMemory(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer value) {
        if (inputPinnedMemoryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          inputPinnedMemory_ = value;
          onChanged();
        } else {
          inputPinnedMemoryBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public Builder setInputPinnedMemory(
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder builderForValue) {
        if (inputPinnedMemoryBuilder_ == null) {
          inputPinnedMemory_ = builderForValue.build();
          onChanged();
        } else {
          inputPinnedMemoryBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public Builder mergeInputPinnedMemory(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer value) {
        if (inputPinnedMemoryBuilder_ == null) {
          if (inputPinnedMemory_ != null) {
            inputPinnedMemory_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.newBuilder(inputPinnedMemory_).mergeFrom(value).buildPartial();
          } else {
            inputPinnedMemory_ = value;
          }
          onChanged();
        } else {
          inputPinnedMemoryBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public Builder clearInputPinnedMemory() {
        if (inputPinnedMemoryBuilder_ == null) {
          inputPinnedMemory_ = null;
          onChanged();
        } else {
          inputPinnedMemory_ = null;
          inputPinnedMemoryBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder getInputPinnedMemoryBuilder() {

        onChanged();
        return getInputPinnedMemoryFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getInputPinnedMemoryOrBuilder() {
        if (inputPinnedMemoryBuilder_ != null) {
          return inputPinnedMemoryBuilder_.getMessageOrBuilder();
        } else {
          return inputPinnedMemory_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : inputPinnedMemory_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer input_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for inputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer input_pinned_memory = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder>
          getInputPinnedMemoryFieldBuilder() {
        if (inputPinnedMemoryBuilder_ == null) {
          inputPinnedMemoryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder>(
                  getInputPinnedMemory(),
                  getParentForChildren(),
                  isClean());
          inputPinnedMemory_ = null;
        }
        return inputPinnedMemoryBuilder_;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer outputPinnedMemory_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder> outputPinnedMemoryBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public boolean hasOutputPinnedMemory() {
        return outputPinnedMemoryBuilder_ != null || outputPinnedMemory_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer getOutputPinnedMemory() {
        if (outputPinnedMemoryBuilder_ == null) {
          return outputPinnedMemory_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : outputPinnedMemory_;
        } else {
          return outputPinnedMemoryBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public Builder setOutputPinnedMemory(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer value) {
        if (outputPinnedMemoryBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          outputPinnedMemory_ = value;
          onChanged();
        } else {
          outputPinnedMemoryBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public Builder setOutputPinnedMemory(
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder builderForValue) {
        if (outputPinnedMemoryBuilder_ == null) {
          outputPinnedMemory_ = builderForValue.build();
          onChanged();
        } else {
          outputPinnedMemoryBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public Builder mergeOutputPinnedMemory(ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer value) {
        if (outputPinnedMemoryBuilder_ == null) {
          if (outputPinnedMemory_ != null) {
            outputPinnedMemory_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.newBuilder(outputPinnedMemory_).mergeFrom(value).buildPartial();
          } else {
            outputPinnedMemory_ = value;
          }
          onChanged();
        } else {
          outputPinnedMemoryBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public Builder clearOutputPinnedMemory() {
        if (outputPinnedMemoryBuilder_ == null) {
          outputPinnedMemory_ = null;
          onChanged();
        } else {
          outputPinnedMemory_ = null;
          outputPinnedMemoryBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder getOutputPinnedMemoryBuilder() {

        onChanged();
        return getOutputPinnedMemoryFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder getOutputPinnedMemoryOrBuilder() {
        if (outputPinnedMemoryBuilder_ != null) {
          return outputPinnedMemoryBuilder_.getMessageOrBuilder();
        } else {
          return outputPinnedMemory_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.getDefaultInstance() : outputPinnedMemory_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: PinnedMemoryBuffer output_pinned_memory
       *&#64;&#64;
       *&#64;&#64;     Use pinned memory buffer when the data transfer for outputs
       *&#64;&#64;     is between GPU memory and non-pinned system memory.
       *&#64;&#64;     Default is true.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy.PinnedMemoryBuffer output_pinned_memory = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder>
          getOutputPinnedMemoryFieldBuilder() {
        if (outputPinnedMemoryBuilder_ == null) {
          outputPinnedMemoryBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBuffer.Builder, ModelConfigOuterClass.ModelOptimizationPolicy.PinnedMemoryBufferOrBuilder>(
                  getOutputPinnedMemory(),
                  getParentForChildren(),
                  isClean());
          outputPinnedMemory_ = null;
        }
        return outputPinnedMemoryBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelOptimizationPolicy)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelOptimizationPolicy)
    private static final ModelConfigOuterClass.ModelOptimizationPolicy DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOptimizationPolicy();
    }

    public static ModelConfigOuterClass.ModelOptimizationPolicy getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelOptimizationPolicy>
        PARSER = new com.google.protobuf.AbstractParser<ModelOptimizationPolicy>() {
      public ModelOptimizationPolicy parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelOptimizationPolicy(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelOptimizationPolicy> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelOptimizationPolicy> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelOptimizationPolicy getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelQueuePolicyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelQueuePolicy)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
     *&#64;&#64;
     *&#64;&#64;     The action applied to timed-out request.
     *&#64;&#64;     The default action is REJECT.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
     */
    int getTimeoutActionValue();
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
     *&#64;&#64;
     *&#64;&#64;     The action applied to timed-out request.
     *&#64;&#64;     The default action is REJECT.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
     */
    ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction getTimeoutAction();

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: uint64 default_timeout_microseconds
     *&#64;&#64;
     *&#64;&#64;     The default timeout for every request, in microseconds.
     *&#64;&#64;     The default value is 0 which indicates that no timeout is set.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 default_timeout_microseconds = 2;</code>
     */
    long getDefaultTimeoutMicroseconds();

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: bool allow_timeout_override
     *&#64;&#64;
     *&#64;&#64;     Whether individual request can override the default timeout value.
     *&#64;&#64;     When true, individual requests can set a timeout that is less than
     *&#64;&#64;     the default timeout value but may not increase the timeout.
     *&#64;&#64;     The default value is false.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool allow_timeout_override = 3;</code>
     */
    boolean getAllowTimeoutOverride();

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: uint32 max_queue_size
     *&#64;&#64;
     *&#64;&#64;     The maximum queue size for holding requests. A request will be
     *&#64;&#64;     rejected immediately if it can't be enqueued because the queue is
     *&#64;&#64;     full. The default value is 0 which indicates that no maximum
     *&#64;&#64;     queue size is enforced.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 max_queue_size = 4;</code>
     */
    int getMaxQueueSize();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelQueuePolicy
   *&#64;&#64;
   *&#64;&#64;   Queue policy for inference requests.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelQueuePolicy}
   */
  public  static final class ModelQueuePolicy extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelQueuePolicy)
      ModelQueuePolicyOrBuilder {
    // Use ModelQueuePolicy.newBuilder() to construct.
    private ModelQueuePolicy(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelQueuePolicy() {
      timeoutAction_ = 0;
      defaultTimeoutMicroseconds_ = 0L;
      allowTimeoutOverride_ = false;
      maxQueueSize_ = 0;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelQueuePolicy(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();

              timeoutAction_ = rawValue;
              break;
            }
            case 16: {

              defaultTimeoutMicroseconds_ = input.readUInt64();
              break;
            }
            case 24: {

              allowTimeoutOverride_ = input.readBool();
              break;
            }
            case 32: {

              maxQueueSize_ = input.readUInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelQueuePolicy_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelQueuePolicy_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelQueuePolicy.class, ModelConfigOuterClass.ModelQueuePolicy.Builder.class);
    }

    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:enum:: TimeoutAction
     *&#64;&#64;
     *&#64;&#64;     The action applied to timed-out requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf enum {@code inference.ModelQueuePolicy.TimeoutAction}
     */
    public enum TimeoutAction
        implements com.google.protobuf.ProtocolMessageEnum {
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Action::REJECT = 0
       *&#64;&#64;
       *&#64;&#64;       Reject the request and return error message accordingly.
       *&#64;&#64;
       * </pre>
       *
       * <code>REJECT = 0;</code>
       */
      REJECT(0),
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Action::DELAY = 1
       *&#64;&#64;
       *&#64;&#64;       Delay the request until all other requests at the same
       *&#64;&#64;       (or higher) priority levels that have not reached their timeouts
       *&#64;&#64;       are processed. A delayed request will eventually be processed,
       *&#64;&#64;       but may be delayed indefinitely due to newly arriving requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>DELAY = 1;</code>
       */
      DELAY(1),
      UNRECOGNIZED(-1),
      ;

      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Action::REJECT = 0
       *&#64;&#64;
       *&#64;&#64;       Reject the request and return error message accordingly.
       *&#64;&#64;
       * </pre>
       *
       * <code>REJECT = 0;</code>
       */
      public static final int REJECT_VALUE = 0;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:enumerator:: Action::DELAY = 1
       *&#64;&#64;
       *&#64;&#64;       Delay the request until all other requests at the same
       *&#64;&#64;       (or higher) priority levels that have not reached their timeouts
       *&#64;&#64;       are processed. A delayed request will eventually be processed,
       *&#64;&#64;       but may be delayed indefinitely due to newly arriving requests.
       *&#64;&#64;
       * </pre>
       *
       * <code>DELAY = 1;</code>
       */
      public static final int DELAY_VALUE = 1;


      public final int getNumber() {
        if (this == UNRECOGNIZED) {
          throw new IllegalArgumentException(
              "Can't get the number of an unknown enum value.");
        }
        return value;
      }

      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static TimeoutAction valueOf(int value) {
        return forNumber(value);
      }

      public static TimeoutAction forNumber(int value) {
        switch (value) {
          case 0: return REJECT;
          case 1: return DELAY;
          default: return null;
        }
      }

      public static com.google.protobuf.Internal.EnumLiteMap<TimeoutAction>
          internalGetValueMap() {
        return internalValueMap;
      }
      private static final com.google.protobuf.Internal.EnumLiteMap<
          TimeoutAction> internalValueMap =
            new com.google.protobuf.Internal.EnumLiteMap<TimeoutAction>() {
              public TimeoutAction findValueByNumber(int number) {
                return TimeoutAction.forNumber(number);
              }
            };

      public final com.google.protobuf.Descriptors.EnumValueDescriptor
          getValueDescriptor() {
        return getDescriptor().getValues().get(ordinal());
      }
      public final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptorForType() {
        return getDescriptor();
      }
      public static final com.google.protobuf.Descriptors.EnumDescriptor
          getDescriptor() {
        return ModelConfigOuterClass.ModelQueuePolicy.getDescriptor().getEnumTypes().get(0);
      }

      private static final TimeoutAction[] VALUES = values();

      public static TimeoutAction valueOf(
          com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
        if (desc.getType() != getDescriptor()) {
          throw new IllegalArgumentException(
            "EnumValueDescriptor is not for this type.");
        }
        if (desc.getIndex() == -1) {
          return UNRECOGNIZED;
        }
        return VALUES[desc.getIndex()];
      }

      private final int value;

      private TimeoutAction(int value) {
        this.value = value;
      }

      // @@protoc_insertion_point(enum_scope:inference.ModelQueuePolicy.TimeoutAction)
    }

    public static final int TIMEOUT_ACTION_FIELD_NUMBER = 1;
    private int timeoutAction_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
     *&#64;&#64;
     *&#64;&#64;     The action applied to timed-out request.
     *&#64;&#64;     The default action is REJECT.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
     */
    public int getTimeoutActionValue() {
      return timeoutAction_;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
     *&#64;&#64;
     *&#64;&#64;     The action applied to timed-out request.
     *&#64;&#64;     The default action is REJECT.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
     */
    public ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction getTimeoutAction() {
      ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction result = ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.valueOf(timeoutAction_);
      return result == null ? ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.UNRECOGNIZED : result;
    }

    public static final int DEFAULT_TIMEOUT_MICROSECONDS_FIELD_NUMBER = 2;
    private long defaultTimeoutMicroseconds_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: uint64 default_timeout_microseconds
     *&#64;&#64;
     *&#64;&#64;     The default timeout for every request, in microseconds.
     *&#64;&#64;     The default value is 0 which indicates that no timeout is set.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 default_timeout_microseconds = 2;</code>
     */
    public long getDefaultTimeoutMicroseconds() {
      return defaultTimeoutMicroseconds_;
    }

    public static final int ALLOW_TIMEOUT_OVERRIDE_FIELD_NUMBER = 3;
    private boolean allowTimeoutOverride_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: bool allow_timeout_override
     *&#64;&#64;
     *&#64;&#64;     Whether individual request can override the default timeout value.
     *&#64;&#64;     When true, individual requests can set a timeout that is less than
     *&#64;&#64;     the default timeout value but may not increase the timeout.
     *&#64;&#64;     The default value is false.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool allow_timeout_override = 3;</code>
     */
    public boolean getAllowTimeoutOverride() {
      return allowTimeoutOverride_;
    }

    public static final int MAX_QUEUE_SIZE_FIELD_NUMBER = 4;
    private int maxQueueSize_;
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: uint32 max_queue_size
     *&#64;&#64;
     *&#64;&#64;     The maximum queue size for holding requests. A request will be
     *&#64;&#64;     rejected immediately if it can't be enqueued because the queue is
     *&#64;&#64;     full. The default value is 0 which indicates that no maximum
     *&#64;&#64;     queue size is enforced.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 max_queue_size = 4;</code>
     */
    public int getMaxQueueSize() {
      return maxQueueSize_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (timeoutAction_ != ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.REJECT.getNumber()) {
        output.writeEnum(1, timeoutAction_);
      }
      if (defaultTimeoutMicroseconds_ != 0L) {
        output.writeUInt64(2, defaultTimeoutMicroseconds_);
      }
      if (allowTimeoutOverride_ != false) {
        output.writeBool(3, allowTimeoutOverride_);
      }
      if (maxQueueSize_ != 0) {
        output.writeUInt32(4, maxQueueSize_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (timeoutAction_ != ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.REJECT.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, timeoutAction_);
      }
      if (defaultTimeoutMicroseconds_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, defaultTimeoutMicroseconds_);
      }
      if (allowTimeoutOverride_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, allowTimeoutOverride_);
      }
      if (maxQueueSize_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, maxQueueSize_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelQueuePolicy)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelQueuePolicy other = (ModelConfigOuterClass.ModelQueuePolicy) obj;

      boolean result = true;
      result = result && timeoutAction_ == other.timeoutAction_;
      result = result && (getDefaultTimeoutMicroseconds()
          == other.getDefaultTimeoutMicroseconds());
      result = result && (getAllowTimeoutOverride()
          == other.getAllowTimeoutOverride());
      result = result && (getMaxQueueSize()
          == other.getMaxQueueSize());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + TIMEOUT_ACTION_FIELD_NUMBER;
      hash = (53 * hash) + timeoutAction_;
      hash = (37 * hash) + DEFAULT_TIMEOUT_MICROSECONDS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getDefaultTimeoutMicroseconds());
      hash = (37 * hash) + ALLOW_TIMEOUT_OVERRIDE_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getAllowTimeoutOverride());
      hash = (37 * hash) + MAX_QUEUE_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + getMaxQueueSize();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelQueuePolicy parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelQueuePolicy prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelQueuePolicy
     *&#64;&#64;
     *&#64;&#64;   Queue policy for inference requests.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelQueuePolicy}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelQueuePolicy)
        ModelConfigOuterClass.ModelQueuePolicyOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelQueuePolicy_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelQueuePolicy_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelQueuePolicy.class, ModelConfigOuterClass.ModelQueuePolicy.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelQueuePolicy.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        timeoutAction_ = 0;

        defaultTimeoutMicroseconds_ = 0L;

        allowTimeoutOverride_ = false;

        maxQueueSize_ = 0;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelQueuePolicy_descriptor;
      }

      public ModelConfigOuterClass.ModelQueuePolicy getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelQueuePolicy build() {
        ModelConfigOuterClass.ModelQueuePolicy result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelQueuePolicy buildPartial() {
        ModelConfigOuterClass.ModelQueuePolicy result = new ModelConfigOuterClass.ModelQueuePolicy(this);
        result.timeoutAction_ = timeoutAction_;
        result.defaultTimeoutMicroseconds_ = defaultTimeoutMicroseconds_;
        result.allowTimeoutOverride_ = allowTimeoutOverride_;
        result.maxQueueSize_ = maxQueueSize_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelQueuePolicy) {
          return mergeFrom((ModelConfigOuterClass.ModelQueuePolicy)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelQueuePolicy other) {
        if (other == ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance()) return this;
        if (other.timeoutAction_ != 0) {
          setTimeoutActionValue(other.getTimeoutActionValue());
        }
        if (other.getDefaultTimeoutMicroseconds() != 0L) {
          setDefaultTimeoutMicroseconds(other.getDefaultTimeoutMicroseconds());
        }
        if (other.getAllowTimeoutOverride() != false) {
          setAllowTimeoutOverride(other.getAllowTimeoutOverride());
        }
        if (other.getMaxQueueSize() != 0) {
          setMaxQueueSize(other.getMaxQueueSize());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelQueuePolicy parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelQueuePolicy) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int timeoutAction_ = 0;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
       *&#64;&#64;
       *&#64;&#64;     The action applied to timed-out request.
       *&#64;&#64;     The default action is REJECT.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
       */
      public int getTimeoutActionValue() {
        return timeoutAction_;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
       *&#64;&#64;
       *&#64;&#64;     The action applied to timed-out request.
       *&#64;&#64;     The default action is REJECT.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
       */
      public Builder setTimeoutActionValue(int value) {
        timeoutAction_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
       *&#64;&#64;
       *&#64;&#64;     The action applied to timed-out request.
       *&#64;&#64;     The default action is REJECT.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
       */
      public ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction getTimeoutAction() {
        ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction result = ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.valueOf(timeoutAction_);
        return result == null ? ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
       *&#64;&#64;
       *&#64;&#64;     The action applied to timed-out request.
       *&#64;&#64;     The default action is REJECT.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
       */
      public Builder setTimeoutAction(ModelConfigOuterClass.ModelQueuePolicy.TimeoutAction value) {
        if (value == null) {
          throw new NullPointerException();
        }

        timeoutAction_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: TimeoutAction timeout_action
       *&#64;&#64;
       *&#64;&#64;     The action applied to timed-out request.
       *&#64;&#64;     The default action is REJECT.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy.TimeoutAction timeout_action = 1;</code>
       */
      public Builder clearTimeoutAction() {

        timeoutAction_ = 0;
        onChanged();
        return this;
      }

      private long defaultTimeoutMicroseconds_ ;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint64 default_timeout_microseconds
       *&#64;&#64;
       *&#64;&#64;     The default timeout for every request, in microseconds.
       *&#64;&#64;     The default value is 0 which indicates that no timeout is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 default_timeout_microseconds = 2;</code>
       */
      public long getDefaultTimeoutMicroseconds() {
        return defaultTimeoutMicroseconds_;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint64 default_timeout_microseconds
       *&#64;&#64;
       *&#64;&#64;     The default timeout for every request, in microseconds.
       *&#64;&#64;     The default value is 0 which indicates that no timeout is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 default_timeout_microseconds = 2;</code>
       */
      public Builder setDefaultTimeoutMicroseconds(long value) {

        defaultTimeoutMicroseconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint64 default_timeout_microseconds
       *&#64;&#64;
       *&#64;&#64;     The default timeout for every request, in microseconds.
       *&#64;&#64;     The default value is 0 which indicates that no timeout is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 default_timeout_microseconds = 2;</code>
       */
      public Builder clearDefaultTimeoutMicroseconds() {

        defaultTimeoutMicroseconds_ = 0L;
        onChanged();
        return this;
      }

      private boolean allowTimeoutOverride_ ;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: bool allow_timeout_override
       *&#64;&#64;
       *&#64;&#64;     Whether individual request can override the default timeout value.
       *&#64;&#64;     When true, individual requests can set a timeout that is less than
       *&#64;&#64;     the default timeout value but may not increase the timeout.
       *&#64;&#64;     The default value is false.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_timeout_override = 3;</code>
       */
      public boolean getAllowTimeoutOverride() {
        return allowTimeoutOverride_;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: bool allow_timeout_override
       *&#64;&#64;
       *&#64;&#64;     Whether individual request can override the default timeout value.
       *&#64;&#64;     When true, individual requests can set a timeout that is less than
       *&#64;&#64;     the default timeout value but may not increase the timeout.
       *&#64;&#64;     The default value is false.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_timeout_override = 3;</code>
       */
      public Builder setAllowTimeoutOverride(boolean value) {

        allowTimeoutOverride_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: bool allow_timeout_override
       *&#64;&#64;
       *&#64;&#64;     Whether individual request can override the default timeout value.
       *&#64;&#64;     When true, individual requests can set a timeout that is less than
       *&#64;&#64;     the default timeout value but may not increase the timeout.
       *&#64;&#64;     The default value is false.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool allow_timeout_override = 3;</code>
       */
      public Builder clearAllowTimeoutOverride() {

        allowTimeoutOverride_ = false;
        onChanged();
        return this;
      }

      private int maxQueueSize_ ;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint32 max_queue_size
       *&#64;&#64;
       *&#64;&#64;     The maximum queue size for holding requests. A request will be
       *&#64;&#64;     rejected immediately if it can't be enqueued because the queue is
       *&#64;&#64;     full. The default value is 0 which indicates that no maximum
       *&#64;&#64;     queue size is enforced.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 max_queue_size = 4;</code>
       */
      public int getMaxQueueSize() {
        return maxQueueSize_;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint32 max_queue_size
       *&#64;&#64;
       *&#64;&#64;     The maximum queue size for holding requests. A request will be
       *&#64;&#64;     rejected immediately if it can't be enqueued because the queue is
       *&#64;&#64;     full. The default value is 0 which indicates that no maximum
       *&#64;&#64;     queue size is enforced.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 max_queue_size = 4;</code>
       */
      public Builder setMaxQueueSize(int value) {

        maxQueueSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: uint32 max_queue_size
       *&#64;&#64;
       *&#64;&#64;     The maximum queue size for holding requests. A request will be
       *&#64;&#64;     rejected immediately if it can't be enqueued because the queue is
       *&#64;&#64;     full. The default value is 0 which indicates that no maximum
       *&#64;&#64;     queue size is enforced.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 max_queue_size = 4;</code>
       */
      public Builder clearMaxQueueSize() {

        maxQueueSize_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelQueuePolicy)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelQueuePolicy)
    private static final ModelConfigOuterClass.ModelQueuePolicy DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelQueuePolicy();
    }

    public static ModelConfigOuterClass.ModelQueuePolicy getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelQueuePolicy>
        PARSER = new com.google.protobuf.AbstractParser<ModelQueuePolicy>() {
      public ModelQueuePolicy parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelQueuePolicy(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelQueuePolicy> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelQueuePolicy> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelQueuePolicy getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelDynamicBatchingOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelDynamicBatching)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    java.util.List<Integer> getPreferredBatchSizeList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    int getPreferredBatchSizeCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    int getPreferredBatchSize(int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 max_queue_delay_microseconds
     *&#64;&#64;
     *&#64;&#64;     The maximum time, in microseconds, a request will be delayed in
     *&#64;&#64;     the scheduling queue to wait for additional requests for
     *&#64;&#64;     batching. Default is 0.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 max_queue_delay_microseconds = 2;</code>
     */
    long getMaxQueueDelayMicroseconds();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool preserve_ordering
     *&#64;&#64;
     *&#64;&#64;     Should the dynamic batcher preserve the ordering of responses to
     *&#64;&#64;     match the order of requests received by the scheduler. Default is
     *&#64;&#64;     false. If true, the responses will be returned in the same order as
     *&#64;&#64;     the order of requests sent to the scheduler. If false, the responses
     *&#64;&#64;     may be returned in arbitrary order. This option is specifically
     *&#64;&#64;     needed when a sequence of related inference requests (i.e. inference
     *&#64;&#64;     requests with the same correlation ID) are sent to the dynamic
     *&#64;&#64;     batcher to ensure that the sequence responses are in the correct
     *&#64;&#64;     order.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool preserve_ordering = 3;</code>
     */
    boolean getPreserveOrdering();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 priority_levels
     *&#64;&#64;
     *&#64;&#64;     The number of priority levels to be enabled for the model,
     *&#64;&#64;     the priority level starts from 1 and 1 is the highest priority.
     *&#64;&#64;     Requests are handled in priority order with all priority 1 requests
     *&#64;&#64;     processed before priority 2, all priority 2 requests processed before
     *&#64;&#64;     priority 3, etc. Requests with the same priority level will be
     *&#64;&#64;     handled in the order that they are received.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 priority_levels = 4;</code>
     */
    int getPriorityLevels();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 default_priority_level
     *&#64;&#64;
     *&#64;&#64;     The priority level used for requests that don't specify their
     *&#64;&#64;     priority. The value must be in the range [ 1, 'priority_levels' ].
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 default_priority_level = 5;</code>
     */
    int getDefaultPriorityLevel();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    boolean hasDefaultQueuePolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    ModelConfigOuterClass.ModelQueuePolicy getDefaultQueuePolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    ModelConfigOuterClass.ModelQueuePolicyOrBuilder getDefaultQueuePolicyOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */
    int getPriorityQueuePolicyCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */
    boolean containsPriorityQueuePolicy(
        int key);
    /**
     * Use {@link #getPriorityQueuePolicyMap()} instead.
     */
    @Deprecated
    java.util.Map<Integer, ModelQueuePolicy>
    getPriorityQueuePolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */
    java.util.Map<Integer, ModelQueuePolicy>
    getPriorityQueuePolicyMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrDefault(
        int key,
        ModelConfigOuterClass.ModelQueuePolicy defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrThrow(
        int key);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelDynamicBatching
   *&#64;&#64;
   *&#64;&#64;   Dynamic batching configuration. These settings control how dynamic
   *&#64;&#64;   batching operates for the model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelDynamicBatching}
   */
  public  static final class ModelDynamicBatching extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelDynamicBatching)
      ModelDynamicBatchingOrBuilder {
    // Use ModelDynamicBatching.newBuilder() to construct.
    private ModelDynamicBatching(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelDynamicBatching() {
      preferredBatchSize_ = java.util.Collections.emptyList();
      maxQueueDelayMicroseconds_ = 0L;
      preserveOrdering_ = false;
      priorityLevels_ = 0;
      defaultPriorityLevel_ = 0;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelDynamicBatching(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                preferredBatchSize_ = new java.util.ArrayList<Integer>();
                mutable_bitField0_ |= 0x00000001;
              }
              preferredBatchSize_.add(input.readInt32());
              break;
            }
            case 10: {
              int length = input.readRawVarint32();
              int limit = input.pushLimit(length);
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001) && input.getBytesUntilLimit() > 0) {
                preferredBatchSize_ = new java.util.ArrayList<Integer>();
                mutable_bitField0_ |= 0x00000001;
              }
              while (input.getBytesUntilLimit() > 0) {
                preferredBatchSize_.add(input.readInt32());
              }
              input.popLimit(limit);
              break;
            }
            case 16: {

              maxQueueDelayMicroseconds_ = input.readUInt64();
              break;
            }
            case 24: {

              preserveOrdering_ = input.readBool();
              break;
            }
            case 32: {

              priorityLevels_ = input.readUInt32();
              break;
            }
            case 40: {

              defaultPriorityLevel_ = input.readUInt32();
              break;
            }
            case 50: {
              ModelConfigOuterClass.ModelQueuePolicy.Builder subBuilder = null;
              if (defaultQueuePolicy_ != null) {
                subBuilder = defaultQueuePolicy_.toBuilder();
              }
              defaultQueuePolicy_ = input.readMessage(ModelConfigOuterClass.ModelQueuePolicy.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(defaultQueuePolicy_);
                defaultQueuePolicy_ = subBuilder.buildPartial();
              }

              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                priorityQueuePolicy_ = com.google.protobuf.MapField.newMapField(
                    PriorityQueuePolicyDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000040;
              }
              com.google.protobuf.MapEntry<Integer, ModelConfigOuterClass.ModelQueuePolicy>
              priorityQueuePolicy = input.readMessage(
                  PriorityQueuePolicyDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              priorityQueuePolicy_.getMutableMap().put(priorityQueuePolicy.getKey(), priorityQueuePolicy.getValue());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          preferredBatchSize_ = java.util.Collections.unmodifiableList(preferredBatchSize_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 7:
          return internalGetPriorityQueuePolicy();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelDynamicBatching.class, ModelConfigOuterClass.ModelDynamicBatching.Builder.class);
    }

    private int bitField0_;
    public static final int PREFERRED_BATCH_SIZE_FIELD_NUMBER = 1;
    private java.util.List<Integer> preferredBatchSize_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    public java.util.List<Integer>
        getPreferredBatchSizeList() {
      return preferredBatchSize_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    public int getPreferredBatchSizeCount() {
      return preferredBatchSize_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
     *&#64;&#64;
     *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
     *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
     *&#64;&#64;     not specified a preferred batch size will be chosen automatically
     *&#64;&#64;     based on model and GPU characteristics.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated int32 preferred_batch_size = 1;</code>
     */
    public int getPreferredBatchSize(int index) {
      return preferredBatchSize_.get(index);
    }
    private int preferredBatchSizeMemoizedSerializedSize = -1;

    public static final int MAX_QUEUE_DELAY_MICROSECONDS_FIELD_NUMBER = 2;
    private long maxQueueDelayMicroseconds_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 max_queue_delay_microseconds
     *&#64;&#64;
     *&#64;&#64;     The maximum time, in microseconds, a request will be delayed in
     *&#64;&#64;     the scheduling queue to wait for additional requests for
     *&#64;&#64;     batching. Default is 0.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 max_queue_delay_microseconds = 2;</code>
     */
    public long getMaxQueueDelayMicroseconds() {
      return maxQueueDelayMicroseconds_;
    }

    public static final int PRESERVE_ORDERING_FIELD_NUMBER = 3;
    private boolean preserveOrdering_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool preserve_ordering
     *&#64;&#64;
     *&#64;&#64;     Should the dynamic batcher preserve the ordering of responses to
     *&#64;&#64;     match the order of requests received by the scheduler. Default is
     *&#64;&#64;     false. If true, the responses will be returned in the same order as
     *&#64;&#64;     the order of requests sent to the scheduler. If false, the responses
     *&#64;&#64;     may be returned in arbitrary order. This option is specifically
     *&#64;&#64;     needed when a sequence of related inference requests (i.e. inference
     *&#64;&#64;     requests with the same correlation ID) are sent to the dynamic
     *&#64;&#64;     batcher to ensure that the sequence responses are in the correct
     *&#64;&#64;     order.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool preserve_ordering = 3;</code>
     */
    public boolean getPreserveOrdering() {
      return preserveOrdering_;
    }

    public static final int PRIORITY_LEVELS_FIELD_NUMBER = 4;
    private int priorityLevels_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 priority_levels
     *&#64;&#64;
     *&#64;&#64;     The number of priority levels to be enabled for the model,
     *&#64;&#64;     the priority level starts from 1 and 1 is the highest priority.
     *&#64;&#64;     Requests are handled in priority order with all priority 1 requests
     *&#64;&#64;     processed before priority 2, all priority 2 requests processed before
     *&#64;&#64;     priority 3, etc. Requests with the same priority level will be
     *&#64;&#64;     handled in the order that they are received.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 priority_levels = 4;</code>
     */
    public int getPriorityLevels() {
      return priorityLevels_;
    }

    public static final int DEFAULT_PRIORITY_LEVEL_FIELD_NUMBER = 5;
    private int defaultPriorityLevel_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 default_priority_level
     *&#64;&#64;
     *&#64;&#64;     The priority level used for requests that don't specify their
     *&#64;&#64;     priority. The value must be in the range [ 1, 'priority_levels' ].
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 default_priority_level = 5;</code>
     */
    public int getDefaultPriorityLevel() {
      return defaultPriorityLevel_;
    }

    public static final int DEFAULT_QUEUE_POLICY_FIELD_NUMBER = 6;
    private ModelConfigOuterClass.ModelQueuePolicy defaultQueuePolicy_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    public boolean hasDefaultQueuePolicy() {
      return defaultQueuePolicy_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    public ModelConfigOuterClass.ModelQueuePolicy getDefaultQueuePolicy() {
      return defaultQueuePolicy_ == null ? ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance() : defaultQueuePolicy_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
     *&#64;&#64;
     *&#64;&#64;     The default queue policy used for requests that don't require
     *&#64;&#64;     priority handling and requests that specify priority levels where
     *&#64;&#64;     there is no specific policy given. If not specified, a policy with
     *&#64;&#64;     default field values will be used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
     */
    public ModelConfigOuterClass.ModelQueuePolicyOrBuilder getDefaultQueuePolicyOrBuilder() {
      return getDefaultQueuePolicy();
    }

    public static final int PRIORITY_QUEUE_POLICY_FIELD_NUMBER = 7;
    private static final class PriorityQueuePolicyDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          Integer, ModelConfigOuterClass.ModelQueuePolicy> defaultEntry =
              com.google.protobuf.MapEntry
              .<Integer, ModelConfigOuterClass.ModelQueuePolicy>newDefaultInstance(
                  ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.UINT32,
                  0,
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        Integer, ModelConfigOuterClass.ModelQueuePolicy> priorityQueuePolicy_;
    private com.google.protobuf.MapField<Integer, ModelConfigOuterClass.ModelQueuePolicy>
    internalGetPriorityQueuePolicy() {
      if (priorityQueuePolicy_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            PriorityQueuePolicyDefaultEntryHolder.defaultEntry);
      }
      return priorityQueuePolicy_;
    }

    public int getPriorityQueuePolicyCount() {
      return internalGetPriorityQueuePolicy().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    public boolean containsPriorityQueuePolicy(
        int key) {

      return internalGetPriorityQueuePolicy().getMap().containsKey(key);
    }
    /**
     * Use {@link #getPriorityQueuePolicyMap()} instead.
     */
    @Deprecated
    public java.util.Map<Integer, ModelQueuePolicy> getPriorityQueuePolicy() {
      return getPriorityQueuePolicyMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    public java.util.Map<Integer, ModelQueuePolicy> getPriorityQueuePolicyMap() {
      return internalGetPriorityQueuePolicy().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    public ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrDefault(
        int key,
        ModelConfigOuterClass.ModelQueuePolicy defaultValue) {

      java.util.Map<Integer, ModelQueuePolicy> map =
          internalGetPriorityQueuePolicy().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
     *&#64;&#64;
     *&#64;&#64;     Specify the queue policy for the priority level. The default queue
     *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
     *&#64;&#64;     policy.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
     */

    public ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrThrow(
        int key) {

      java.util.Map<Integer, ModelQueuePolicy> map =
          internalGetPriorityQueuePolicy().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      getSerializedSize();
      if (getPreferredBatchSizeList().size() > 0) {
        output.writeUInt32NoTag(10);
        output.writeUInt32NoTag(preferredBatchSizeMemoizedSerializedSize);
      }
      for (int i = 0; i < preferredBatchSize_.size(); i++) {
        output.writeInt32NoTag(preferredBatchSize_.get(i));
      }
      if (maxQueueDelayMicroseconds_ != 0L) {
        output.writeUInt64(2, maxQueueDelayMicroseconds_);
      }
      if (preserveOrdering_ != false) {
        output.writeBool(3, preserveOrdering_);
      }
      if (priorityLevels_ != 0) {
        output.writeUInt32(4, priorityLevels_);
      }
      if (defaultPriorityLevel_ != 0) {
        output.writeUInt32(5, defaultPriorityLevel_);
      }
      if (defaultQueuePolicy_ != null) {
        output.writeMessage(6, getDefaultQueuePolicy());
      }
      for (java.util.Map.Entry<Integer, ModelQueuePolicy> entry
           : internalGetPriorityQueuePolicy().getMap().entrySet()) {
        com.google.protobuf.MapEntry<Integer, ModelConfigOuterClass.ModelQueuePolicy>
        priorityQueuePolicy = PriorityQueuePolicyDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        output.writeMessage(7, priorityQueuePolicy);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < preferredBatchSize_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeInt32SizeNoTag(preferredBatchSize_.get(i));
        }
        size += dataSize;
        if (!getPreferredBatchSizeList().isEmpty()) {
          size += 1;
          size += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(dataSize);
        }
        preferredBatchSizeMemoizedSerializedSize = dataSize;
      }
      if (maxQueueDelayMicroseconds_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(2, maxQueueDelayMicroseconds_);
      }
      if (preserveOrdering_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(3, preserveOrdering_);
      }
      if (priorityLevels_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(4, priorityLevels_);
      }
      if (defaultPriorityLevel_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(5, defaultPriorityLevel_);
      }
      if (defaultQueuePolicy_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getDefaultQueuePolicy());
      }
      for (java.util.Map.Entry<Integer, ModelQueuePolicy> entry
           : internalGetPriorityQueuePolicy().getMap().entrySet()) {
        com.google.protobuf.MapEntry<Integer, ModelConfigOuterClass.ModelQueuePolicy>
        priorityQueuePolicy = PriorityQueuePolicyDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(7, priorityQueuePolicy);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelDynamicBatching)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelDynamicBatching other = (ModelConfigOuterClass.ModelDynamicBatching) obj;

      boolean result = true;
      result = result && getPreferredBatchSizeList()
          .equals(other.getPreferredBatchSizeList());
      result = result && (getMaxQueueDelayMicroseconds()
          == other.getMaxQueueDelayMicroseconds());
      result = result && (getPreserveOrdering()
          == other.getPreserveOrdering());
      result = result && (getPriorityLevels()
          == other.getPriorityLevels());
      result = result && (getDefaultPriorityLevel()
          == other.getDefaultPriorityLevel());
      result = result && (hasDefaultQueuePolicy() == other.hasDefaultQueuePolicy());
      if (hasDefaultQueuePolicy()) {
        result = result && getDefaultQueuePolicy()
            .equals(other.getDefaultQueuePolicy());
      }
      result = result && internalGetPriorityQueuePolicy().equals(
          other.internalGetPriorityQueuePolicy());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getPreferredBatchSizeCount() > 0) {
        hash = (37 * hash) + PREFERRED_BATCH_SIZE_FIELD_NUMBER;
        hash = (53 * hash) + getPreferredBatchSizeList().hashCode();
      }
      hash = (37 * hash) + MAX_QUEUE_DELAY_MICROSECONDS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getMaxQueueDelayMicroseconds());
      hash = (37 * hash) + PRESERVE_ORDERING_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getPreserveOrdering());
      hash = (37 * hash) + PRIORITY_LEVELS_FIELD_NUMBER;
      hash = (53 * hash) + getPriorityLevels();
      hash = (37 * hash) + DEFAULT_PRIORITY_LEVEL_FIELD_NUMBER;
      hash = (53 * hash) + getDefaultPriorityLevel();
      if (hasDefaultQueuePolicy()) {
        hash = (37 * hash) + DEFAULT_QUEUE_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultQueuePolicy().hashCode();
      }
      if (!internalGetPriorityQueuePolicy().getMap().isEmpty()) {
        hash = (37 * hash) + PRIORITY_QUEUE_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + internalGetPriorityQueuePolicy().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelDynamicBatching parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelDynamicBatching prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelDynamicBatching
     *&#64;&#64;
     *&#64;&#64;   Dynamic batching configuration. These settings control how dynamic
     *&#64;&#64;   batching operates for the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelDynamicBatching}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelDynamicBatching)
        ModelConfigOuterClass.ModelDynamicBatchingOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 7:
            return internalGetPriorityQueuePolicy();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 7:
            return internalGetMutablePriorityQueuePolicy();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelDynamicBatching.class, ModelConfigOuterClass.ModelDynamicBatching.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelDynamicBatching.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        preferredBatchSize_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        maxQueueDelayMicroseconds_ = 0L;

        preserveOrdering_ = false;

        priorityLevels_ = 0;

        defaultPriorityLevel_ = 0;

        if (defaultQueuePolicyBuilder_ == null) {
          defaultQueuePolicy_ = null;
        } else {
          defaultQueuePolicy_ = null;
          defaultQueuePolicyBuilder_ = null;
        }
        internalGetMutablePriorityQueuePolicy().clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelDynamicBatching_descriptor;
      }

      public ModelConfigOuterClass.ModelDynamicBatching getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelDynamicBatching build() {
        ModelConfigOuterClass.ModelDynamicBatching result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelDynamicBatching buildPartial() {
        ModelConfigOuterClass.ModelDynamicBatching result = new ModelConfigOuterClass.ModelDynamicBatching(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          preferredBatchSize_ = java.util.Collections.unmodifiableList(preferredBatchSize_);
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.preferredBatchSize_ = preferredBatchSize_;
        result.maxQueueDelayMicroseconds_ = maxQueueDelayMicroseconds_;
        result.preserveOrdering_ = preserveOrdering_;
        result.priorityLevels_ = priorityLevels_;
        result.defaultPriorityLevel_ = defaultPriorityLevel_;
        if (defaultQueuePolicyBuilder_ == null) {
          result.defaultQueuePolicy_ = defaultQueuePolicy_;
        } else {
          result.defaultQueuePolicy_ = defaultQueuePolicyBuilder_.build();
        }
        result.priorityQueuePolicy_ = internalGetPriorityQueuePolicy();
        result.priorityQueuePolicy_.makeImmutable();
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelDynamicBatching) {
          return mergeFrom((ModelConfigOuterClass.ModelDynamicBatching)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelDynamicBatching other) {
        if (other == ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance()) return this;
        if (!other.preferredBatchSize_.isEmpty()) {
          if (preferredBatchSize_.isEmpty()) {
            preferredBatchSize_ = other.preferredBatchSize_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensurePreferredBatchSizeIsMutable();
            preferredBatchSize_.addAll(other.preferredBatchSize_);
          }
          onChanged();
        }
        if (other.getMaxQueueDelayMicroseconds() != 0L) {
          setMaxQueueDelayMicroseconds(other.getMaxQueueDelayMicroseconds());
        }
        if (other.getPreserveOrdering() != false) {
          setPreserveOrdering(other.getPreserveOrdering());
        }
        if (other.getPriorityLevels() != 0) {
          setPriorityLevels(other.getPriorityLevels());
        }
        if (other.getDefaultPriorityLevel() != 0) {
          setDefaultPriorityLevel(other.getDefaultPriorityLevel());
        }
        if (other.hasDefaultQueuePolicy()) {
          mergeDefaultQueuePolicy(other.getDefaultQueuePolicy());
        }
        internalGetMutablePriorityQueuePolicy().mergeFrom(
            other.internalGetPriorityQueuePolicy());
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelDynamicBatching parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelDynamicBatching) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<Integer> preferredBatchSize_ = java.util.Collections.emptyList();
      private void ensurePreferredBatchSizeIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          preferredBatchSize_ = new java.util.ArrayList<Integer>(preferredBatchSize_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public java.util.List<Integer>
          getPreferredBatchSizeList() {
        return java.util.Collections.unmodifiableList(preferredBatchSize_);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public int getPreferredBatchSizeCount() {
        return preferredBatchSize_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public int getPreferredBatchSize(int index) {
        return preferredBatchSize_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public Builder setPreferredBatchSize(
          int index, int value) {
        ensurePreferredBatchSizeIsMutable();
        preferredBatchSize_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public Builder addPreferredBatchSize(int value) {
        ensurePreferredBatchSizeIsMutable();
        preferredBatchSize_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public Builder addAllPreferredBatchSize(
          Iterable<? extends Integer> values) {
        ensurePreferredBatchSizeIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, preferredBatchSize_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;     Preferred batch sizes for dynamic batching. If a batch of one of
       *&#64;&#64;     these sizes can be formed it will be executed immediately.  If
       *&#64;&#64;     not specified a preferred batch size will be chosen automatically
       *&#64;&#64;     based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 1;</code>
       */
      public Builder clearPreferredBatchSize() {
        preferredBatchSize_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }

      private long maxQueueDelayMicroseconds_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_queue_delay_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, a request will be delayed in
       *&#64;&#64;     the scheduling queue to wait for additional requests for
       *&#64;&#64;     batching. Default is 0.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_queue_delay_microseconds = 2;</code>
       */
      public long getMaxQueueDelayMicroseconds() {
        return maxQueueDelayMicroseconds_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_queue_delay_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, a request will be delayed in
       *&#64;&#64;     the scheduling queue to wait for additional requests for
       *&#64;&#64;     batching. Default is 0.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_queue_delay_microseconds = 2;</code>
       */
      public Builder setMaxQueueDelayMicroseconds(long value) {

        maxQueueDelayMicroseconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_queue_delay_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, a request will be delayed in
       *&#64;&#64;     the scheduling queue to wait for additional requests for
       *&#64;&#64;     batching. Default is 0.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_queue_delay_microseconds = 2;</code>
       */
      public Builder clearMaxQueueDelayMicroseconds() {

        maxQueueDelayMicroseconds_ = 0L;
        onChanged();
        return this;
      }

      private boolean preserveOrdering_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool preserve_ordering
       *&#64;&#64;
       *&#64;&#64;     Should the dynamic batcher preserve the ordering of responses to
       *&#64;&#64;     match the order of requests received by the scheduler. Default is
       *&#64;&#64;     false. If true, the responses will be returned in the same order as
       *&#64;&#64;     the order of requests sent to the scheduler. If false, the responses
       *&#64;&#64;     may be returned in arbitrary order. This option is specifically
       *&#64;&#64;     needed when a sequence of related inference requests (i.e. inference
       *&#64;&#64;     requests with the same correlation ID) are sent to the dynamic
       *&#64;&#64;     batcher to ensure that the sequence responses are in the correct
       *&#64;&#64;     order.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool preserve_ordering = 3;</code>
       */
      public boolean getPreserveOrdering() {
        return preserveOrdering_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool preserve_ordering
       *&#64;&#64;
       *&#64;&#64;     Should the dynamic batcher preserve the ordering of responses to
       *&#64;&#64;     match the order of requests received by the scheduler. Default is
       *&#64;&#64;     false. If true, the responses will be returned in the same order as
       *&#64;&#64;     the order of requests sent to the scheduler. If false, the responses
       *&#64;&#64;     may be returned in arbitrary order. This option is specifically
       *&#64;&#64;     needed when a sequence of related inference requests (i.e. inference
       *&#64;&#64;     requests with the same correlation ID) are sent to the dynamic
       *&#64;&#64;     batcher to ensure that the sequence responses are in the correct
       *&#64;&#64;     order.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool preserve_ordering = 3;</code>
       */
      public Builder setPreserveOrdering(boolean value) {

        preserveOrdering_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool preserve_ordering
       *&#64;&#64;
       *&#64;&#64;     Should the dynamic batcher preserve the ordering of responses to
       *&#64;&#64;     match the order of requests received by the scheduler. Default is
       *&#64;&#64;     false. If true, the responses will be returned in the same order as
       *&#64;&#64;     the order of requests sent to the scheduler. If false, the responses
       *&#64;&#64;     may be returned in arbitrary order. This option is specifically
       *&#64;&#64;     needed when a sequence of related inference requests (i.e. inference
       *&#64;&#64;     requests with the same correlation ID) are sent to the dynamic
       *&#64;&#64;     batcher to ensure that the sequence responses are in the correct
       *&#64;&#64;     order.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool preserve_ordering = 3;</code>
       */
      public Builder clearPreserveOrdering() {

        preserveOrdering_ = false;
        onChanged();
        return this;
      }

      private int priorityLevels_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 priority_levels
       *&#64;&#64;
       *&#64;&#64;     The number of priority levels to be enabled for the model,
       *&#64;&#64;     the priority level starts from 1 and 1 is the highest priority.
       *&#64;&#64;     Requests are handled in priority order with all priority 1 requests
       *&#64;&#64;     processed before priority 2, all priority 2 requests processed before
       *&#64;&#64;     priority 3, etc. Requests with the same priority level will be
       *&#64;&#64;     handled in the order that they are received.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 priority_levels = 4;</code>
       */
      public int getPriorityLevels() {
        return priorityLevels_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 priority_levels
       *&#64;&#64;
       *&#64;&#64;     The number of priority levels to be enabled for the model,
       *&#64;&#64;     the priority level starts from 1 and 1 is the highest priority.
       *&#64;&#64;     Requests are handled in priority order with all priority 1 requests
       *&#64;&#64;     processed before priority 2, all priority 2 requests processed before
       *&#64;&#64;     priority 3, etc. Requests with the same priority level will be
       *&#64;&#64;     handled in the order that they are received.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 priority_levels = 4;</code>
       */
      public Builder setPriorityLevels(int value) {

        priorityLevels_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 priority_levels
       *&#64;&#64;
       *&#64;&#64;     The number of priority levels to be enabled for the model,
       *&#64;&#64;     the priority level starts from 1 and 1 is the highest priority.
       *&#64;&#64;     Requests are handled in priority order with all priority 1 requests
       *&#64;&#64;     processed before priority 2, all priority 2 requests processed before
       *&#64;&#64;     priority 3, etc. Requests with the same priority level will be
       *&#64;&#64;     handled in the order that they are received.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 priority_levels = 4;</code>
       */
      public Builder clearPriorityLevels() {

        priorityLevels_ = 0;
        onChanged();
        return this;
      }

      private int defaultPriorityLevel_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 default_priority_level
       *&#64;&#64;
       *&#64;&#64;     The priority level used for requests that don't specify their
       *&#64;&#64;     priority. The value must be in the range [ 1, 'priority_levels' ].
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 default_priority_level = 5;</code>
       */
      public int getDefaultPriorityLevel() {
        return defaultPriorityLevel_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 default_priority_level
       *&#64;&#64;
       *&#64;&#64;     The priority level used for requests that don't specify their
       *&#64;&#64;     priority. The value must be in the range [ 1, 'priority_levels' ].
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 default_priority_level = 5;</code>
       */
      public Builder setDefaultPriorityLevel(int value) {

        defaultPriorityLevel_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 default_priority_level
       *&#64;&#64;
       *&#64;&#64;     The priority level used for requests that don't specify their
       *&#64;&#64;     priority. The value must be in the range [ 1, 'priority_levels' ].
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 default_priority_level = 5;</code>
       */
      public Builder clearDefaultPriorityLevel() {

        defaultPriorityLevel_ = 0;
        onChanged();
        return this;
      }

      private ModelConfigOuterClass.ModelQueuePolicy defaultQueuePolicy_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelQueuePolicy, ModelConfigOuterClass.ModelQueuePolicy.Builder, ModelConfigOuterClass.ModelQueuePolicyOrBuilder> defaultQueuePolicyBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public boolean hasDefaultQueuePolicy() {
        return defaultQueuePolicyBuilder_ != null || defaultQueuePolicy_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public ModelConfigOuterClass.ModelQueuePolicy getDefaultQueuePolicy() {
        if (defaultQueuePolicyBuilder_ == null) {
          return defaultQueuePolicy_ == null ? ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance() : defaultQueuePolicy_;
        } else {
          return defaultQueuePolicyBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public Builder setDefaultQueuePolicy(ModelConfigOuterClass.ModelQueuePolicy value) {
        if (defaultQueuePolicyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          defaultQueuePolicy_ = value;
          onChanged();
        } else {
          defaultQueuePolicyBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public Builder setDefaultQueuePolicy(
          ModelConfigOuterClass.ModelQueuePolicy.Builder builderForValue) {
        if (defaultQueuePolicyBuilder_ == null) {
          defaultQueuePolicy_ = builderForValue.build();
          onChanged();
        } else {
          defaultQueuePolicyBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public Builder mergeDefaultQueuePolicy(ModelConfigOuterClass.ModelQueuePolicy value) {
        if (defaultQueuePolicyBuilder_ == null) {
          if (defaultQueuePolicy_ != null) {
            defaultQueuePolicy_ =
              ModelConfigOuterClass.ModelQueuePolicy.newBuilder(defaultQueuePolicy_).mergeFrom(value).buildPartial();
          } else {
            defaultQueuePolicy_ = value;
          }
          onChanged();
        } else {
          defaultQueuePolicyBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public Builder clearDefaultQueuePolicy() {
        if (defaultQueuePolicyBuilder_ == null) {
          defaultQueuePolicy_ = null;
          onChanged();
        } else {
          defaultQueuePolicy_ = null;
          defaultQueuePolicyBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public ModelConfigOuterClass.ModelQueuePolicy.Builder getDefaultQueuePolicyBuilder() {

        onChanged();
        return getDefaultQueuePolicyFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      public ModelConfigOuterClass.ModelQueuePolicyOrBuilder getDefaultQueuePolicyOrBuilder() {
        if (defaultQueuePolicyBuilder_ != null) {
          return defaultQueuePolicyBuilder_.getMessageOrBuilder();
        } else {
          return defaultQueuePolicy_ == null ?
              ModelConfigOuterClass.ModelQueuePolicy.getDefaultInstance() : defaultQueuePolicy_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelQueuePolicy default_queue_policy
       *&#64;&#64;
       *&#64;&#64;     The default queue policy used for requests that don't require
       *&#64;&#64;     priority handling and requests that specify priority levels where
       *&#64;&#64;     there is no specific policy given. If not specified, a policy with
       *&#64;&#64;     default field values will be used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelQueuePolicy default_queue_policy = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelQueuePolicy, ModelConfigOuterClass.ModelQueuePolicy.Builder, ModelConfigOuterClass.ModelQueuePolicyOrBuilder>
          getDefaultQueuePolicyFieldBuilder() {
        if (defaultQueuePolicyBuilder_ == null) {
          defaultQueuePolicyBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelQueuePolicy, ModelConfigOuterClass.ModelQueuePolicy.Builder, ModelConfigOuterClass.ModelQueuePolicyOrBuilder>(
                  getDefaultQueuePolicy(),
                  getParentForChildren(),
                  isClean());
          defaultQueuePolicy_ = null;
        }
        return defaultQueuePolicyBuilder_;
      }

      private com.google.protobuf.MapField<
          Integer, ModelConfigOuterClass.ModelQueuePolicy> priorityQueuePolicy_;
      private com.google.protobuf.MapField<Integer, ModelConfigOuterClass.ModelQueuePolicy>
      internalGetPriorityQueuePolicy() {
        if (priorityQueuePolicy_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              PriorityQueuePolicyDefaultEntryHolder.defaultEntry);
        }
        return priorityQueuePolicy_;
      }
      private com.google.protobuf.MapField<Integer, ModelConfigOuterClass.ModelQueuePolicy>
      internalGetMutablePriorityQueuePolicy() {
        onChanged();;
        if (priorityQueuePolicy_ == null) {
          priorityQueuePolicy_ = com.google.protobuf.MapField.newMapField(
              PriorityQueuePolicyDefaultEntryHolder.defaultEntry);
        }
        if (!priorityQueuePolicy_.isMutable()) {
          priorityQueuePolicy_ = priorityQueuePolicy_.copy();
        }
        return priorityQueuePolicy_;
      }

      public int getPriorityQueuePolicyCount() {
        return internalGetPriorityQueuePolicy().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public boolean containsPriorityQueuePolicy(
          int key) {

        return internalGetPriorityQueuePolicy().getMap().containsKey(key);
      }
      /**
       * Use {@link #getPriorityQueuePolicyMap()} instead.
       */
      @Deprecated
      public java.util.Map<Integer, ModelQueuePolicy> getPriorityQueuePolicy() {
        return getPriorityQueuePolicyMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public java.util.Map<Integer, ModelQueuePolicy> getPriorityQueuePolicyMap() {
        return internalGetPriorityQueuePolicy().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrDefault(
          int key,
          ModelConfigOuterClass.ModelQueuePolicy defaultValue) {

        java.util.Map<Integer, ModelQueuePolicy> map =
            internalGetPriorityQueuePolicy().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public ModelConfigOuterClass.ModelQueuePolicy getPriorityQueuePolicyOrThrow(
          int key) {

        java.util.Map<Integer, ModelQueuePolicy> map =
            internalGetPriorityQueuePolicy().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearPriorityQueuePolicy() {
        getMutablePriorityQueuePolicy().clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public Builder removePriorityQueuePolicy(
          int key) {

        getMutablePriorityQueuePolicy().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<Integer, ModelQueuePolicy>
      getMutablePriorityQueuePolicy() {
        return internalGetMutablePriorityQueuePolicy().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */
      public Builder putPriorityQueuePolicy(
          int key,
          ModelConfigOuterClass.ModelQueuePolicy value) {

        if (value == null) { throw new NullPointerException(); }
        getMutablePriorityQueuePolicy().put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;uint32, ModelQueuePolicy&gt; priority_queue_policy
       *&#64;&#64;
       *&#64;&#64;     Specify the queue policy for the priority level. The default queue
       *&#64;&#64;     policy will be used if a priority level doesn't specify a queue
       *&#64;&#64;     policy.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;uint32, .inference.ModelQueuePolicy&gt; priority_queue_policy = 7;</code>
       */

      public Builder putAllPriorityQueuePolicy(
          java.util.Map<Integer, ModelQueuePolicy> values) {
        getMutablePriorityQueuePolicy().putAll(values);
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelDynamicBatching)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelDynamicBatching)
    private static final ModelConfigOuterClass.ModelDynamicBatching DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelDynamicBatching();
    }

    public static ModelConfigOuterClass.ModelDynamicBatching getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelDynamicBatching>
        PARSER = new com.google.protobuf.AbstractParser<ModelDynamicBatching>() {
      public ModelDynamicBatching parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelDynamicBatching(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelDynamicBatching> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelDynamicBatching> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelDynamicBatching getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelSequenceBatchingOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelSequenceBatching)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyDirect direct
     *&#64;&#64;
     *&#64;&#64;       StrategyDirect scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDirect();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyDirect direct
     *&#64;&#64;
     *&#64;&#64;       StrategyDirect scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder getDirectOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
     *&#64;&#64;
     *&#64;&#64;       StrategyOldest scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getOldest();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
     *&#64;&#64;
     *&#64;&#64;       StrategyOldest scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder getOldestOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 max_sequence_idle_microseconds
     *&#64;&#64;
     *&#64;&#64;     The maximum time, in microseconds, that a sequence is allowed to
     *&#64;&#64;     be idle before it is aborted. The inference server considers a
     *&#64;&#64;     sequence idle when it does not have any inference request queued
     *&#64;&#64;     for the sequence. If this limit is exceeded, the inference server
     *&#64;&#64;     will free the sequence slot allocated by the sequence and make it
     *&#64;&#64;     available for another sequence. If not specified (or specified as
     *&#64;&#64;     zero) a default value of 1000000 (1 second) is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 max_sequence_idle_microseconds = 1;</code>
     */
    long getMaxSequenceIdleMicroseconds();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    java.util.List<ModelSequenceBatching.ControlInput>
        getControlInputList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.ControlInput getControlInput(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    int getControlInputCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    java.util.List<? extends ModelSequenceBatching.ControlInputOrBuilder>
        getControlInputOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder getControlInputOrBuilder(
        int index);

    public ModelConfigOuterClass.ModelSequenceBatching.StrategyChoiceCase getStrategyChoiceCase();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelSequenceBatching
   *&#64;&#64;
   *&#64;&#64;   Sequence batching configuration. These settings control how sequence
   *&#64;&#64;   batching operates for the model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelSequenceBatching}
   */
  public  static final class ModelSequenceBatching extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelSequenceBatching)
      ModelSequenceBatchingOrBuilder {
    // Use ModelSequenceBatching.newBuilder() to construct.
    private ModelSequenceBatching(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelSequenceBatching() {
      maxSequenceIdleMicroseconds_ = 0L;
      controlInput_ = java.util.Collections.emptyList();
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelSequenceBatching(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {

              maxSequenceIdleMicroseconds_ = input.readUInt64();
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                controlInput_ = new java.util.ArrayList<ControlInput>();
                mutable_bitField0_ |= 0x00000008;
              }
              controlInput_.add(
                  input.readMessage(ModelConfigOuterClass.ModelSequenceBatching.ControlInput.parser(), extensionRegistry));
              break;
            }
            case 26: {
              ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder subBuilder = null;
              if (strategyChoiceCase_ == 3) {
                subBuilder = ((ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_).toBuilder();
              }
              strategyChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_);
                strategyChoice_ = subBuilder.buildPartial();
              }
              strategyChoiceCase_ = 3;
              break;
            }
            case 34: {
              ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder subBuilder = null;
              if (strategyChoiceCase_ == 4) {
                subBuilder = ((ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_).toBuilder();
              }
              strategyChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_);
                strategyChoice_ = subBuilder.buildPartial();
              }
              strategyChoiceCase_ = 4;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          controlInput_ = java.util.Collections.unmodifiableList(controlInput_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelSequenceBatching.class, ModelConfigOuterClass.ModelSequenceBatching.Builder.class);
    }

    public interface ControlOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelSequenceBatching.Control)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;       The kind of this control.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
       */
      int getKindValue();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;       The kind of this control.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
       */
      ModelConfigOuterClass.ModelSequenceBatching.Control.Kind getKind();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      java.util.List<Integer> getInt32FalseTrueList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      int getInt32FalseTrueCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      int getInt32FalseTrue(int index);

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      java.util.List<Float> getFp32FalseTrueList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      int getFp32FalseTrueCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      float getFp32FalseTrue(int index);

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The control's datatype.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 4;</code>
       */
      int getDataTypeValue();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The control's datatype.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 4;</code>
       */
      ModelConfigOuterClass.DataType getDataType();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message Control
     *&#64;&#64;
     *&#64;&#64;     A control is a signal that the sequence batcher uses to
     *&#64;&#64;     communicate with a backend.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelSequenceBatching.Control}
     */
    public  static final class Control extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelSequenceBatching.Control)
        ControlOrBuilder {
      // Use Control.newBuilder() to construct.
      private Control(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Control() {
        kind_ = 0;
        int32FalseTrue_ = java.util.Collections.emptyList();
        fp32FalseTrue_ = java.util.Collections.emptyList();
        dataType_ = 0;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Control(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {
                int rawValue = input.readEnum();

                kind_ = rawValue;
                break;
              }
              case 16: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  int32FalseTrue_ = new java.util.ArrayList<Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                int32FalseTrue_.add(input.readInt32());
                break;
              }
              case 18: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0) {
                  int32FalseTrue_ = new java.util.ArrayList<Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                while (input.getBytesUntilLimit() > 0) {
                  int32FalseTrue_.add(input.readInt32());
                }
                input.popLimit(limit);
                break;
              }
              case 29: {
                if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                  fp32FalseTrue_ = new java.util.ArrayList<Float>();
                  mutable_bitField0_ |= 0x00000004;
                }
                fp32FalseTrue_.add(input.readFloat());
                break;
              }
              case 26: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                if (!((mutable_bitField0_ & 0x00000004) == 0x00000004) && input.getBytesUntilLimit() > 0) {
                  fp32FalseTrue_ = new java.util.ArrayList<Float>();
                  mutable_bitField0_ |= 0x00000004;
                }
                while (input.getBytesUntilLimit() > 0) {
                  fp32FalseTrue_.add(input.readFloat());
                }
                input.popLimit(limit);
                break;
              }
              case 32: {
                int rawValue = input.readEnum();

                dataType_ = rawValue;
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            int32FalseTrue_ = java.util.Collections.unmodifiableList(int32FalseTrue_);
          }
          if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
            fp32FalseTrue_ = java.util.Collections.unmodifiableList(fp32FalseTrue_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_Control_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_Control_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelSequenceBatching.Control.class, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder.class);
      }

      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;    .. cpp:enum:: Kind
       *&#64;&#64;
       *&#64;&#64;       The kind of the control.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf enum {@code inference.ModelSequenceBatching.Control.Kind}
       */
      public enum Kind
          implements com.google.protobuf.ProtocolMessageEnum {
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_START = 0
         *&#64;&#64;
         *&#64;&#64;         A new sequence is/is-not starting. If true a sequence is
         *&#64;&#64;         starting, if false a sequence is continuing. Must
         *&#64;&#64;         specify either int32_false_true or fp32_false_true for
         *&#64;&#64;         this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_START = 0;</code>
         */
        CONTROL_SEQUENCE_START(0),
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_READY = 1
         *&#64;&#64;
         *&#64;&#64;         A sequence is/is-not ready for inference. If true the
         *&#64;&#64;         input tensor data is valid and should be used. If false
         *&#64;&#64;         the input tensor data is invalid and inferencing should
         *&#64;&#64;         be "skipped".  Must specify either int32_false_true or
         *&#64;&#64;         fp32_false_true for this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_READY = 1;</code>
         */
        CONTROL_SEQUENCE_READY(1),
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_END = 2
         *&#64;&#64;
         *&#64;&#64;         A sequence is/is-not ending. If true a sequence is
         *&#64;&#64;         ending, if false a sequence is continuing. Must
         *&#64;&#64;         specify either int32_false_true or fp32_false_true for
         *&#64;&#64;         this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_END = 2;</code>
         */
        CONTROL_SEQUENCE_END(2),
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_CORRID = 3
         *&#64;&#64;
         *&#64;&#64;         The correlation ID of the sequence. The correlation ID
         *&#64;&#64;         is an uint64_t value that is communicated in whole or
         *&#64;&#64;         in part by the tensor. The tensor's datatype must be
         *&#64;&#64;         specified by data_type and must be TYPE_UINT64, TYPE_INT64,
         *&#64;&#64;         TYPE_UINT32 or TYPE_INT32. If a 32-bit datatype is specified
         *&#64;&#64;         the correlation ID will be truncated to the low-order 32
         *&#64;&#64;         bits. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_CORRID = 3;</code>
         */
        CONTROL_SEQUENCE_CORRID(3),
        UNRECOGNIZED(-1),
        ;

        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_START = 0
         *&#64;&#64;
         *&#64;&#64;         A new sequence is/is-not starting. If true a sequence is
         *&#64;&#64;         starting, if false a sequence is continuing. Must
         *&#64;&#64;         specify either int32_false_true or fp32_false_true for
         *&#64;&#64;         this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_START = 0;</code>
         */
        public static final int CONTROL_SEQUENCE_START_VALUE = 0;
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_READY = 1
         *&#64;&#64;
         *&#64;&#64;         A sequence is/is-not ready for inference. If true the
         *&#64;&#64;         input tensor data is valid and should be used. If false
         *&#64;&#64;         the input tensor data is invalid and inferencing should
         *&#64;&#64;         be "skipped".  Must specify either int32_false_true or
         *&#64;&#64;         fp32_false_true for this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_READY = 1;</code>
         */
        public static final int CONTROL_SEQUENCE_READY_VALUE = 1;
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_END = 2
         *&#64;&#64;
         *&#64;&#64;         A sequence is/is-not ending. If true a sequence is
         *&#64;&#64;         ending, if false a sequence is continuing. Must
         *&#64;&#64;         specify either int32_false_true or fp32_false_true for
         *&#64;&#64;         this control. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_END = 2;</code>
         */
        public static final int CONTROL_SEQUENCE_END_VALUE = 2;
        /**
         * <pre>
         *&#64;&#64;      .. cpp:enumerator:: Kind::CONTROL_SEQUENCE_CORRID = 3
         *&#64;&#64;
         *&#64;&#64;         The correlation ID of the sequence. The correlation ID
         *&#64;&#64;         is an uint64_t value that is communicated in whole or
         *&#64;&#64;         in part by the tensor. The tensor's datatype must be
         *&#64;&#64;         specified by data_type and must be TYPE_UINT64, TYPE_INT64,
         *&#64;&#64;         TYPE_UINT32 or TYPE_INT32. If a 32-bit datatype is specified
         *&#64;&#64;         the correlation ID will be truncated to the low-order 32
         *&#64;&#64;         bits. This control is optional.
         *&#64;&#64;
         * </pre>
         *
         * <code>CONTROL_SEQUENCE_CORRID = 3;</code>
         */
        public static final int CONTROL_SEQUENCE_CORRID_VALUE = 3;


        public final int getNumber() {
          if (this == UNRECOGNIZED) {
            throw new IllegalArgumentException(
                "Can't get the number of an unknown enum value.");
          }
          return value;
        }

        /**
         * @deprecated Use {@link #forNumber(int)} instead.
         */
        @Deprecated
        public static Kind valueOf(int value) {
          return forNumber(value);
        }

        public static Kind forNumber(int value) {
          switch (value) {
            case 0: return CONTROL_SEQUENCE_START;
            case 1: return CONTROL_SEQUENCE_READY;
            case 2: return CONTROL_SEQUENCE_END;
            case 3: return CONTROL_SEQUENCE_CORRID;
            default: return null;
          }
        }

        public static com.google.protobuf.Internal.EnumLiteMap<Kind>
            internalGetValueMap() {
          return internalValueMap;
        }
        private static final com.google.protobuf.Internal.EnumLiteMap<
            Kind> internalValueMap =
              new com.google.protobuf.Internal.EnumLiteMap<Kind>() {
                public Kind findValueByNumber(int number) {
                  return Kind.forNumber(number);
                }
              };

        public final com.google.protobuf.Descriptors.EnumValueDescriptor
            getValueDescriptor() {
          return getDescriptor().getValues().get(ordinal());
        }
        public final com.google.protobuf.Descriptors.EnumDescriptor
            getDescriptorForType() {
          return getDescriptor();
        }
        public static final com.google.protobuf.Descriptors.EnumDescriptor
            getDescriptor() {
          return ModelConfigOuterClass.ModelSequenceBatching.Control.getDescriptor().getEnumTypes().get(0);
        }

        private static final Kind[] VALUES = values();

        public static Kind valueOf(
            com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
          if (desc.getType() != getDescriptor()) {
            throw new IllegalArgumentException(
              "EnumValueDescriptor is not for this type.");
          }
          if (desc.getIndex() == -1) {
            return UNRECOGNIZED;
          }
          return VALUES[desc.getIndex()];
        }

        private final int value;

        private Kind(int value) {
          this.value = value;
        }

        // @@protoc_insertion_point(enum_scope:inference.ModelSequenceBatching.Control.Kind)
      }

      private int bitField0_;
      public static final int KIND_FIELD_NUMBER = 1;
      private int kind_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;       The kind of this control.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
       */
      public int getKindValue() {
        return kind_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Kind kind
       *&#64;&#64;
       *&#64;&#64;       The kind of this control.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.Control.Kind getKind() {
        ModelConfigOuterClass.ModelSequenceBatching.Control.Kind result = ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.valueOf(kind_);
        return result == null ? ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.UNRECOGNIZED : result;
      }

      public static final int INT32_FALSE_TRUE_FIELD_NUMBER = 2;
      private java.util.List<Integer> int32FalseTrue_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      public java.util.List<Integer>
          getInt32FalseTrueList() {
        return int32FalseTrue_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      public int getInt32FalseTrueCount() {
        return int32FalseTrue_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in an int32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 int32_false_true = 2;</code>
       */
      public int getInt32FalseTrue(int index) {
        return int32FalseTrue_.get(index);
      }
      private int int32FalseTrueMemoizedSerializedSize = -1;

      public static final int FP32_FALSE_TRUE_FIELD_NUMBER = 3;
      private java.util.List<Float> fp32FalseTrue_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      public java.util.List<Float>
          getFp32FalseTrueList() {
        return fp32FalseTrue_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      public int getFp32FalseTrueCount() {
        return fp32FalseTrue_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control's true and false setting is indicated by setting
       *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
       *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
       *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
       *&#64;&#64;       first the false value and the second the true value.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated float fp32_false_true = 3;</code>
       */
      public float getFp32FalseTrue(int index) {
        return fp32FalseTrue_.get(index);
      }
      private int fp32FalseTrueMemoizedSerializedSize = -1;

      public static final int DATA_TYPE_FIELD_NUMBER = 4;
      private int dataType_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The control's datatype.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 4;</code>
       */
      public int getDataTypeValue() {
        return dataType_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The control's datatype.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 4;</code>
       */
      public ModelConfigOuterClass.DataType getDataType() {
        ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
        return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (kind_ != ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.CONTROL_SEQUENCE_START.getNumber()) {
          output.writeEnum(1, kind_);
        }
        if (getInt32FalseTrueList().size() > 0) {
          output.writeUInt32NoTag(18);
          output.writeUInt32NoTag(int32FalseTrueMemoizedSerializedSize);
        }
        for (int i = 0; i < int32FalseTrue_.size(); i++) {
          output.writeInt32NoTag(int32FalseTrue_.get(i));
        }
        if (getFp32FalseTrueList().size() > 0) {
          output.writeUInt32NoTag(26);
          output.writeUInt32NoTag(fp32FalseTrueMemoizedSerializedSize);
        }
        for (int i = 0; i < fp32FalseTrue_.size(); i++) {
          output.writeFloatNoTag(fp32FalseTrue_.get(i));
        }
        if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
          output.writeEnum(4, dataType_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (kind_ != ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.CONTROL_SEQUENCE_START.getNumber()) {
          size += com.google.protobuf.CodedOutputStream
            .computeEnumSize(1, kind_);
        }
        {
          int dataSize = 0;
          for (int i = 0; i < int32FalseTrue_.size(); i++) {
            dataSize += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(int32FalseTrue_.get(i));
          }
          size += dataSize;
          if (!getInt32FalseTrueList().isEmpty()) {
            size += 1;
            size += com.google.protobuf.CodedOutputStream
                .computeInt32SizeNoTag(dataSize);
          }
          int32FalseTrueMemoizedSerializedSize = dataSize;
        }
        {
          int dataSize = 0;
          dataSize = 4 * getFp32FalseTrueList().size();
          size += dataSize;
          if (!getFp32FalseTrueList().isEmpty()) {
            size += 1;
            size += com.google.protobuf.CodedOutputStream
                .computeInt32SizeNoTag(dataSize);
          }
          fp32FalseTrueMemoizedSerializedSize = dataSize;
        }
        if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
          size += com.google.protobuf.CodedOutputStream
            .computeEnumSize(4, dataType_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelSequenceBatching.Control)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelSequenceBatching.Control other = (ModelConfigOuterClass.ModelSequenceBatching.Control) obj;

        boolean result = true;
        result = result && kind_ == other.kind_;
        result = result && getInt32FalseTrueList()
            .equals(other.getInt32FalseTrueList());
        result = result && getFp32FalseTrueList()
            .equals(other.getFp32FalseTrueList());
        result = result && dataType_ == other.dataType_;
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + KIND_FIELD_NUMBER;
        hash = (53 * hash) + kind_;
        if (getInt32FalseTrueCount() > 0) {
          hash = (37 * hash) + INT32_FALSE_TRUE_FIELD_NUMBER;
          hash = (53 * hash) + getInt32FalseTrueList().hashCode();
        }
        if (getFp32FalseTrueCount() > 0) {
          hash = (37 * hash) + FP32_FALSE_TRUE_FIELD_NUMBER;
          hash = (53 * hash) + getFp32FalseTrueList().hashCode();
        }
        hash = (37 * hash) + DATA_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + dataType_;
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.Control parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelSequenceBatching.Control prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message Control
       *&#64;&#64;
       *&#64;&#64;     A control is a signal that the sequence batcher uses to
       *&#64;&#64;     communicate with a backend.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelSequenceBatching.Control}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelSequenceBatching.Control)
          ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_Control_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_Control_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelSequenceBatching.Control.class, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelSequenceBatching.Control.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          kind_ = 0;

          int32FalseTrue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          fp32FalseTrue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          dataType_ = 0;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_Control_descriptor;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.Control getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelSequenceBatching.Control.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelSequenceBatching.Control build() {
          ModelConfigOuterClass.ModelSequenceBatching.Control result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.Control buildPartial() {
          ModelConfigOuterClass.ModelSequenceBatching.Control result = new ModelConfigOuterClass.ModelSequenceBatching.Control(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          result.kind_ = kind_;
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            int32FalseTrue_ = java.util.Collections.unmodifiableList(int32FalseTrue_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.int32FalseTrue_ = int32FalseTrue_;
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            fp32FalseTrue_ = java.util.Collections.unmodifiableList(fp32FalseTrue_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.fp32FalseTrue_ = fp32FalseTrue_;
          result.dataType_ = dataType_;
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelSequenceBatching.Control) {
            return mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.Control)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelSequenceBatching.Control other) {
          if (other == ModelConfigOuterClass.ModelSequenceBatching.Control.getDefaultInstance()) return this;
          if (other.kind_ != 0) {
            setKindValue(other.getKindValue());
          }
          if (!other.int32FalseTrue_.isEmpty()) {
            if (int32FalseTrue_.isEmpty()) {
              int32FalseTrue_ = other.int32FalseTrue_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureInt32FalseTrueIsMutable();
              int32FalseTrue_.addAll(other.int32FalseTrue_);
            }
            onChanged();
          }
          if (!other.fp32FalseTrue_.isEmpty()) {
            if (fp32FalseTrue_.isEmpty()) {
              fp32FalseTrue_ = other.fp32FalseTrue_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureFp32FalseTrueIsMutable();
              fp32FalseTrue_.addAll(other.fp32FalseTrue_);
            }
            onChanged();
          }
          if (other.dataType_ != 0) {
            setDataTypeValue(other.getDataTypeValue());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelSequenceBatching.Control parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelSequenceBatching.Control) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private int kind_ = 0;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Kind kind
         *&#64;&#64;
         *&#64;&#64;       The kind of this control.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
         */
        public int getKindValue() {
          return kind_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Kind kind
         *&#64;&#64;
         *&#64;&#64;       The kind of this control.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
         */
        public Builder setKindValue(int value) {
          kind_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Kind kind
         *&#64;&#64;
         *&#64;&#64;       The kind of this control.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.Control.Kind getKind() {
          ModelConfigOuterClass.ModelSequenceBatching.Control.Kind result = ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.valueOf(kind_);
          return result == null ? ModelConfigOuterClass.ModelSequenceBatching.Control.Kind.UNRECOGNIZED : result;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Kind kind
         *&#64;&#64;
         *&#64;&#64;       The kind of this control.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
         */
        public Builder setKind(ModelConfigOuterClass.ModelSequenceBatching.Control.Kind value) {
          if (value == null) {
            throw new NullPointerException();
          }

          kind_ = value.getNumber();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Kind kind
         *&#64;&#64;
         *&#64;&#64;       The kind of this control.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.ModelSequenceBatching.Control.Kind kind = 1;</code>
         */
        public Builder clearKind() {

          kind_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<Integer> int32FalseTrue_ = java.util.Collections.emptyList();
        private void ensureInt32FalseTrueIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            int32FalseTrue_ = new java.util.ArrayList<Integer>(int32FalseTrue_);
            bitField0_ |= 0x00000002;
           }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public java.util.List<Integer>
            getInt32FalseTrueList() {
          return java.util.Collections.unmodifiableList(int32FalseTrue_);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public int getInt32FalseTrueCount() {
          return int32FalseTrue_.size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public int getInt32FalseTrue(int index) {
          return int32FalseTrue_.get(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public Builder setInt32FalseTrue(
            int index, int value) {
          ensureInt32FalseTrueIsMutable();
          int32FalseTrue_.set(index, value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public Builder addInt32FalseTrue(int value) {
          ensureInt32FalseTrueIsMutable();
          int32FalseTrue_.add(value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public Builder addAllInt32FalseTrue(
            Iterable<? extends Integer> values) {
          ensureInt32FalseTrueIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, int32FalseTrue_);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 int32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in an int32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'int32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 int32_false_true = 2;</code>
         */
        public Builder clearInt32FalseTrue() {
          int32FalseTrue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }

        private java.util.List<Float> fp32FalseTrue_ = java.util.Collections.emptyList();
        private void ensureFp32FalseTrueIsMutable() {
          if (!((bitField0_ & 0x00000004) == 0x00000004)) {
            fp32FalseTrue_ = new java.util.ArrayList<Float>(fp32FalseTrue_);
            bitField0_ |= 0x00000004;
           }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public java.util.List<Float>
            getFp32FalseTrueList() {
          return java.util.Collections.unmodifiableList(fp32FalseTrue_);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public int getFp32FalseTrueCount() {
          return fp32FalseTrue_.size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public float getFp32FalseTrue(int index) {
          return fp32FalseTrue_.get(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public Builder setFp32FalseTrue(
            int index, float value) {
          ensureFp32FalseTrueIsMutable();
          fp32FalseTrue_.set(index, value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public Builder addFp32FalseTrue(float value) {
          ensureFp32FalseTrueIsMutable();
          fp32FalseTrue_.add(value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public Builder addAllFp32FalseTrue(
            Iterable<? extends Float> values) {
          ensureFp32FalseTrueIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, fp32FalseTrue_);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: float fp32_false_true (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control's true and false setting is indicated by setting
         *&#64;&#64;       a value in a fp32 tensor. The tensor must be a
         *&#64;&#64;       1-dimensional tensor with size equal to the batch size of
         *&#64;&#64;       the request. 'fp32_false_true' must have two entries: the
         *&#64;&#64;       first the false value and the second the true value.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated float fp32_false_true = 3;</code>
         */
        public Builder clearFp32FalseTrue() {
          fp32FalseTrue_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
          return this;
        }

        private int dataType_ = 0;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The control's datatype.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 4;</code>
         */
        public int getDataTypeValue() {
          return dataType_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The control's datatype.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 4;</code>
         */
        public Builder setDataTypeValue(int value) {
          dataType_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The control's datatype.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 4;</code>
         */
        public ModelConfigOuterClass.DataType getDataType() {
          ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
          return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The control's datatype.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 4;</code>
         */
        public Builder setDataType(ModelConfigOuterClass.DataType value) {
          if (value == null) {
            throw new NullPointerException();
          }

          dataType_ = value.getNumber();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The control's datatype.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 4;</code>
         */
        public Builder clearDataType() {

          dataType_ = 0;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelSequenceBatching.Control)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.Control)
      private static final ModelConfigOuterClass.ModelSequenceBatching.Control DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelSequenceBatching.Control();
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.Control getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Control>
          PARSER = new com.google.protobuf.AbstractParser<Control>() {
        public Control parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Control(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Control> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Control> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelSequenceBatching.Control getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface ControlInputOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelSequenceBatching.ControlInput)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The name of the model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      String getName();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The name of the model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      com.google.protobuf.ByteString
          getNameBytes();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      java.util.List<Control>
          getControlList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      ModelConfigOuterClass.ModelSequenceBatching.Control getControl(int index);
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      int getControlCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      java.util.List<? extends ControlOrBuilder>
          getControlOrBuilderList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder getControlOrBuilder(
          int index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message ControlInput
     *&#64;&#64;
     *&#64;&#64;     The sequence control values to communicate by a model input.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelSequenceBatching.ControlInput}
     */
    public  static final class ControlInput extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelSequenceBatching.ControlInput)
        ControlInputOrBuilder {
      // Use ControlInput.newBuilder() to construct.
      private ControlInput(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private ControlInput() {
        name_ = "";
        control_ = java.util.Collections.emptyList();
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private ControlInput(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                String s = input.readStringRequireUtf8();

                name_ = s;
                break;
              }
              case 18: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  control_ = new java.util.ArrayList<Control>();
                  mutable_bitField0_ |= 0x00000002;
                }
                control_.add(
                    input.readMessage(ModelConfigOuterClass.ModelSequenceBatching.Control.parser(), extensionRegistry));
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            control_ = java.util.Collections.unmodifiableList(control_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_ControlInput_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_ControlInput_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelSequenceBatching.ControlInput.class, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder.class);
      }

      private int bitField0_;
      public static final int NAME_FIELD_NUMBER = 1;
      private volatile Object name_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The name of the model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (ref instanceof String) {
          return (String) ref;
        } else {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;       The name of the model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int CONTROL_FIELD_NUMBER = 2;
      private java.util.List<Control> control_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      public java.util.List<Control> getControlList() {
        return control_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      public java.util.List<? extends ControlOrBuilder>
          getControlOrBuilderList() {
        return control_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      public int getControlCount() {
        return control_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.Control getControl(int index) {
        return control_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: Control control (repeated)
       *&#64;&#64;
       *&#64;&#64;       The control value(s) that should be communicated to the
       *&#64;&#64;       model using this model input.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder getControlOrBuilder(
          int index) {
        return control_.get(index);
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!getNameBytes().isEmpty()) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
        }
        for (int i = 0; i < control_.size(); i++) {
          output.writeMessage(2, control_.get(i));
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!getNameBytes().isEmpty()) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
        }
        for (int i = 0; i < control_.size(); i++) {
          size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(2, control_.get(i));
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelSequenceBatching.ControlInput)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelSequenceBatching.ControlInput other = (ModelConfigOuterClass.ModelSequenceBatching.ControlInput) obj;

        boolean result = true;
        result = result && getName()
            .equals(other.getName());
        result = result && getControlList()
            .equals(other.getControlList());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
        if (getControlCount() > 0) {
          hash = (37 * hash) + CONTROL_FIELD_NUMBER;
          hash = (53 * hash) + getControlList().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelSequenceBatching.ControlInput prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message ControlInput
       *&#64;&#64;
       *&#64;&#64;     The sequence control values to communicate by a model input.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelSequenceBatching.ControlInput}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelSequenceBatching.ControlInput)
          ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_ControlInput_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_ControlInput_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelSequenceBatching.ControlInput.class, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelSequenceBatching.ControlInput.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
            getControlFieldBuilder();
          }
        }
        public Builder clear() {
          super.clear();
          name_ = "";

          if (controlBuilder_ == null) {
            control_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            controlBuilder_.clear();
          }
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_ControlInput_descriptor;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.ControlInput getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelSequenceBatching.ControlInput.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelSequenceBatching.ControlInput build() {
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.ControlInput buildPartial() {
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput result = new ModelConfigOuterClass.ModelSequenceBatching.ControlInput(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          result.name_ = name_;
          if (controlBuilder_ == null) {
            if (((bitField0_ & 0x00000002) == 0x00000002)) {
              control_ = java.util.Collections.unmodifiableList(control_);
              bitField0_ = (bitField0_ & ~0x00000002);
            }
            result.control_ = control_;
          } else {
            result.control_ = controlBuilder_.build();
          }
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelSequenceBatching.ControlInput) {
            return mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.ControlInput)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelSequenceBatching.ControlInput other) {
          if (other == ModelConfigOuterClass.ModelSequenceBatching.ControlInput.getDefaultInstance()) return this;
          if (!other.getName().isEmpty()) {
            name_ = other.name_;
            onChanged();
          }
          if (controlBuilder_ == null) {
            if (!other.control_.isEmpty()) {
              if (control_.isEmpty()) {
                control_ = other.control_;
                bitField0_ = (bitField0_ & ~0x00000002);
              } else {
                ensureControlIsMutable();
                control_.addAll(other.control_);
              }
              onChanged();
            }
          } else {
            if (!other.control_.isEmpty()) {
              if (controlBuilder_.isEmpty()) {
                controlBuilder_.dispose();
                controlBuilder_ = null;
                control_ = other.control_;
                bitField0_ = (bitField0_ & ~0x00000002);
                controlBuilder_ =
                  com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                     getControlFieldBuilder() : null;
              } else {
                controlBuilder_.addAllMessages(other.control_);
              }
            }
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelSequenceBatching.ControlInput) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private Object name_ = "";
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public String getName() {
          Object ref = name_;
          if (!(ref instanceof String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            String s = bs.toStringUtf8();
            name_ = s;
            return s;
          } else {
            return (String) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public com.google.protobuf.ByteString
            getNameBytes() {
          Object ref = name_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8(
                    (String) ref);
            name_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public Builder setName(
            String value) {
          if (value == null) {
    throw new NullPointerException();
  }

          name_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public Builder clearName() {

          name_ = getDefaultInstance().getName();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string name
         *&#64;&#64;
         *&#64;&#64;       The name of the model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string name = 1;</code>
         */
        public Builder setNameBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

          name_ = value;
          onChanged();
          return this;
        }

        private java.util.List<Control> control_ =
          java.util.Collections.emptyList();
        private void ensureControlIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            control_ = new java.util.ArrayList<Control>(control_);
            bitField0_ |= 0x00000002;
           }
        }

        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelSequenceBatching.Control, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder> controlBuilder_;

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public java.util.List<Control> getControlList() {
          if (controlBuilder_ == null) {
            return java.util.Collections.unmodifiableList(control_);
          } else {
            return controlBuilder_.getMessageList();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public int getControlCount() {
          if (controlBuilder_ == null) {
            return control_.size();
          } else {
            return controlBuilder_.getCount();
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.Control getControl(int index) {
          if (controlBuilder_ == null) {
            return control_.get(index);
          } else {
            return controlBuilder_.getMessage(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder setControl(
            int index, ModelConfigOuterClass.ModelSequenceBatching.Control value) {
          if (controlBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureControlIsMutable();
            control_.set(index, value);
            onChanged();
          } else {
            controlBuilder_.setMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder setControl(
            int index, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder builderForValue) {
          if (controlBuilder_ == null) {
            ensureControlIsMutable();
            control_.set(index, builderForValue.build());
            onChanged();
          } else {
            controlBuilder_.setMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder addControl(ModelConfigOuterClass.ModelSequenceBatching.Control value) {
          if (controlBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureControlIsMutable();
            control_.add(value);
            onChanged();
          } else {
            controlBuilder_.addMessage(value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder addControl(
            int index, ModelConfigOuterClass.ModelSequenceBatching.Control value) {
          if (controlBuilder_ == null) {
            if (value == null) {
              throw new NullPointerException();
            }
            ensureControlIsMutable();
            control_.add(index, value);
            onChanged();
          } else {
            controlBuilder_.addMessage(index, value);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder addControl(
            ModelConfigOuterClass.ModelSequenceBatching.Control.Builder builderForValue) {
          if (controlBuilder_ == null) {
            ensureControlIsMutable();
            control_.add(builderForValue.build());
            onChanged();
          } else {
            controlBuilder_.addMessage(builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder addControl(
            int index, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder builderForValue) {
          if (controlBuilder_ == null) {
            ensureControlIsMutable();
            control_.add(index, builderForValue.build());
            onChanged();
          } else {
            controlBuilder_.addMessage(index, builderForValue.build());
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder addAllControl(
            Iterable<? extends Control> values) {
          if (controlBuilder_ == null) {
            ensureControlIsMutable();
            com.google.protobuf.AbstractMessageLite.Builder.addAll(
                values, control_);
            onChanged();
          } else {
            controlBuilder_.addAllMessages(values);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder clearControl() {
          if (controlBuilder_ == null) {
            control_ = java.util.Collections.emptyList();
            bitField0_ = (bitField0_ & ~0x00000002);
            onChanged();
          } else {
            controlBuilder_.clear();
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public Builder removeControl(int index) {
          if (controlBuilder_ == null) {
            ensureControlIsMutable();
            control_.remove(index);
            onChanged();
          } else {
            controlBuilder_.remove(index);
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.Control.Builder getControlBuilder(
            int index) {
          return getControlFieldBuilder().getBuilder(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder getControlOrBuilder(
            int index) {
          if (controlBuilder_ == null) {
            return control_.get(index);  } else {
            return controlBuilder_.getMessageOrBuilder(index);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public java.util.List<? extends ControlOrBuilder>
             getControlOrBuilderList() {
          if (controlBuilder_ != null) {
            return controlBuilder_.getMessageOrBuilderList();
          } else {
            return java.util.Collections.unmodifiableList(control_);
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.Control.Builder addControlBuilder() {
          return getControlFieldBuilder().addBuilder(
              ModelConfigOuterClass.ModelSequenceBatching.Control.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public ModelConfigOuterClass.ModelSequenceBatching.Control.Builder addControlBuilder(
            int index) {
          return getControlFieldBuilder().addBuilder(
              index, ModelConfigOuterClass.ModelSequenceBatching.Control.getDefaultInstance());
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: Control control (repeated)
         *&#64;&#64;
         *&#64;&#64;       The control value(s) that should be communicated to the
         *&#64;&#64;       model using this model input.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated .inference.ModelSequenceBatching.Control control = 2;</code>
         */
        public java.util.List<Control.Builder>
             getControlBuilderList() {
          return getControlFieldBuilder().getBuilderList();
        }
        private com.google.protobuf.RepeatedFieldBuilderV3<
            ModelConfigOuterClass.ModelSequenceBatching.Control, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder>
            getControlFieldBuilder() {
          if (controlBuilder_ == null) {
            controlBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
                ModelConfigOuterClass.ModelSequenceBatching.Control, ModelConfigOuterClass.ModelSequenceBatching.Control.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlOrBuilder>(
                    control_,
                    ((bitField0_ & 0x00000002) == 0x00000002),
                    getParentForChildren(),
                    isClean());
            control_ = null;
          }
          return controlBuilder_;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelSequenceBatching.ControlInput)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.ControlInput)
      private static final ModelConfigOuterClass.ModelSequenceBatching.ControlInput DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelSequenceBatching.ControlInput();
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.ControlInput getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<ControlInput>
          PARSER = new com.google.protobuf.AbstractParser<ControlInput>() {
        public ControlInput parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new ControlInput(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<ControlInput> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<ControlInput> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelSequenceBatching.ControlInput getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface StrategyDirectOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelSequenceBatching.StrategyDirect)
        com.google.protobuf.MessageOrBuilder {
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message StrategyDirect
     *&#64;&#64;
     *&#64;&#64;     The sequence batcher uses a specific, unique batch
     *&#64;&#64;     slot for each sequence. All inference requests in a
     *&#64;&#64;     sequence are directed to the same batch slot in the same
     *&#64;&#64;     model instance over the lifetime of the sequence. This
     *&#64;&#64;     is the default strategy.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelSequenceBatching.StrategyDirect}
     */
    public  static final class StrategyDirect extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelSequenceBatching.StrategyDirect)
        StrategyDirectOrBuilder {
      // Use StrategyDirect.newBuilder() to construct.
      private StrategyDirect(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private StrategyDirect() {
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private StrategyDirect(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyDirect_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.class, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder.class);
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect other = (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) obj;

        boolean result = true;
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message StrategyDirect
       *&#64;&#64;
       *&#64;&#64;     The sequence batcher uses a specific, unique batch
       *&#64;&#64;     slot for each sequence. All inference requests in a
       *&#64;&#64;     sequence are directed to the same batch slot in the same
       *&#64;&#64;     model instance over the lifetime of the sequence. This
       *&#64;&#64;     is the default strategy.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelSequenceBatching.StrategyDirect}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelSequenceBatching.StrategyDirect)
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyDirect_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.class, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect build() {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect buildPartial() {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect result = new ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect(this);
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) {
            return mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect other) {
          if (other == ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance()) return this;
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelSequenceBatching.StrategyDirect)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.StrategyDirect)
      private static final ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect();
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<StrategyDirect>
          PARSER = new com.google.protobuf.AbstractParser<StrategyDirect>() {
        public StrategyDirect parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new StrategyDirect(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<StrategyDirect> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<StrategyDirect> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public interface StrategyOldestOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelSequenceBatching.StrategyOldest)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 max_candidate_sequences
       *&#64;&#64;
       *&#64;&#64;       Maximum number of candidate sequences that the batcher
       *&#64;&#64;       maintains. Excess seqences are kept in an ordered backlog
       *&#64;&#64;       and become candidates when existing candidate sequences
       *&#64;&#64;       complete.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 max_candidate_sequences = 1;</code>
       */
      int getMaxCandidateSequences();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      java.util.List<Integer> getPreferredBatchSizeList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      int getPreferredBatchSizeCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      int getPreferredBatchSize(int index);

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: uint64 max_queue_delay_microseconds
       *&#64;&#64;
       *&#64;&#64;       The maximum time, in microseconds, a candidate request
       *&#64;&#64;       will be delayed in the dynamic batch scheduling queue to
       *&#64;&#64;       wait for additional requests for batching. Default is 0.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_queue_delay_microseconds = 3;</code>
       */
      long getMaxQueueDelayMicroseconds();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message StrategyOldest
     *&#64;&#64;
     *&#64;&#64;     The sequence batcher maintains up to 'max_candidate_sequences'
     *&#64;&#64;     candidate sequences. 'max_candidate_sequences' can be greater
     *&#64;&#64;     than the model's 'max_batch_size'. For inferencing the batcher
     *&#64;&#64;     chooses from the candidate sequences up to 'max_batch_size'
     *&#64;&#64;     inference requests. Requests are chosen in an oldest-first
     *&#64;&#64;     manner across all candidate sequences. A given sequence is
     *&#64;&#64;     not guaranteed to be assigned to the same batch slot for
     *&#64;&#64;     all inference requests of that sequence.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelSequenceBatching.StrategyOldest}
     */
    public  static final class StrategyOldest extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelSequenceBatching.StrategyOldest)
        StrategyOldestOrBuilder {
      // Use StrategyOldest.newBuilder() to construct.
      private StrategyOldest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private StrategyOldest() {
        maxCandidateSequences_ = 0;
        preferredBatchSize_ = java.util.Collections.emptyList();
        maxQueueDelayMicroseconds_ = 0L;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private StrategyOldest(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {

                maxCandidateSequences_ = input.readInt32();
                break;
              }
              case 16: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  preferredBatchSize_ = new java.util.ArrayList<Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                preferredBatchSize_.add(input.readInt32());
                break;
              }
              case 18: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0) {
                  preferredBatchSize_ = new java.util.ArrayList<Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                while (input.getBytesUntilLimit() > 0) {
                  preferredBatchSize_.add(input.readInt32());
                }
                input.popLimit(limit);
                break;
              }
              case 24: {

                maxQueueDelayMicroseconds_ = input.readUInt64();
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            preferredBatchSize_ = java.util.Collections.unmodifiableList(preferredBatchSize_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyOldest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.class, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder.class);
      }

      private int bitField0_;
      public static final int MAX_CANDIDATE_SEQUENCES_FIELD_NUMBER = 1;
      private int maxCandidateSequences_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 max_candidate_sequences
       *&#64;&#64;
       *&#64;&#64;       Maximum number of candidate sequences that the batcher
       *&#64;&#64;       maintains. Excess seqences are kept in an ordered backlog
       *&#64;&#64;       and become candidates when existing candidate sequences
       *&#64;&#64;       complete.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 max_candidate_sequences = 1;</code>
       */
      public int getMaxCandidateSequences() {
        return maxCandidateSequences_;
      }

      public static final int PREFERRED_BATCH_SIZE_FIELD_NUMBER = 2;
      private java.util.List<Integer> preferredBatchSize_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      public java.util.List<Integer>
          getPreferredBatchSizeList() {
        return preferredBatchSize_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      public int getPreferredBatchSizeCount() {
        return preferredBatchSize_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
       *&#64;&#64;
       *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
       *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
       *&#64;&#64;       it will be executed immediately.  If not specified a
       *&#64;&#64;       preferred batch size will be chosen automatically
       *&#64;&#64;       based on model and GPU characteristics.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int32 preferred_batch_size = 2;</code>
       */
      public int getPreferredBatchSize(int index) {
        return preferredBatchSize_.get(index);
      }
      private int preferredBatchSizeMemoizedSerializedSize = -1;

      public static final int MAX_QUEUE_DELAY_MICROSECONDS_FIELD_NUMBER = 3;
      private long maxQueueDelayMicroseconds_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: uint64 max_queue_delay_microseconds
       *&#64;&#64;
       *&#64;&#64;       The maximum time, in microseconds, a candidate request
       *&#64;&#64;       will be delayed in the dynamic batch scheduling queue to
       *&#64;&#64;       wait for additional requests for batching. Default is 0.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_queue_delay_microseconds = 3;</code>
       */
      public long getMaxQueueDelayMicroseconds() {
        return maxQueueDelayMicroseconds_;
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (maxCandidateSequences_ != 0) {
          output.writeInt32(1, maxCandidateSequences_);
        }
        if (getPreferredBatchSizeList().size() > 0) {
          output.writeUInt32NoTag(18);
          output.writeUInt32NoTag(preferredBatchSizeMemoizedSerializedSize);
        }
        for (int i = 0; i < preferredBatchSize_.size(); i++) {
          output.writeInt32NoTag(preferredBatchSize_.get(i));
        }
        if (maxQueueDelayMicroseconds_ != 0L) {
          output.writeUInt64(3, maxQueueDelayMicroseconds_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (maxCandidateSequences_ != 0) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt32Size(1, maxCandidateSequences_);
        }
        {
          int dataSize = 0;
          for (int i = 0; i < preferredBatchSize_.size(); i++) {
            dataSize += com.google.protobuf.CodedOutputStream
              .computeInt32SizeNoTag(preferredBatchSize_.get(i));
          }
          size += dataSize;
          if (!getPreferredBatchSizeList().isEmpty()) {
            size += 1;
            size += com.google.protobuf.CodedOutputStream
                .computeInt32SizeNoTag(dataSize);
          }
          preferredBatchSizeMemoizedSerializedSize = dataSize;
        }
        if (maxQueueDelayMicroseconds_ != 0L) {
          size += com.google.protobuf.CodedOutputStream
            .computeUInt64Size(3, maxQueueDelayMicroseconds_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest other = (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) obj;

        boolean result = true;
        result = result && (getMaxCandidateSequences()
            == other.getMaxCandidateSequences());
        result = result && getPreferredBatchSizeList()
            .equals(other.getPreferredBatchSizeList());
        result = result && (getMaxQueueDelayMicroseconds()
            == other.getMaxQueueDelayMicroseconds());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + MAX_CANDIDATE_SEQUENCES_FIELD_NUMBER;
        hash = (53 * hash) + getMaxCandidateSequences();
        if (getPreferredBatchSizeCount() > 0) {
          hash = (37 * hash) + PREFERRED_BATCH_SIZE_FIELD_NUMBER;
          hash = (53 * hash) + getPreferredBatchSizeList().hashCode();
        }
        hash = (37 * hash) + MAX_QUEUE_DELAY_MICROSECONDS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMaxQueueDelayMicroseconds());
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message StrategyOldest
       *&#64;&#64;
       *&#64;&#64;     The sequence batcher maintains up to 'max_candidate_sequences'
       *&#64;&#64;     candidate sequences. 'max_candidate_sequences' can be greater
       *&#64;&#64;     than the model's 'max_batch_size'. For inferencing the batcher
       *&#64;&#64;     chooses from the candidate sequences up to 'max_batch_size'
       *&#64;&#64;     inference requests. Requests are chosen in an oldest-first
       *&#64;&#64;     manner across all candidate sequences. A given sequence is
       *&#64;&#64;     not guaranteed to be assigned to the same batch slot for
       *&#64;&#64;     all inference requests of that sequence.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelSequenceBatching.StrategyOldest}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelSequenceBatching.StrategyOldest)
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyOldest_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.class, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          maxCandidateSequences_ = 0;

          preferredBatchSize_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          maxQueueDelayMicroseconds_ = 0L;

          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest build() {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest buildPartial() {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest result = new ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          result.maxCandidateSequences_ = maxCandidateSequences_;
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            preferredBatchSize_ = java.util.Collections.unmodifiableList(preferredBatchSize_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.preferredBatchSize_ = preferredBatchSize_;
          result.maxQueueDelayMicroseconds_ = maxQueueDelayMicroseconds_;
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) {
            return mergeFrom((ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest other) {
          if (other == ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance()) return this;
          if (other.getMaxCandidateSequences() != 0) {
            setMaxCandidateSequences(other.getMaxCandidateSequences());
          }
          if (!other.preferredBatchSize_.isEmpty()) {
            if (preferredBatchSize_.isEmpty()) {
              preferredBatchSize_ = other.preferredBatchSize_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensurePreferredBatchSizeIsMutable();
              preferredBatchSize_.addAll(other.preferredBatchSize_);
            }
            onChanged();
          }
          if (other.getMaxQueueDelayMicroseconds() != 0L) {
            setMaxQueueDelayMicroseconds(other.getMaxQueueDelayMicroseconds());
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private int maxCandidateSequences_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 max_candidate_sequences
         *&#64;&#64;
         *&#64;&#64;       Maximum number of candidate sequences that the batcher
         *&#64;&#64;       maintains. Excess seqences are kept in an ordered backlog
         *&#64;&#64;       and become candidates when existing candidate sequences
         *&#64;&#64;       complete.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 max_candidate_sequences = 1;</code>
         */
        public int getMaxCandidateSequences() {
          return maxCandidateSequences_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 max_candidate_sequences
         *&#64;&#64;
         *&#64;&#64;       Maximum number of candidate sequences that the batcher
         *&#64;&#64;       maintains. Excess seqences are kept in an ordered backlog
         *&#64;&#64;       and become candidates when existing candidate sequences
         *&#64;&#64;       complete.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 max_candidate_sequences = 1;</code>
         */
        public Builder setMaxCandidateSequences(int value) {

          maxCandidateSequences_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 max_candidate_sequences
         *&#64;&#64;
         *&#64;&#64;       Maximum number of candidate sequences that the batcher
         *&#64;&#64;       maintains. Excess seqences are kept in an ordered backlog
         *&#64;&#64;       and become candidates when existing candidate sequences
         *&#64;&#64;       complete.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int32 max_candidate_sequences = 1;</code>
         */
        public Builder clearMaxCandidateSequences() {

          maxCandidateSequences_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<Integer> preferredBatchSize_ = java.util.Collections.emptyList();
        private void ensurePreferredBatchSizeIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            preferredBatchSize_ = new java.util.ArrayList<Integer>(preferredBatchSize_);
            bitField0_ |= 0x00000002;
           }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public java.util.List<Integer>
            getPreferredBatchSizeList() {
          return java.util.Collections.unmodifiableList(preferredBatchSize_);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public int getPreferredBatchSizeCount() {
          return preferredBatchSize_.size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public int getPreferredBatchSize(int index) {
          return preferredBatchSize_.get(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public Builder setPreferredBatchSize(
            int index, int value) {
          ensurePreferredBatchSizeIsMutable();
          preferredBatchSize_.set(index, value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public Builder addPreferredBatchSize(int value) {
          ensurePreferredBatchSizeIsMutable();
          preferredBatchSize_.add(value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public Builder addAllPreferredBatchSize(
            Iterable<? extends Integer> values) {
          ensurePreferredBatchSizeIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, preferredBatchSize_);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int32 preferred_batch_size (repeated)
         *&#64;&#64;
         *&#64;&#64;       Preferred batch sizes for dynamic batching of candidate
         *&#64;&#64;       sequences. If a batch of one of these sizes can be formed
         *&#64;&#64;       it will be executed immediately.  If not specified a
         *&#64;&#64;       preferred batch size will be chosen automatically
         *&#64;&#64;       based on model and GPU characteristics.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int32 preferred_batch_size = 2;</code>
         */
        public Builder clearPreferredBatchSize() {
          preferredBatchSize_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }

        private long maxQueueDelayMicroseconds_ ;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint64 max_queue_delay_microseconds
         *&#64;&#64;
         *&#64;&#64;       The maximum time, in microseconds, a candidate request
         *&#64;&#64;       will be delayed in the dynamic batch scheduling queue to
         *&#64;&#64;       wait for additional requests for batching. Default is 0.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint64 max_queue_delay_microseconds = 3;</code>
         */
        public long getMaxQueueDelayMicroseconds() {
          return maxQueueDelayMicroseconds_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint64 max_queue_delay_microseconds
         *&#64;&#64;
         *&#64;&#64;       The maximum time, in microseconds, a candidate request
         *&#64;&#64;       will be delayed in the dynamic batch scheduling queue to
         *&#64;&#64;       wait for additional requests for batching. Default is 0.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint64 max_queue_delay_microseconds = 3;</code>
         */
        public Builder setMaxQueueDelayMicroseconds(long value) {

          maxQueueDelayMicroseconds_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: uint64 max_queue_delay_microseconds
         *&#64;&#64;
         *&#64;&#64;       The maximum time, in microseconds, a candidate request
         *&#64;&#64;       will be delayed in the dynamic batch scheduling queue to
         *&#64;&#64;       wait for additional requests for batching. Default is 0.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional uint64 max_queue_delay_microseconds = 3;</code>
         */
        public Builder clearMaxQueueDelayMicroseconds() {

          maxQueueDelayMicroseconds_ = 0L;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelSequenceBatching.StrategyOldest)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching.StrategyOldest)
      private static final ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest();
      }

      public static ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<StrategyOldest>
          PARSER = new com.google.protobuf.AbstractParser<StrategyOldest>() {
        public StrategyOldest parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new StrategyOldest(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<StrategyOldest> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<StrategyOldest> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    private int strategyChoiceCase_ = 0;
    private Object strategyChoice_;
    public enum StrategyChoiceCase
        implements com.google.protobuf.Internal.EnumLite {
      DIRECT(3),
      OLDEST(4),
      STRATEGYCHOICE_NOT_SET(0);
      private final int value;
      private StrategyChoiceCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static StrategyChoiceCase valueOf(int value) {
        return forNumber(value);
      }

      public static StrategyChoiceCase forNumber(int value) {
        switch (value) {
          case 3: return DIRECT;
          case 4: return OLDEST;
          case 0: return STRATEGYCHOICE_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public StrategyChoiceCase
    getStrategyChoiceCase() {
      return StrategyChoiceCase.forNumber(
          strategyChoiceCase_);
    }

    public static final int DIRECT_FIELD_NUMBER = 3;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyDirect direct
     *&#64;&#64;
     *&#64;&#64;       StrategyDirect scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDirect() {
      if (strategyChoiceCase_ == 3) {
         return (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyDirect direct
     *&#64;&#64;
     *&#64;&#64;       StrategyDirect scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder getDirectOrBuilder() {
      if (strategyChoiceCase_ == 3) {
         return (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
    }

    public static final int OLDEST_FIELD_NUMBER = 4;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
     *&#64;&#64;
     *&#64;&#64;       StrategyOldest scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getOldest() {
      if (strategyChoiceCase_ == 4) {
         return (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
     *&#64;&#64;
     *&#64;&#64;       StrategyOldest scheduling strategy.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder getOldestOrBuilder() {
      if (strategyChoiceCase_ == 4) {
         return (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
    }

    public static final int MAX_SEQUENCE_IDLE_MICROSECONDS_FIELD_NUMBER = 1;
    private long maxSequenceIdleMicroseconds_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint64 max_sequence_idle_microseconds
     *&#64;&#64;
     *&#64;&#64;     The maximum time, in microseconds, that a sequence is allowed to
     *&#64;&#64;     be idle before it is aborted. The inference server considers a
     *&#64;&#64;     sequence idle when it does not have any inference request queued
     *&#64;&#64;     for the sequence. If this limit is exceeded, the inference server
     *&#64;&#64;     will free the sequence slot allocated by the sequence and make it
     *&#64;&#64;     available for another sequence. If not specified (or specified as
     *&#64;&#64;     zero) a default value of 1000000 (1 second) is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint64 max_sequence_idle_microseconds = 1;</code>
     */
    public long getMaxSequenceIdleMicroseconds() {
      return maxSequenceIdleMicroseconds_;
    }

    public static final int CONTROL_INPUT_FIELD_NUMBER = 2;
    private java.util.List<ControlInput> controlInput_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    public java.util.List<ControlInput> getControlInputList() {
      return controlInput_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    public java.util.List<? extends ControlInputOrBuilder>
        getControlInputOrBuilderList() {
      return controlInput_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    public int getControlInputCount() {
      return controlInput_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.ControlInput getControlInput(int index) {
      return controlInput_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The model input(s) that the server should use to communicate
     *&#64;&#64;     sequence start, stop, ready and similar control values to the
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder getControlInputOrBuilder(
        int index) {
      return controlInput_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (maxSequenceIdleMicroseconds_ != 0L) {
        output.writeUInt64(1, maxSequenceIdleMicroseconds_);
      }
      for (int i = 0; i < controlInput_.size(); i++) {
        output.writeMessage(2, controlInput_.get(i));
      }
      if (strategyChoiceCase_ == 3) {
        output.writeMessage(3, (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_);
      }
      if (strategyChoiceCase_ == 4) {
        output.writeMessage(4, (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (maxSequenceIdleMicroseconds_ != 0L) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt64Size(1, maxSequenceIdleMicroseconds_);
      }
      for (int i = 0; i < controlInput_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, controlInput_.get(i));
      }
      if (strategyChoiceCase_ == 3) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_);
      }
      if (strategyChoiceCase_ == 4) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelSequenceBatching)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelSequenceBatching other = (ModelConfigOuterClass.ModelSequenceBatching) obj;

      boolean result = true;
      result = result && (getMaxSequenceIdleMicroseconds()
          == other.getMaxSequenceIdleMicroseconds());
      result = result && getControlInputList()
          .equals(other.getControlInputList());
      result = result && getStrategyChoiceCase().equals(
          other.getStrategyChoiceCase());
      if (!result) return false;
      switch (strategyChoiceCase_) {
        case 3:
          result = result && getDirect()
              .equals(other.getDirect());
          break;
        case 4:
          result = result && getOldest()
              .equals(other.getOldest());
          break;
        case 0:
        default:
      }
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + MAX_SEQUENCE_IDLE_MICROSECONDS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
          getMaxSequenceIdleMicroseconds());
      if (getControlInputCount() > 0) {
        hash = (37 * hash) + CONTROL_INPUT_FIELD_NUMBER;
        hash = (53 * hash) + getControlInputList().hashCode();
      }
      switch (strategyChoiceCase_) {
        case 3:
          hash = (37 * hash) + DIRECT_FIELD_NUMBER;
          hash = (53 * hash) + getDirect().hashCode();
          break;
        case 4:
          hash = (37 * hash) + OLDEST_FIELD_NUMBER;
          hash = (53 * hash) + getOldest().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelSequenceBatching parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelSequenceBatching prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelSequenceBatching
     *&#64;&#64;
     *&#64;&#64;   Sequence batching configuration. These settings control how sequence
     *&#64;&#64;   batching operates for the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelSequenceBatching}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelSequenceBatching)
        ModelConfigOuterClass.ModelSequenceBatchingOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelSequenceBatching.class, ModelConfigOuterClass.ModelSequenceBatching.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelSequenceBatching.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getControlInputFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        maxSequenceIdleMicroseconds_ = 0L;

        if (controlInputBuilder_ == null) {
          controlInput_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          controlInputBuilder_.clear();
        }
        strategyChoiceCase_ = 0;
        strategyChoice_ = null;
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelSequenceBatching_descriptor;
      }

      public ModelConfigOuterClass.ModelSequenceBatching getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelSequenceBatching build() {
        ModelConfigOuterClass.ModelSequenceBatching result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelSequenceBatching buildPartial() {
        ModelConfigOuterClass.ModelSequenceBatching result = new ModelConfigOuterClass.ModelSequenceBatching(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (strategyChoiceCase_ == 3) {
          if (directBuilder_ == null) {
            result.strategyChoice_ = strategyChoice_;
          } else {
            result.strategyChoice_ = directBuilder_.build();
          }
        }
        if (strategyChoiceCase_ == 4) {
          if (oldestBuilder_ == null) {
            result.strategyChoice_ = strategyChoice_;
          } else {
            result.strategyChoice_ = oldestBuilder_.build();
          }
        }
        result.maxSequenceIdleMicroseconds_ = maxSequenceIdleMicroseconds_;
        if (controlInputBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            controlInput_ = java.util.Collections.unmodifiableList(controlInput_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.controlInput_ = controlInput_;
        } else {
          result.controlInput_ = controlInputBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        result.strategyChoiceCase_ = strategyChoiceCase_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelSequenceBatching) {
          return mergeFrom((ModelConfigOuterClass.ModelSequenceBatching)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelSequenceBatching other) {
        if (other == ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance()) return this;
        if (other.getMaxSequenceIdleMicroseconds() != 0L) {
          setMaxSequenceIdleMicroseconds(other.getMaxSequenceIdleMicroseconds());
        }
        if (controlInputBuilder_ == null) {
          if (!other.controlInput_.isEmpty()) {
            if (controlInput_.isEmpty()) {
              controlInput_ = other.controlInput_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureControlInputIsMutable();
              controlInput_.addAll(other.controlInput_);
            }
            onChanged();
          }
        } else {
          if (!other.controlInput_.isEmpty()) {
            if (controlInputBuilder_.isEmpty()) {
              controlInputBuilder_.dispose();
              controlInputBuilder_ = null;
              controlInput_ = other.controlInput_;
              bitField0_ = (bitField0_ & ~0x00000008);
              controlInputBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getControlInputFieldBuilder() : null;
            } else {
              controlInputBuilder_.addAllMessages(other.controlInput_);
            }
          }
        }
        switch (other.getStrategyChoiceCase()) {
          case DIRECT: {
            mergeDirect(other.getDirect());
            break;
          }
          case OLDEST: {
            mergeOldest(other.getOldest());
            break;
          }
          case STRATEGYCHOICE_NOT_SET: {
            break;
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelSequenceBatching parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelSequenceBatching) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int strategyChoiceCase_ = 0;
      private Object strategyChoice_;
      public StrategyChoiceCase
          getStrategyChoiceCase() {
        return StrategyChoiceCase.forNumber(
            strategyChoiceCase_);
      }

      public Builder clearStrategyChoice() {
        strategyChoiceCase_ = 0;
        strategyChoice_ = null;
        onChanged();
        return this;
      }

      private int bitField0_;

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder> directBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect getDirect() {
        if (directBuilder_ == null) {
          if (strategyChoiceCase_ == 3) {
            return (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
        } else {
          if (strategyChoiceCase_ == 3) {
            return directBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public Builder setDirect(ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect value) {
        if (directBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          strategyChoice_ = value;
          onChanged();
        } else {
          directBuilder_.setMessage(value);
        }
        strategyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public Builder setDirect(
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder builderForValue) {
        if (directBuilder_ == null) {
          strategyChoice_ = builderForValue.build();
          onChanged();
        } else {
          directBuilder_.setMessage(builderForValue.build());
        }
        strategyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public Builder mergeDirect(ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect value) {
        if (directBuilder_ == null) {
          if (strategyChoiceCase_ == 3 &&
              strategyChoice_ != ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance()) {
            strategyChoice_ = ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.newBuilder((ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            strategyChoice_ = value;
          }
          onChanged();
        } else {
          if (strategyChoiceCase_ == 3) {
            directBuilder_.mergeFrom(value);
          }
          directBuilder_.setMessage(value);
        }
        strategyChoiceCase_ = 3;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public Builder clearDirect() {
        if (directBuilder_ == null) {
          if (strategyChoiceCase_ == 3) {
            strategyChoiceCase_ = 0;
            strategyChoice_ = null;
            onChanged();
          }
        } else {
          if (strategyChoiceCase_ == 3) {
            strategyChoiceCase_ = 0;
            strategyChoice_ = null;
          }
          directBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder getDirectBuilder() {
        return getDirectFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder getDirectOrBuilder() {
        if ((strategyChoiceCase_ == 3) && (directBuilder_ != null)) {
          return directBuilder_.getMessageOrBuilder();
        } else {
          if (strategyChoiceCase_ == 3) {
            return (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyDirect direct
       *&#64;&#64;
       *&#64;&#64;       StrategyDirect scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyDirect direct = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder>
          getDirectFieldBuilder() {
        if (directBuilder_ == null) {
          if (!(strategyChoiceCase_ == 3)) {
            strategyChoice_ = ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.getDefaultInstance();
          }
          directBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyDirectOrBuilder>(
                  (ModelConfigOuterClass.ModelSequenceBatching.StrategyDirect) strategyChoice_,
                  getParentForChildren(),
                  isClean());
          strategyChoice_ = null;
        }
        strategyChoiceCase_ = 3;
        onChanged();;
        return directBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder> oldestBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest getOldest() {
        if (oldestBuilder_ == null) {
          if (strategyChoiceCase_ == 4) {
            return (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
        } else {
          if (strategyChoiceCase_ == 4) {
            return oldestBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public Builder setOldest(ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest value) {
        if (oldestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          strategyChoice_ = value;
          onChanged();
        } else {
          oldestBuilder_.setMessage(value);
        }
        strategyChoiceCase_ = 4;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public Builder setOldest(
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder builderForValue) {
        if (oldestBuilder_ == null) {
          strategyChoice_ = builderForValue.build();
          onChanged();
        } else {
          oldestBuilder_.setMessage(builderForValue.build());
        }
        strategyChoiceCase_ = 4;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public Builder mergeOldest(ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest value) {
        if (oldestBuilder_ == null) {
          if (strategyChoiceCase_ == 4 &&
              strategyChoice_ != ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance()) {
            strategyChoice_ = ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.newBuilder((ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            strategyChoice_ = value;
          }
          onChanged();
        } else {
          if (strategyChoiceCase_ == 4) {
            oldestBuilder_.mergeFrom(value);
          }
          oldestBuilder_.setMessage(value);
        }
        strategyChoiceCase_ = 4;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public Builder clearOldest() {
        if (oldestBuilder_ == null) {
          if (strategyChoiceCase_ == 4) {
            strategyChoiceCase_ = 0;
            strategyChoice_ = null;
            onChanged();
          }
        } else {
          if (strategyChoiceCase_ == 4) {
            strategyChoiceCase_ = 0;
            strategyChoice_ = null;
          }
          oldestBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder getOldestBuilder() {
        return getOldestFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder getOldestOrBuilder() {
        if ((strategyChoiceCase_ == 4) && (oldestBuilder_ != null)) {
          return oldestBuilder_.getMessageOrBuilder();
        } else {
          if (strategyChoiceCase_ == 4) {
            return (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: StrategyOldest oldest
       *&#64;&#64;
       *&#64;&#64;       StrategyOldest scheduling strategy.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching.StrategyOldest oldest = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder>
          getOldestFieldBuilder() {
        if (oldestBuilder_ == null) {
          if (!(strategyChoiceCase_ == 4)) {
            strategyChoice_ = ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.getDefaultInstance();
          }
          oldestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest.Builder, ModelConfigOuterClass.ModelSequenceBatching.StrategyOldestOrBuilder>(
                  (ModelConfigOuterClass.ModelSequenceBatching.StrategyOldest) strategyChoice_,
                  getParentForChildren(),
                  isClean());
          strategyChoice_ = null;
        }
        strategyChoiceCase_ = 4;
        onChanged();;
        return oldestBuilder_;
      }

      private long maxSequenceIdleMicroseconds_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_sequence_idle_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, that a sequence is allowed to
       *&#64;&#64;     be idle before it is aborted. The inference server considers a
       *&#64;&#64;     sequence idle when it does not have any inference request queued
       *&#64;&#64;     for the sequence. If this limit is exceeded, the inference server
       *&#64;&#64;     will free the sequence slot allocated by the sequence and make it
       *&#64;&#64;     available for another sequence. If not specified (or specified as
       *&#64;&#64;     zero) a default value of 1000000 (1 second) is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_sequence_idle_microseconds = 1;</code>
       */
      public long getMaxSequenceIdleMicroseconds() {
        return maxSequenceIdleMicroseconds_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_sequence_idle_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, that a sequence is allowed to
       *&#64;&#64;     be idle before it is aborted. The inference server considers a
       *&#64;&#64;     sequence idle when it does not have any inference request queued
       *&#64;&#64;     for the sequence. If this limit is exceeded, the inference server
       *&#64;&#64;     will free the sequence slot allocated by the sequence and make it
       *&#64;&#64;     available for another sequence. If not specified (or specified as
       *&#64;&#64;     zero) a default value of 1000000 (1 second) is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_sequence_idle_microseconds = 1;</code>
       */
      public Builder setMaxSequenceIdleMicroseconds(long value) {

        maxSequenceIdleMicroseconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint64 max_sequence_idle_microseconds
       *&#64;&#64;
       *&#64;&#64;     The maximum time, in microseconds, that a sequence is allowed to
       *&#64;&#64;     be idle before it is aborted. The inference server considers a
       *&#64;&#64;     sequence idle when it does not have any inference request queued
       *&#64;&#64;     for the sequence. If this limit is exceeded, the inference server
       *&#64;&#64;     will free the sequence slot allocated by the sequence and make it
       *&#64;&#64;     available for another sequence. If not specified (or specified as
       *&#64;&#64;     zero) a default value of 1000000 (1 second) is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint64 max_sequence_idle_microseconds = 1;</code>
       */
      public Builder clearMaxSequenceIdleMicroseconds() {

        maxSequenceIdleMicroseconds_ = 0L;
        onChanged();
        return this;
      }

      private java.util.List<ControlInput> controlInput_ =
        java.util.Collections.emptyList();
      private void ensureControlInputIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          controlInput_ = new java.util.ArrayList<ControlInput>(controlInput_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder> controlInputBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public java.util.List<ControlInput> getControlInputList() {
        if (controlInputBuilder_ == null) {
          return java.util.Collections.unmodifiableList(controlInput_);
        } else {
          return controlInputBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public int getControlInputCount() {
        if (controlInputBuilder_ == null) {
          return controlInput_.size();
        } else {
          return controlInputBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlInput getControlInput(int index) {
        if (controlInputBuilder_ == null) {
          return controlInput_.get(index);
        } else {
          return controlInputBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder setControlInput(
          int index, ModelConfigOuterClass.ModelSequenceBatching.ControlInput value) {
        if (controlInputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureControlInputIsMutable();
          controlInput_.set(index, value);
          onChanged();
        } else {
          controlInputBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder setControlInput(
          int index, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder builderForValue) {
        if (controlInputBuilder_ == null) {
          ensureControlInputIsMutable();
          controlInput_.set(index, builderForValue.build());
          onChanged();
        } else {
          controlInputBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder addControlInput(ModelConfigOuterClass.ModelSequenceBatching.ControlInput value) {
        if (controlInputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureControlInputIsMutable();
          controlInput_.add(value);
          onChanged();
        } else {
          controlInputBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder addControlInput(
          int index, ModelConfigOuterClass.ModelSequenceBatching.ControlInput value) {
        if (controlInputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureControlInputIsMutable();
          controlInput_.add(index, value);
          onChanged();
        } else {
          controlInputBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder addControlInput(
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder builderForValue) {
        if (controlInputBuilder_ == null) {
          ensureControlInputIsMutable();
          controlInput_.add(builderForValue.build());
          onChanged();
        } else {
          controlInputBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder addControlInput(
          int index, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder builderForValue) {
        if (controlInputBuilder_ == null) {
          ensureControlInputIsMutable();
          controlInput_.add(index, builderForValue.build());
          onChanged();
        } else {
          controlInputBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder addAllControlInput(
          Iterable<? extends ControlInput> values) {
        if (controlInputBuilder_ == null) {
          ensureControlInputIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, controlInput_);
          onChanged();
        } else {
          controlInputBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder clearControlInput() {
        if (controlInputBuilder_ == null) {
          controlInput_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          controlInputBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public Builder removeControlInput(int index) {
        if (controlInputBuilder_ == null) {
          ensureControlInputIsMutable();
          controlInput_.remove(index);
          onChanged();
        } else {
          controlInputBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder getControlInputBuilder(
          int index) {
        return getControlInputFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder getControlInputOrBuilder(
          int index) {
        if (controlInputBuilder_ == null) {
          return controlInput_.get(index);  } else {
          return controlInputBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public java.util.List<? extends ControlInputOrBuilder>
           getControlInputOrBuilderList() {
        if (controlInputBuilder_ != null) {
          return controlInputBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(controlInput_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder addControlInputBuilder() {
        return getControlInputFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelSequenceBatching.ControlInput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder addControlInputBuilder(
          int index) {
        return getControlInputFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ControlInput control_input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The model input(s) that the server should use to communicate
       *&#64;&#64;     sequence start, stop, ready and similar control values to the
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelSequenceBatching.ControlInput control_input = 2;</code>
       */
      public java.util.List<ControlInput.Builder>
           getControlInputBuilderList() {
        return getControlInputFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching.ControlInput, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder>
          getControlInputFieldBuilder() {
        if (controlInputBuilder_ == null) {
          controlInputBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelSequenceBatching.ControlInput, ModelConfigOuterClass.ModelSequenceBatching.ControlInput.Builder, ModelConfigOuterClass.ModelSequenceBatching.ControlInputOrBuilder>(
                  controlInput_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          controlInput_ = null;
        }
        return controlInputBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelSequenceBatching)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelSequenceBatching)
    private static final ModelConfigOuterClass.ModelSequenceBatching DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelSequenceBatching();
    }

    public static ModelConfigOuterClass.ModelSequenceBatching getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelSequenceBatching>
        PARSER = new com.google.protobuf.AbstractParser<ModelSequenceBatching>() {
      public ModelSequenceBatching parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelSequenceBatching(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelSequenceBatching> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelSequenceBatching> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelSequenceBatching getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelEnsemblingOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelEnsembling)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    java.util.List<ModelEnsembling.Step>
        getStepList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    ModelConfigOuterClass.ModelEnsembling.Step getStep(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    int getStepCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    java.util.List<? extends ModelEnsembling.StepOrBuilder>
        getStepOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    ModelConfigOuterClass.ModelEnsembling.StepOrBuilder getStepOrBuilder(
        int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelEnsembling
   *&#64;&#64;
   *&#64;&#64;   Model ensembling configuration. These settings specify the models that
   *&#64;&#64;   compose the ensemble and how data flows between the models.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelEnsembling}
   */
  public  static final class ModelEnsembling extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelEnsembling)
      ModelEnsemblingOrBuilder {
    // Use ModelEnsembling.newBuilder() to construct.
    private ModelEnsembling(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelEnsembling() {
      step_ = java.util.Collections.emptyList();
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelEnsembling(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                step_ = new java.util.ArrayList<Step>();
                mutable_bitField0_ |= 0x00000001;
              }
              step_.add(
                  input.readMessage(ModelConfigOuterClass.ModelEnsembling.Step.parser(), extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          step_ = java.util.Collections.unmodifiableList(step_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelEnsembling.class, ModelConfigOuterClass.ModelEnsembling.Builder.class);
    }

    public interface StepOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelEnsembling.Step)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string model_name
       *&#64;&#64;
       *&#64;&#64;     The name of the model to execute for this step of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string model_name = 1;</code>
       */
      String getModelName();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string model_name
       *&#64;&#64;
       *&#64;&#64;     The name of the model to execute for this step of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string model_name = 1;</code>
       */
      com.google.protobuf.ByteString
          getModelNameBytes();

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 model_version
       *&#64;&#64;
       *&#64;&#64;     The version of the model to use for inference. If -1
       *&#64;&#64;     the latest/most-recent version of the model is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int64 model_version = 2;</code>
       */
      long getModelVersion();

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */
      int getInputMapCount();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */
      boolean containsInputMap(
          String key);
      /**
       * Use {@link #getInputMapMap()} instead.
       */
      @Deprecated
      java.util.Map<String, String>
      getInputMap();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */
      java.util.Map<String, String>
      getInputMapMap();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      String getInputMapOrDefault(
          String key,
          String defaultValue);
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      String getInputMapOrThrow(
          String key);

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */
      int getOutputMapCount();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */
      boolean containsOutputMap(
          String key);
      /**
       * Use {@link #getOutputMapMap()} instead.
       */
      @Deprecated
      java.util.Map<String, String>
      getOutputMap();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */
      java.util.Map<String, String>
      getOutputMapMap();
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      String getOutputMapOrDefault(
          String key,
          String defaultValue);
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      String getOutputMapOrThrow(
          String key);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: message Step
     *&#64;&#64;
     *&#64;&#64;     Each step specifies a model included in the ensemble,
     *&#64;&#64;     maps ensemble tensor names to the model input tensors,
     *&#64;&#64;     and maps model output tensors to ensemble tensor names
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelEnsembling.Step}
     */
    public  static final class Step extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelEnsembling.Step)
        StepOrBuilder {
      // Use Step.newBuilder() to construct.
      private Step(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Step() {
        modelName_ = "";
        modelVersion_ = 0L;
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Step(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 10: {
                String s = input.readStringRequireUtf8();

                modelName_ = s;
                break;
              }
              case 16: {

                modelVersion_ = input.readInt64();
                break;
              }
              case 26: {
                if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                  inputMap_ = com.google.protobuf.MapField.newMapField(
                      InputMapDefaultEntryHolder.defaultEntry);
                  mutable_bitField0_ |= 0x00000004;
                }
                com.google.protobuf.MapEntry<String, String>
                inputMap = input.readMessage(
                    InputMapDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
                inputMap_.getMutableMap().put(inputMap.getKey(), inputMap.getValue());
                break;
              }
              case 34: {
                if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                  outputMap_ = com.google.protobuf.MapField.newMapField(
                      OutputMapDefaultEntryHolder.defaultEntry);
                  mutable_bitField0_ |= 0x00000008;
                }
                com.google.protobuf.MapEntry<String, String>
                outputMap = input.readMessage(
                    OutputMapDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
                outputMap_.getMutableMap().put(outputMap.getKey(), outputMap.getValue());
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 3:
            return internalGetInputMap();
          case 4:
            return internalGetOutputMap();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelEnsembling.Step.class, ModelConfigOuterClass.ModelEnsembling.Step.Builder.class);
      }

      private int bitField0_;
      public static final int MODEL_NAME_FIELD_NUMBER = 1;
      private volatile Object modelName_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string model_name
       *&#64;&#64;
       *&#64;&#64;     The name of the model to execute for this step of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string model_name = 1;</code>
       */
      public String getModelName() {
        Object ref = modelName_;
        if (ref instanceof String) {
          return (String) ref;
        } else {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          modelName_ = s;
          return s;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string model_name
       *&#64;&#64;
       *&#64;&#64;     The name of the model to execute for this step of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string model_name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getModelNameBytes() {
        Object ref = modelName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          modelName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      public static final int MODEL_VERSION_FIELD_NUMBER = 2;
      private long modelVersion_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int64 model_version
       *&#64;&#64;
       *&#64;&#64;     The version of the model to use for inference. If -1
       *&#64;&#64;     the latest/most-recent version of the model is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int64 model_version = 2;</code>
       */
      public long getModelVersion() {
        return modelVersion_;
      }

      public static final int INPUT_MAP_FIELD_NUMBER = 3;
      private static final class InputMapDefaultEntryHolder {
        static final com.google.protobuf.MapEntry<
            String, String> defaultEntry =
                com.google.protobuf.MapEntry
                .<String, String>newDefaultInstance(
                    ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_InputMapEntry_descriptor,
                    com.google.protobuf.WireFormat.FieldType.STRING,
                    "",
                    com.google.protobuf.WireFormat.FieldType.STRING,
                    "");
      }
      private com.google.protobuf.MapField<
          String, String> inputMap_;
      private com.google.protobuf.MapField<String, String>
      internalGetInputMap() {
        if (inputMap_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              InputMapDefaultEntryHolder.defaultEntry);
        }
        return inputMap_;
      }

      public int getInputMapCount() {
        return internalGetInputMap().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      public boolean containsInputMap(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetInputMap().getMap().containsKey(key);
      }
      /**
       * Use {@link #getInputMapMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, String> getInputMap() {
        return getInputMapMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      public java.util.Map<String, String> getInputMapMap() {
        return internalGetInputMap().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      public String getInputMapOrDefault(
          String key,
          String defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetInputMap().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
       *&#64;&#64;     shape as the model input. Each model input must be assigned to
       *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
       *&#64;&#64;     to multiple model inputs.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; input_map = 3;</code>
       */

      public String getInputMapOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetInputMap().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public static final int OUTPUT_MAP_FIELD_NUMBER = 4;
      private static final class OutputMapDefaultEntryHolder {
        static final com.google.protobuf.MapEntry<
            String, String> defaultEntry =
                com.google.protobuf.MapEntry
                .<String, String>newDefaultInstance(
                    ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_OutputMapEntry_descriptor,
                    com.google.protobuf.WireFormat.FieldType.STRING,
                    "",
                    com.google.protobuf.WireFormat.FieldType.STRING,
                    "");
      }
      private com.google.protobuf.MapField<
          String, String> outputMap_;
      private com.google.protobuf.MapField<String, String>
      internalGetOutputMap() {
        if (outputMap_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              OutputMapDefaultEntryHolder.defaultEntry);
        }
        return outputMap_;
      }

      public int getOutputMapCount() {
        return internalGetOutputMap().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      public boolean containsOutputMap(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetOutputMap().getMap().containsKey(key);
      }
      /**
       * Use {@link #getOutputMapMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, String> getOutputMap() {
        return getOutputMapMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      public java.util.Map<String, String> getOutputMapMap() {
        return internalGetOutputMap().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      public String getOutputMapOrDefault(
          String key,
          String defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetOutputMap().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
       *&#64;&#64;
       *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
       *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
       *&#64;&#64;     be inferred from the model output. It is optional to assign all
       *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
       *&#64;&#64;     can appear in an output map only once.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; output_map = 4;</code>
       */

      public String getOutputMapOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetOutputMap().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        if (!getModelNameBytes().isEmpty()) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 1, modelName_);
        }
        if (modelVersion_ != 0L) {
          output.writeInt64(2, modelVersion_);
        }
        for (java.util.Map.Entry<String, String> entry
             : internalGetInputMap().getMap().entrySet()) {
          com.google.protobuf.MapEntry<String, String>
          inputMap = InputMapDefaultEntryHolder.defaultEntry.newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
          output.writeMessage(3, inputMap);
        }
        for (java.util.Map.Entry<String, String> entry
             : internalGetOutputMap().getMap().entrySet()) {
          com.google.protobuf.MapEntry<String, String>
          outputMap = OutputMapDefaultEntryHolder.defaultEntry.newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
          output.writeMessage(4, outputMap);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (!getModelNameBytes().isEmpty()) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, modelName_);
        }
        if (modelVersion_ != 0L) {
          size += com.google.protobuf.CodedOutputStream
            .computeInt64Size(2, modelVersion_);
        }
        for (java.util.Map.Entry<String, String> entry
             : internalGetInputMap().getMap().entrySet()) {
          com.google.protobuf.MapEntry<String, String>
          inputMap = InputMapDefaultEntryHolder.defaultEntry.newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
          size += com.google.protobuf.CodedOutputStream
              .computeMessageSize(3, inputMap);
        }
        for (java.util.Map.Entry<String, String> entry
             : internalGetOutputMap().getMap().entrySet()) {
          com.google.protobuf.MapEntry<String, String>
          outputMap = OutputMapDefaultEntryHolder.defaultEntry.newBuilderForType()
              .setKey(entry.getKey())
              .setValue(entry.getValue())
              .build();
          size += com.google.protobuf.CodedOutputStream
              .computeMessageSize(4, outputMap);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelEnsembling.Step)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelEnsembling.Step other = (ModelConfigOuterClass.ModelEnsembling.Step) obj;

        boolean result = true;
        result = result && getModelName()
            .equals(other.getModelName());
        result = result && (getModelVersion()
            == other.getModelVersion());
        result = result && internalGetInputMap().equals(
            other.internalGetInputMap());
        result = result && internalGetOutputMap().equals(
            other.internalGetOutputMap());
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + MODEL_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getModelName().hashCode();
        hash = (37 * hash) + MODEL_VERSION_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getModelVersion());
        if (!internalGetInputMap().getMap().isEmpty()) {
          hash = (37 * hash) + INPUT_MAP_FIELD_NUMBER;
          hash = (53 * hash) + internalGetInputMap().hashCode();
        }
        if (!internalGetOutputMap().getMap().isEmpty()) {
          hash = (37 * hash) + OUTPUT_MAP_FIELD_NUMBER;
          hash = (53 * hash) + internalGetOutputMap().hashCode();
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelEnsembling.Step parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelEnsembling.Step prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: message Step
       *&#64;&#64;
       *&#64;&#64;     Each step specifies a model included in the ensemble,
       *&#64;&#64;     maps ensemble tensor names to the model input tensors,
       *&#64;&#64;     and maps model output tensors to ensemble tensor names
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelEnsembling.Step}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelEnsembling.Step)
          ModelConfigOuterClass.ModelEnsembling.StepOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_descriptor;
        }

        @SuppressWarnings({"rawtypes"})
        protected com.google.protobuf.MapField internalGetMapField(
            int number) {
          switch (number) {
            case 3:
              return internalGetInputMap();
            case 4:
              return internalGetOutputMap();
            default:
              throw new RuntimeException(
                  "Invalid map field number: " + number);
          }
        }
        @SuppressWarnings({"rawtypes"})
        protected com.google.protobuf.MapField internalGetMutableMapField(
            int number) {
          switch (number) {
            case 3:
              return internalGetMutableInputMap();
            case 4:
              return internalGetMutableOutputMap();
            default:
              throw new RuntimeException(
                  "Invalid map field number: " + number);
          }
        }
        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelEnsembling.Step.class, ModelConfigOuterClass.ModelEnsembling.Step.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelEnsembling.Step.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          modelName_ = "";

          modelVersion_ = 0L;

          internalGetMutableInputMap().clear();
          internalGetMutableOutputMap().clear();
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_Step_descriptor;
        }

        public ModelConfigOuterClass.ModelEnsembling.Step getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelEnsembling.Step.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelEnsembling.Step build() {
          ModelConfigOuterClass.ModelEnsembling.Step result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelEnsembling.Step buildPartial() {
          ModelConfigOuterClass.ModelEnsembling.Step result = new ModelConfigOuterClass.ModelEnsembling.Step(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          result.modelName_ = modelName_;
          result.modelVersion_ = modelVersion_;
          result.inputMap_ = internalGetInputMap();
          result.inputMap_.makeImmutable();
          result.outputMap_ = internalGetOutputMap();
          result.outputMap_.makeImmutable();
          result.bitField0_ = to_bitField0_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelEnsembling.Step) {
            return mergeFrom((ModelConfigOuterClass.ModelEnsembling.Step)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelEnsembling.Step other) {
          if (other == ModelConfigOuterClass.ModelEnsembling.Step.getDefaultInstance()) return this;
          if (!other.getModelName().isEmpty()) {
            modelName_ = other.modelName_;
            onChanged();
          }
          if (other.getModelVersion() != 0L) {
            setModelVersion(other.getModelVersion());
          }
          internalGetMutableInputMap().mergeFrom(
              other.internalGetInputMap());
          internalGetMutableOutputMap().mergeFrom(
              other.internalGetOutputMap());
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelEnsembling.Step parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelEnsembling.Step) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int bitField0_;

        private Object modelName_ = "";
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string model_name
         *&#64;&#64;
         *&#64;&#64;     The name of the model to execute for this step of the ensemble.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string model_name = 1;</code>
         */
        public String getModelName() {
          Object ref = modelName_;
          if (!(ref instanceof String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            String s = bs.toStringUtf8();
            modelName_ = s;
            return s;
          } else {
            return (String) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string model_name
         *&#64;&#64;
         *&#64;&#64;     The name of the model to execute for this step of the ensemble.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string model_name = 1;</code>
         */
        public com.google.protobuf.ByteString
            getModelNameBytes() {
          Object ref = modelName_;
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8(
                    (String) ref);
            modelName_ = b;
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string model_name
         *&#64;&#64;
         *&#64;&#64;     The name of the model to execute for this step of the ensemble.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string model_name = 1;</code>
         */
        public Builder setModelName(
            String value) {
          if (value == null) {
    throw new NullPointerException();
  }

          modelName_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string model_name
         *&#64;&#64;
         *&#64;&#64;     The name of the model to execute for this step of the ensemble.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string model_name = 1;</code>
         */
        public Builder clearModelName() {

          modelName_ = getDefaultInstance().getModelName();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: string model_name
         *&#64;&#64;
         *&#64;&#64;     The name of the model to execute for this step of the ensemble.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string model_name = 1;</code>
         */
        public Builder setModelNameBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

          modelName_ = value;
          onChanged();
          return this;
        }

        private long modelVersion_ ;
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 model_version
         *&#64;&#64;
         *&#64;&#64;     The version of the model to use for inference. If -1
         *&#64;&#64;     the latest/most-recent version of the model is used.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int64 model_version = 2;</code>
         */
        public long getModelVersion() {
          return modelVersion_;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 model_version
         *&#64;&#64;
         *&#64;&#64;     The version of the model to use for inference. If -1
         *&#64;&#64;     the latest/most-recent version of the model is used.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int64 model_version = 2;</code>
         */
        public Builder setModelVersion(long value) {

          modelVersion_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: int64 model_version
         *&#64;&#64;
         *&#64;&#64;     The version of the model to use for inference. If -1
         *&#64;&#64;     the latest/most-recent version of the model is used.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional int64 model_version = 2;</code>
         */
        public Builder clearModelVersion() {

          modelVersion_ = 0L;
          onChanged();
          return this;
        }

        private com.google.protobuf.MapField<
            String, String> inputMap_;
        private com.google.protobuf.MapField<String, String>
        internalGetInputMap() {
          if (inputMap_ == null) {
            return com.google.protobuf.MapField.emptyMapField(
                InputMapDefaultEntryHolder.defaultEntry);
          }
          return inputMap_;
        }
        private com.google.protobuf.MapField<String, String>
        internalGetMutableInputMap() {
          onChanged();;
          if (inputMap_ == null) {
            inputMap_ = com.google.protobuf.MapField.newMapField(
                InputMapDefaultEntryHolder.defaultEntry);
          }
          if (!inputMap_.isMutable()) {
            inputMap_ = inputMap_.copy();
          }
          return inputMap_;
        }

        public int getInputMapCount() {
          return internalGetInputMap().getMap().size();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public boolean containsInputMap(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          return internalGetInputMap().getMap().containsKey(key);
        }
        /**
         * Use {@link #getInputMapMap()} instead.
         */
        @Deprecated
        public java.util.Map<String, String> getInputMap() {
          return getInputMapMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public java.util.Map<String, String> getInputMapMap() {
          return internalGetInputMap().getMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public String getInputMapOrDefault(
            String key,
            String defaultValue) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetInputMap().getMap();
          return map.containsKey(key) ? map.get(key) : defaultValue;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public String getInputMapOrThrow(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetInputMap().getMap();
          if (!map.containsKey(key)) {
            throw new IllegalArgumentException();
          }
          return map.get(key);
        }

        public Builder clearInputMap() {
          getMutableInputMap().clear();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public Builder removeInputMap(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          getMutableInputMap().remove(key);
          return this;
        }
        /**
         * Use alternate mutation accessors instead.
         */
        @Deprecated
        public java.util.Map<String, String>
        getMutableInputMap() {
          return internalGetMutableInputMap().getMutableMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */
        public Builder putInputMap(
            String key,
            String value) {
          if (key == null) { throw new NullPointerException(); }
          if (value == null) { throw new NullPointerException(); }
          getMutableInputMap().put(key, value);
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; input_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an input tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The ensemble tensor must have the same data type and
         *&#64;&#64;     shape as the model input. Each model input must be assigned to
         *&#64;&#64;     one ensemble tensor, but the same ensemble tensor can be assigned
         *&#64;&#64;     to multiple model inputs.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; input_map = 3;</code>
         */

        public Builder putAllInputMap(
            java.util.Map<String, String> values) {
          getMutableInputMap().putAll(values);
          return this;
        }

        private com.google.protobuf.MapField<
            String, String> outputMap_;
        private com.google.protobuf.MapField<String, String>
        internalGetOutputMap() {
          if (outputMap_ == null) {
            return com.google.protobuf.MapField.emptyMapField(
                OutputMapDefaultEntryHolder.defaultEntry);
          }
          return outputMap_;
        }
        private com.google.protobuf.MapField<String, String>
        internalGetMutableOutputMap() {
          onChanged();;
          if (outputMap_ == null) {
            outputMap_ = com.google.protobuf.MapField.newMapField(
                OutputMapDefaultEntryHolder.defaultEntry);
          }
          if (!outputMap_.isMutable()) {
            outputMap_ = outputMap_.copy();
          }
          return outputMap_;
        }

        public int getOutputMapCount() {
          return internalGetOutputMap().getMap().size();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public boolean containsOutputMap(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          return internalGetOutputMap().getMap().containsKey(key);
        }
        /**
         * Use {@link #getOutputMapMap()} instead.
         */
        @Deprecated
        public java.util.Map<String, String> getOutputMap() {
          return getOutputMapMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public java.util.Map<String, String> getOutputMapMap() {
          return internalGetOutputMap().getMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public String getOutputMapOrDefault(
            String key,
            String defaultValue) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetOutputMap().getMap();
          return map.containsKey(key) ? map.get(key) : defaultValue;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public String getOutputMapOrThrow(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          java.util.Map<String, String> map =
              internalGetOutputMap().getMap();
          if (!map.containsKey(key)) {
            throw new IllegalArgumentException();
          }
          return map.get(key);
        }

        public Builder clearOutputMap() {
          getMutableOutputMap().clear();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public Builder removeOutputMap(
            String key) {
          if (key == null) { throw new NullPointerException(); }
          getMutableOutputMap().remove(key);
          return this;
        }
        /**
         * Use alternate mutation accessors instead.
         */
        @Deprecated
        public java.util.Map<String, String>
        getMutableOutputMap() {
          return internalGetMutableOutputMap().getMutableMap();
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */
        public Builder putOutputMap(
            String key,
            String value) {
          if (key == null) { throw new NullPointerException(); }
          if (value == null) { throw new NullPointerException(); }
          getMutableOutputMap().put(key, value);
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; output_map
         *&#64;&#64;
         *&#64;&#64;     Map from name of an output tensor on this step's model to ensemble
         *&#64;&#64;     tensor name. The data type and shape of the ensemble tensor will
         *&#64;&#64;     be inferred from the model output. It is optional to assign all
         *&#64;&#64;     model outputs to ensemble tensors. One ensemble tensor name
         *&#64;&#64;     can appear in an output map only once.
         *&#64;&#64;
         * </pre>
         *
         * <code>map&lt;string, string&gt; output_map = 4;</code>
         */

        public Builder putAllOutputMap(
            java.util.Map<String, String> values) {
          getMutableOutputMap().putAll(values);
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelEnsembling.Step)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelEnsembling.Step)
      private static final ModelConfigOuterClass.ModelEnsembling.Step DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelEnsembling.Step();
      }

      public static ModelConfigOuterClass.ModelEnsembling.Step getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Step>
          PARSER = new com.google.protobuf.AbstractParser<Step>() {
        public Step parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Step(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Step> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Step> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelEnsembling.Step getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    public static final int STEP_FIELD_NUMBER = 1;
    private java.util.List<Step> step_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    public java.util.List<Step> getStepList() {
      return step_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    public java.util.List<? extends StepOrBuilder>
        getStepOrBuilderList() {
      return step_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    public int getStepCount() {
      return step_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    public ModelConfigOuterClass.ModelEnsembling.Step getStep(int index) {
      return step_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: Step step (repeated)
     *&#64;&#64;
     *&#64;&#64;     The models and the input / output mappings used within the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
     */
    public ModelConfigOuterClass.ModelEnsembling.StepOrBuilder getStepOrBuilder(
        int index) {
      return step_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < step_.size(); i++) {
        output.writeMessage(1, step_.get(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < step_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, step_.get(i));
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelEnsembling)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelEnsembling other = (ModelConfigOuterClass.ModelEnsembling) obj;

      boolean result = true;
      result = result && getStepList()
          .equals(other.getStepList());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getStepCount() > 0) {
        hash = (37 * hash) + STEP_FIELD_NUMBER;
        hash = (53 * hash) + getStepList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelEnsembling parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelEnsembling prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelEnsembling
     *&#64;&#64;
     *&#64;&#64;   Model ensembling configuration. These settings specify the models that
     *&#64;&#64;   compose the ensemble and how data flows between the models.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelEnsembling}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelEnsembling)
        ModelConfigOuterClass.ModelEnsemblingOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelEnsembling.class, ModelConfigOuterClass.ModelEnsembling.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelEnsembling.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStepFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (stepBuilder_ == null) {
          step_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          stepBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelEnsembling_descriptor;
      }

      public ModelConfigOuterClass.ModelEnsembling getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelEnsembling build() {
        ModelConfigOuterClass.ModelEnsembling result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelEnsembling buildPartial() {
        ModelConfigOuterClass.ModelEnsembling result = new ModelConfigOuterClass.ModelEnsembling(this);
        int from_bitField0_ = bitField0_;
        if (stepBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            step_ = java.util.Collections.unmodifiableList(step_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.step_ = step_;
        } else {
          result.step_ = stepBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelEnsembling) {
          return mergeFrom((ModelConfigOuterClass.ModelEnsembling)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelEnsembling other) {
        if (other == ModelConfigOuterClass.ModelEnsembling.getDefaultInstance()) return this;
        if (stepBuilder_ == null) {
          if (!other.step_.isEmpty()) {
            if (step_.isEmpty()) {
              step_ = other.step_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureStepIsMutable();
              step_.addAll(other.step_);
            }
            onChanged();
          }
        } else {
          if (!other.step_.isEmpty()) {
            if (stepBuilder_.isEmpty()) {
              stepBuilder_.dispose();
              stepBuilder_ = null;
              step_ = other.step_;
              bitField0_ = (bitField0_ & ~0x00000001);
              stepBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getStepFieldBuilder() : null;
            } else {
              stepBuilder_.addAllMessages(other.step_);
            }
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelEnsembling parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelEnsembling) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<Step> step_ =
        java.util.Collections.emptyList();
      private void ensureStepIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          step_ = new java.util.ArrayList<Step>(step_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelEnsembling.Step, ModelConfigOuterClass.ModelEnsembling.Step.Builder, ModelConfigOuterClass.ModelEnsembling.StepOrBuilder> stepBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public java.util.List<Step> getStepList() {
        if (stepBuilder_ == null) {
          return java.util.Collections.unmodifiableList(step_);
        } else {
          return stepBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public int getStepCount() {
        if (stepBuilder_ == null) {
          return step_.size();
        } else {
          return stepBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.Step getStep(int index) {
        if (stepBuilder_ == null) {
          return step_.get(index);
        } else {
          return stepBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder setStep(
          int index, ModelConfigOuterClass.ModelEnsembling.Step value) {
        if (stepBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStepIsMutable();
          step_.set(index, value);
          onChanged();
        } else {
          stepBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder setStep(
          int index, ModelConfigOuterClass.ModelEnsembling.Step.Builder builderForValue) {
        if (stepBuilder_ == null) {
          ensureStepIsMutable();
          step_.set(index, builderForValue.build());
          onChanged();
        } else {
          stepBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder addStep(ModelConfigOuterClass.ModelEnsembling.Step value) {
        if (stepBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStepIsMutable();
          step_.add(value);
          onChanged();
        } else {
          stepBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder addStep(
          int index, ModelConfigOuterClass.ModelEnsembling.Step value) {
        if (stepBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureStepIsMutable();
          step_.add(index, value);
          onChanged();
        } else {
          stepBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder addStep(
          ModelConfigOuterClass.ModelEnsembling.Step.Builder builderForValue) {
        if (stepBuilder_ == null) {
          ensureStepIsMutable();
          step_.add(builderForValue.build());
          onChanged();
        } else {
          stepBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder addStep(
          int index, ModelConfigOuterClass.ModelEnsembling.Step.Builder builderForValue) {
        if (stepBuilder_ == null) {
          ensureStepIsMutable();
          step_.add(index, builderForValue.build());
          onChanged();
        } else {
          stepBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder addAllStep(
          Iterable<? extends Step> values) {
        if (stepBuilder_ == null) {
          ensureStepIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, step_);
          onChanged();
        } else {
          stepBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder clearStep() {
        if (stepBuilder_ == null) {
          step_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          stepBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public Builder removeStep(int index) {
        if (stepBuilder_ == null) {
          ensureStepIsMutable();
          step_.remove(index);
          onChanged();
        } else {
          stepBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.Step.Builder getStepBuilder(
          int index) {
        return getStepFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.StepOrBuilder getStepOrBuilder(
          int index) {
        if (stepBuilder_ == null) {
          return step_.get(index);  } else {
          return stepBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public java.util.List<? extends StepOrBuilder>
           getStepOrBuilderList() {
        if (stepBuilder_ != null) {
          return stepBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(step_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.Step.Builder addStepBuilder() {
        return getStepFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelEnsembling.Step.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.Step.Builder addStepBuilder(
          int index) {
        return getStepFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelEnsembling.Step.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: Step step (repeated)
       *&#64;&#64;
       *&#64;&#64;     The models and the input / output mappings used within the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelEnsembling.Step step = 1;</code>
       */
      public java.util.List<Step.Builder>
           getStepBuilderList() {
        return getStepFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelEnsembling.Step, ModelConfigOuterClass.ModelEnsembling.Step.Builder, ModelConfigOuterClass.ModelEnsembling.StepOrBuilder>
          getStepFieldBuilder() {
        if (stepBuilder_ == null) {
          stepBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelEnsembling.Step, ModelConfigOuterClass.ModelEnsembling.Step.Builder, ModelConfigOuterClass.ModelEnsembling.StepOrBuilder>(
                  step_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          step_ = null;
        }
        return stepBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelEnsembling)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelEnsembling)
    private static final ModelConfigOuterClass.ModelEnsembling DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelEnsembling();
    }

    public static ModelConfigOuterClass.ModelEnsembling getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelEnsembling>
        PARSER = new com.google.protobuf.AbstractParser<ModelEnsembling>() {
      public ModelEnsembling parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelEnsembling(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelEnsembling> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelEnsembling> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelEnsembling getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelParameterOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelParameter)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string string_value
     *&#64;&#64;
     *&#64;&#64;     The string value of the parameter.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string string_value = 1;</code>
     */
    String getStringValue();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string string_value
     *&#64;&#64;
     *&#64;&#64;     The string value of the parameter.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string string_value = 1;</code>
     */
    com.google.protobuf.ByteString
        getStringValueBytes();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelParameter
   *&#64;&#64;
   *&#64;&#64;   A model parameter.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelParameter}
   */
  public  static final class ModelParameter extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelParameter)
      ModelParameterOrBuilder {
    // Use ModelParameter.newBuilder() to construct.
    private ModelParameter(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelParameter() {
      stringValue_ = "";
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelParameter(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              stringValue_ = s;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelParameter_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelParameter_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelParameter.class, ModelConfigOuterClass.ModelParameter.Builder.class);
    }

    public static final int STRING_VALUE_FIELD_NUMBER = 1;
    private volatile Object stringValue_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string string_value
     *&#64;&#64;
     *&#64;&#64;     The string value of the parameter.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string string_value = 1;</code>
     */
    public String getStringValue() {
      Object ref = stringValue_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        stringValue_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string string_value
     *&#64;&#64;
     *&#64;&#64;     The string value of the parameter.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string string_value = 1;</code>
     */
    public com.google.protobuf.ByteString
        getStringValueBytes() {
      Object ref = stringValue_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        stringValue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getStringValueBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, stringValue_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getStringValueBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, stringValue_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelParameter)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelParameter other = (ModelConfigOuterClass.ModelParameter) obj;

      boolean result = true;
      result = result && getStringValue()
          .equals(other.getStringValue());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + STRING_VALUE_FIELD_NUMBER;
      hash = (53 * hash) + getStringValue().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelParameter parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelParameter parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelParameter parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelParameter parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelParameter prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelParameter
     *&#64;&#64;
     *&#64;&#64;   A model parameter.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelParameter}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelParameter)
        ModelConfigOuterClass.ModelParameterOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelParameter_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelParameter_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelParameter.class, ModelConfigOuterClass.ModelParameter.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelParameter.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        stringValue_ = "";

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelParameter_descriptor;
      }

      public ModelConfigOuterClass.ModelParameter getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelParameter.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelParameter build() {
        ModelConfigOuterClass.ModelParameter result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelParameter buildPartial() {
        ModelConfigOuterClass.ModelParameter result = new ModelConfigOuterClass.ModelParameter(this);
        result.stringValue_ = stringValue_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelParameter) {
          return mergeFrom((ModelConfigOuterClass.ModelParameter)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelParameter other) {
        if (other == ModelConfigOuterClass.ModelParameter.getDefaultInstance()) return this;
        if (!other.getStringValue().isEmpty()) {
          stringValue_ = other.stringValue_;
          onChanged();
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelParameter parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelParameter) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private Object stringValue_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string string_value
       *&#64;&#64;
       *&#64;&#64;     The string value of the parameter.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string string_value = 1;</code>
       */
      public String getStringValue() {
        Object ref = stringValue_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          stringValue_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string string_value
       *&#64;&#64;
       *&#64;&#64;     The string value of the parameter.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string string_value = 1;</code>
       */
      public com.google.protobuf.ByteString
          getStringValueBytes() {
        Object ref = stringValue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          stringValue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string string_value
       *&#64;&#64;
       *&#64;&#64;     The string value of the parameter.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string string_value = 1;</code>
       */
      public Builder setStringValue(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        stringValue_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string string_value
       *&#64;&#64;
       *&#64;&#64;     The string value of the parameter.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string string_value = 1;</code>
       */
      public Builder clearStringValue() {

        stringValue_ = getDefaultInstance().getStringValue();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string string_value
       *&#64;&#64;
       *&#64;&#64;     The string value of the parameter.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string string_value = 1;</code>
       */
      public Builder setStringValueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        stringValue_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelParameter)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelParameter)
    private static final ModelConfigOuterClass.ModelParameter DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelParameter();
    }

    public static ModelConfigOuterClass.ModelParameter getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelParameter>
        PARSER = new com.google.protobuf.AbstractParser<ModelParameter>() {
      public ModelParameter parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelParameter(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelParameter> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelParameter> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelParameter getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelWarmupOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelWarmup)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the request sample.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    String getName();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the request sample.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 batch_size
     *&#64;&#64;
     *&#64;&#64;     The batch size of the inference request. This must be &gt;= 1. For
     *&#64;&#64;     models that don't support batching, batch_size must be 1. If
     *&#64;&#64;     batch_size &gt; 1, the 'inputs' specified below will be duplicated to
     *&#64;&#64;     match the batch size requested.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 batch_size = 2;</code>
     */
    int getBatchSize();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */
    int getInputsCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */
    boolean containsInputs(
        String key);
    /**
     * Use {@link #getInputsMap()} instead.
     */
    @Deprecated
    java.util.Map<String, ModelWarmup.Input>
    getInputs();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */
    java.util.Map<String, ModelWarmup.Input>
    getInputsMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    ModelConfigOuterClass.ModelWarmup.Input getInputsOrDefault(
        String key,
        ModelConfigOuterClass.ModelWarmup.Input defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    ModelConfigOuterClass.ModelWarmup.Input getInputsOrThrow(
        String key);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelWarmup
   *&#64;&#64;
   *&#64;&#64;   Settings used to construct the request sample for model warmup.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelWarmup}
   */
  public  static final class ModelWarmup extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelWarmup)
      ModelWarmupOrBuilder {
    // Use ModelWarmup.newBuilder() to construct.
    private ModelWarmup(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelWarmup() {
      name_ = "";
      batchSize_ = 0;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelWarmup(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 16: {

              batchSize_ = input.readUInt32();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                inputs_ = com.google.protobuf.MapField.newMapField(
                    InputsDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000004;
              }
              com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelWarmup.Input>
              inputs = input.readMessage(
                  InputsDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              inputs_.getMutableMap().put(inputs.getKey(), inputs.getValue());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelWarmup_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 3:
          return internalGetInputs();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelWarmup_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelWarmup.class, ModelConfigOuterClass.ModelWarmup.Builder.class);
    }

    public interface InputOrBuilder extends
        // @@protoc_insertion_point(interface_extends:inference.ModelWarmup.Input)
        com.google.protobuf.MessageOrBuilder {

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 1;</code>
       */
      int getDataTypeValue();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 1;</code>
       */
      ModelConfigOuterClass.DataType getDataType();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      java.util.List<Long> getDimsList();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      int getDimsCount();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      long getDims(int index);

      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;    .. cpp:var:: bool zero_data
       *&#64;&#64;
       *&#64;&#64;       The identifier for using zeros as input data. Note that the
       *&#64;&#64;       value of 'zero_data' will not be checked, instead, zero data
       *&#64;&#64;       will be used as long as the field is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool zero_data = 3;</code>
       */
      boolean getZeroData();

      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;    .. cpp:var:: bool random_data
       *&#64;&#64;
       *&#64;&#64;       The identifier for using random data as input data. Note that
       *&#64;&#64;       the value of 'random_data' will not be checked, instead,
       *&#64;&#64;       random data will be used as long as the field is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool random_data = 4;</code>
       */
      boolean getRandomData();

      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string input_data_file
       *&#64;&#64;
       *&#64;&#64;       The file whose content will be used as raw input data in
       *&#64;&#64;       row-major order. The file must be provided in a sub-directory
       *&#64;&#64;       'warmup' under the model directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string input_data_file = 5;</code>
       */
      String getInputDataFile();
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string input_data_file
       *&#64;&#64;
       *&#64;&#64;       The file whose content will be used as raw input data in
       *&#64;&#64;       row-major order. The file must be provided in a sub-directory
       *&#64;&#64;       'warmup' under the model directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string input_data_file = 5;</code>
       */
      com.google.protobuf.ByteString
          getInputDataFileBytes();

      public ModelConfigOuterClass.ModelWarmup.Input.InputDataTypeCase getInputDataTypeCase();
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;  .. cpp:var:: message Input
     *&#64;&#64;
     *&#64;&#64;     Meta data associated with an input.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelWarmup.Input}
     */
    public  static final class Input extends
        com.google.protobuf.GeneratedMessageV3 implements
        // @@protoc_insertion_point(message_implements:inference.ModelWarmup.Input)
        InputOrBuilder {
      // Use Input.newBuilder() to construct.
      private Input(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
        super(builder);
      }
      private Input() {
        dataType_ = 0;
        dims_ = java.util.Collections.emptyList();
      }

      @Override
      public final com.google.protobuf.UnknownFieldSet
      getUnknownFields() {
        return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
      }
      private Input(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        this();
        int mutable_bitField0_ = 0;
        try {
          boolean done = false;
          while (!done) {
            int tag = input.readTag();
            switch (tag) {
              case 0:
                done = true;
                break;
              default: {
                if (!input.skipField(tag)) {
                  done = true;
                }
                break;
              }
              case 8: {
                int rawValue = input.readEnum();

                dataType_ = rawValue;
                break;
              }
              case 16: {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  dims_ = new java.util.ArrayList<Long>();
                  mutable_bitField0_ |= 0x00000002;
                }
                dims_.add(input.readInt64());
                break;
              }
              case 18: {
                int length = input.readRawVarint32();
                int limit = input.pushLimit(length);
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002) && input.getBytesUntilLimit() > 0) {
                  dims_ = new java.util.ArrayList<Long>();
                  mutable_bitField0_ |= 0x00000002;
                }
                while (input.getBytesUntilLimit() > 0) {
                  dims_.add(input.readInt64());
                }
                input.popLimit(limit);
                break;
              }
              case 24: {
                inputDataTypeCase_ = 3;
                inputDataType_ = input.readBool();
                break;
              }
              case 32: {
                inputDataTypeCase_ = 4;
                inputDataType_ = input.readBool();
                break;
              }
              case 42: {
                String s = input.readStringRequireUtf8();
                inputDataTypeCase_ = 5;
                inputDataType_ = s;
                break;
              }
            }
          }
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          throw e.setUnfinishedMessage(this);
        } catch (java.io.IOException e) {
          throw new com.google.protobuf.InvalidProtocolBufferException(
              e).setUnfinishedMessage(this);
        } finally {
          if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
            dims_ = java.util.Collections.unmodifiableList(dims_);
          }
          makeExtensionsImmutable();
        }
      }
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelWarmup_Input_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelWarmup_Input_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelWarmup.Input.class, ModelConfigOuterClass.ModelWarmup.Input.Builder.class);
      }

      private int bitField0_;
      private int inputDataTypeCase_ = 0;
      private Object inputDataType_;
      public enum InputDataTypeCase
          implements com.google.protobuf.Internal.EnumLite {
        ZERO_DATA(3),
        RANDOM_DATA(4),
        INPUT_DATA_FILE(5),
        INPUTDATATYPE_NOT_SET(0);
        private final int value;
        private InputDataTypeCase(int value) {
          this.value = value;
        }
        /**
         * @deprecated Use {@link #forNumber(int)} instead.
         */
        @Deprecated
        public static InputDataTypeCase valueOf(int value) {
          return forNumber(value);
        }

        public static InputDataTypeCase forNumber(int value) {
          switch (value) {
            case 3: return ZERO_DATA;
            case 4: return RANDOM_DATA;
            case 5: return INPUT_DATA_FILE;
            case 0: return INPUTDATATYPE_NOT_SET;
            default: return null;
          }
        }
        public int getNumber() {
          return this.value;
        }
      };

      public InputDataTypeCase
      getInputDataTypeCase() {
        return InputDataTypeCase.forNumber(
            inputDataTypeCase_);
      }

      public static final int DATA_TYPE_FIELD_NUMBER = 1;
      private int dataType_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 1;</code>
       */
      public int getDataTypeValue() {
        return dataType_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: DataType data_type
       *&#64;&#64;
       *&#64;&#64;       The data-type of the input.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.DataType data_type = 1;</code>
       */
      public ModelConfigOuterClass.DataType getDataType() {
        ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
        return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
      }

      public static final int DIMS_FIELD_NUMBER = 2;
      private java.util.List<Long> dims_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      public java.util.List<Long>
          getDimsList() {
        return dims_;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      public int getDimsCount() {
        return dims_.size();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
       *&#64;&#64;
       *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated int64 dims = 2;</code>
       */
      public long getDims(int index) {
        return dims_.get(index);
      }
      private int dimsMemoizedSerializedSize = -1;

      public static final int ZERO_DATA_FIELD_NUMBER = 3;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;    .. cpp:var:: bool zero_data
       *&#64;&#64;
       *&#64;&#64;       The identifier for using zeros as input data. Note that the
       *&#64;&#64;       value of 'zero_data' will not be checked, instead, zero data
       *&#64;&#64;       will be used as long as the field is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool zero_data = 3;</code>
       */
      public boolean getZeroData() {
        if (inputDataTypeCase_ == 3) {
          return (Boolean) inputDataType_;
        }
        return false;
      }

      public static final int RANDOM_DATA_FIELD_NUMBER = 4;
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;    .. cpp:var:: bool random_data
       *&#64;&#64;
       *&#64;&#64;       The identifier for using random data as input data. Note that
       *&#64;&#64;       the value of 'random_data' will not be checked, instead,
       *&#64;&#64;       random data will be used as long as the field is set.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool random_data = 4;</code>
       */
      public boolean getRandomData() {
        if (inputDataTypeCase_ == 4) {
          return (Boolean) inputDataType_;
        }
        return false;
      }

      public static final int INPUT_DATA_FILE_FIELD_NUMBER = 5;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string input_data_file
       *&#64;&#64;
       *&#64;&#64;       The file whose content will be used as raw input data in
       *&#64;&#64;       row-major order. The file must be provided in a sub-directory
       *&#64;&#64;       'warmup' under the model directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string input_data_file = 5;</code>
       */
      public String getInputDataFile() {
        Object ref = "";
        if (inputDataTypeCase_ == 5) {
          ref = inputDataType_;
        }
        if (ref instanceof String) {
          return (String) ref;
        } else {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          if (inputDataTypeCase_ == 5) {
            inputDataType_ = s;
          }
          return s;
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: string input_data_file
       *&#64;&#64;
       *&#64;&#64;       The file whose content will be used as raw input data in
       *&#64;&#64;       row-major order. The file must be provided in a sub-directory
       *&#64;&#64;       'warmup' under the model directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string input_data_file = 5;</code>
       */
      public com.google.protobuf.ByteString
          getInputDataFileBytes() {
        Object ref = "";
        if (inputDataTypeCase_ == 5) {
          ref = inputDataType_;
        }
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          if (inputDataTypeCase_ == 5) {
            inputDataType_ = b;
          }
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }

      private byte memoizedIsInitialized = -1;
      public final boolean isInitialized() {
        byte isInitialized = memoizedIsInitialized;
        if (isInitialized == 1) return true;
        if (isInitialized == 0) return false;

        memoizedIsInitialized = 1;
        return true;
      }

      public void writeTo(com.google.protobuf.CodedOutputStream output)
                          throws java.io.IOException {
        getSerializedSize();
        if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
          output.writeEnum(1, dataType_);
        }
        if (getDimsList().size() > 0) {
          output.writeUInt32NoTag(18);
          output.writeUInt32NoTag(dimsMemoizedSerializedSize);
        }
        for (int i = 0; i < dims_.size(); i++) {
          output.writeInt64NoTag(dims_.get(i));
        }
        if (inputDataTypeCase_ == 3) {
          output.writeBool(
              3, (boolean)((Boolean) inputDataType_));
        }
        if (inputDataTypeCase_ == 4) {
          output.writeBool(
              4, (boolean)((Boolean) inputDataType_));
        }
        if (inputDataTypeCase_ == 5) {
          com.google.protobuf.GeneratedMessageV3.writeString(output, 5, inputDataType_);
        }
      }

      public int getSerializedSize() {
        int size = memoizedSize;
        if (size != -1) return size;

        size = 0;
        if (dataType_ != ModelConfigOuterClass.DataType.TYPE_INVALID.getNumber()) {
          size += com.google.protobuf.CodedOutputStream
            .computeEnumSize(1, dataType_);
        }
        {
          int dataSize = 0;
          for (int i = 0; i < dims_.size(); i++) {
            dataSize += com.google.protobuf.CodedOutputStream
              .computeInt64SizeNoTag(dims_.get(i));
          }
          size += dataSize;
          if (!getDimsList().isEmpty()) {
            size += 1;
            size += com.google.protobuf.CodedOutputStream
                .computeInt32SizeNoTag(dataSize);
          }
          dimsMemoizedSerializedSize = dataSize;
        }
        if (inputDataTypeCase_ == 3) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(
                3, (boolean)((Boolean) inputDataType_));
        }
        if (inputDataTypeCase_ == 4) {
          size += com.google.protobuf.CodedOutputStream
            .computeBoolSize(
                4, (boolean)((Boolean) inputDataType_));
        }
        if (inputDataTypeCase_ == 5) {
          size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, inputDataType_);
        }
        memoizedSize = size;
        return size;
      }

      private static final long serialVersionUID = 0L;
      @Override
      public boolean equals(final Object obj) {
        if (obj == this) {
         return true;
        }
        if (!(obj instanceof ModelConfigOuterClass.ModelWarmup.Input)) {
          return super.equals(obj);
        }
        ModelConfigOuterClass.ModelWarmup.Input other = (ModelConfigOuterClass.ModelWarmup.Input) obj;

        boolean result = true;
        result = result && dataType_ == other.dataType_;
        result = result && getDimsList()
            .equals(other.getDimsList());
        result = result && getInputDataTypeCase().equals(
            other.getInputDataTypeCase());
        if (!result) return false;
        switch (inputDataTypeCase_) {
          case 3:
            result = result && (getZeroData()
                == other.getZeroData());
            break;
          case 4:
            result = result && (getRandomData()
                == other.getRandomData());
            break;
          case 5:
            result = result && getInputDataFile()
                .equals(other.getInputDataFile());
            break;
          case 0:
          default:
        }
        return result;
      }

      @Override
      public int hashCode() {
        if (memoizedHashCode != 0) {
          return memoizedHashCode;
        }
        int hash = 41;
        hash = (19 * hash) + getDescriptorForType().hashCode();
        hash = (37 * hash) + DATA_TYPE_FIELD_NUMBER;
        hash = (53 * hash) + dataType_;
        if (getDimsCount() > 0) {
          hash = (37 * hash) + DIMS_FIELD_NUMBER;
          hash = (53 * hash) + getDimsList().hashCode();
        }
        switch (inputDataTypeCase_) {
          case 3:
            hash = (37 * hash) + ZERO_DATA_FIELD_NUMBER;
            hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
                getZeroData());
            break;
          case 4:
            hash = (37 * hash) + RANDOM_DATA_FIELD_NUMBER;
            hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
                getRandomData());
            break;
          case 5:
            hash = (37 * hash) + INPUT_DATA_FILE_FIELD_NUMBER;
            hash = (53 * hash) + getInputDataFile().hashCode();
            break;
          case 0:
          default:
        }
        hash = (29 * hash) + unknownFields.hashCode();
        memoizedHashCode = hash;
        return hash;
      }

      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          com.google.protobuf.ByteString data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          com.google.protobuf.ByteString data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(byte[] data)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          byte[] data,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
        return PARSER.parseFrom(data, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseDelimitedFrom(java.io.InputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseDelimitedFrom(
          java.io.InputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          com.google.protobuf.CodedInputStream input)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input);
      }
      public static ModelConfigOuterClass.ModelWarmup.Input parseFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        return com.google.protobuf.GeneratedMessageV3
            .parseWithIOException(PARSER, input, extensionRegistry);
      }

      public Builder newBuilderForType() { return newBuilder(); }
      public static Builder newBuilder() {
        return DEFAULT_INSTANCE.toBuilder();
      }
      public static Builder newBuilder(ModelConfigOuterClass.ModelWarmup.Input prototype) {
        return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
      }
      public Builder toBuilder() {
        return this == DEFAULT_INSTANCE
            ? new Builder() : new Builder().mergeFrom(this);
      }

      @Override
      protected Builder newBuilderForType(
          BuilderParent parent) {
        Builder builder = new Builder(parent);
        return builder;
      }
      /**
       * <pre>
       *&#64;&#64;
       *&#64;&#64;  .. cpp:var:: message Input
       *&#64;&#64;
       *&#64;&#64;     Meta data associated with an input.
       *&#64;&#64;
       * </pre>
       *
       * Protobuf type {@code inference.ModelWarmup.Input}
       */
      public static final class Builder extends
          com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
          // @@protoc_insertion_point(builder_implements:inference.ModelWarmup.Input)
          ModelConfigOuterClass.ModelWarmup.InputOrBuilder {
        public static final com.google.protobuf.Descriptors.Descriptor
            getDescriptor() {
          return ModelConfigOuterClass.internal_static_inference_ModelWarmup_Input_descriptor;
        }

        protected FieldAccessorTable
            internalGetFieldAccessorTable() {
          return ModelConfigOuterClass.internal_static_inference_ModelWarmup_Input_fieldAccessorTable
              .ensureFieldAccessorsInitialized(
                  ModelConfigOuterClass.ModelWarmup.Input.class, ModelConfigOuterClass.ModelWarmup.Input.Builder.class);
        }

        // Construct using ModelConfigOuterClass.ModelWarmup.Input.newBuilder()
        private Builder() {
          maybeForceBuilderInitialization();
        }

        private Builder(
            BuilderParent parent) {
          super(parent);
          maybeForceBuilderInitialization();
        }
        private void maybeForceBuilderInitialization() {
          if (com.google.protobuf.GeneratedMessageV3
                  .alwaysUseFieldBuilders) {
          }
        }
        public Builder clear() {
          super.clear();
          dataType_ = 0;

          dims_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          inputDataTypeCase_ = 0;
          inputDataType_ = null;
          return this;
        }

        public com.google.protobuf.Descriptors.Descriptor
            getDescriptorForType() {
          return ModelConfigOuterClass.internal_static_inference_ModelWarmup_Input_descriptor;
        }

        public ModelConfigOuterClass.ModelWarmup.Input getDefaultInstanceForType() {
          return ModelConfigOuterClass.ModelWarmup.Input.getDefaultInstance();
        }

        public ModelConfigOuterClass.ModelWarmup.Input build() {
          ModelConfigOuterClass.ModelWarmup.Input result = buildPartial();
          if (!result.isInitialized()) {
            throw newUninitializedMessageException(result);
          }
          return result;
        }

        public ModelConfigOuterClass.ModelWarmup.Input buildPartial() {
          ModelConfigOuterClass.ModelWarmup.Input result = new ModelConfigOuterClass.ModelWarmup.Input(this);
          int from_bitField0_ = bitField0_;
          int to_bitField0_ = 0;
          result.dataType_ = dataType_;
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            dims_ = java.util.Collections.unmodifiableList(dims_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.dims_ = dims_;
          if (inputDataTypeCase_ == 3) {
            result.inputDataType_ = inputDataType_;
          }
          if (inputDataTypeCase_ == 4) {
            result.inputDataType_ = inputDataType_;
          }
          if (inputDataTypeCase_ == 5) {
            result.inputDataType_ = inputDataType_;
          }
          result.bitField0_ = to_bitField0_;
          result.inputDataTypeCase_ = inputDataTypeCase_;
          onBuilt();
          return result;
        }

        public Builder clone() {
          return (Builder) super.clone();
        }
        public Builder setField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.setField(field, value);
        }
        public Builder clearField(
            com.google.protobuf.Descriptors.FieldDescriptor field) {
          return (Builder) super.clearField(field);
        }
        public Builder clearOneof(
            com.google.protobuf.Descriptors.OneofDescriptor oneof) {
          return (Builder) super.clearOneof(oneof);
        }
        public Builder setRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            int index, Object value) {
          return (Builder) super.setRepeatedField(field, index, value);
        }
        public Builder addRepeatedField(
            com.google.protobuf.Descriptors.FieldDescriptor field,
            Object value) {
          return (Builder) super.addRepeatedField(field, value);
        }
        public Builder mergeFrom(com.google.protobuf.Message other) {
          if (other instanceof ModelConfigOuterClass.ModelWarmup.Input) {
            return mergeFrom((ModelConfigOuterClass.ModelWarmup.Input)other);
          } else {
            super.mergeFrom(other);
            return this;
          }
        }

        public Builder mergeFrom(ModelConfigOuterClass.ModelWarmup.Input other) {
          if (other == ModelConfigOuterClass.ModelWarmup.Input.getDefaultInstance()) return this;
          if (other.dataType_ != 0) {
            setDataTypeValue(other.getDataTypeValue());
          }
          if (!other.dims_.isEmpty()) {
            if (dims_.isEmpty()) {
              dims_ = other.dims_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureDimsIsMutable();
              dims_.addAll(other.dims_);
            }
            onChanged();
          }
          switch (other.getInputDataTypeCase()) {
            case ZERO_DATA: {
              setZeroData(other.getZeroData());
              break;
            }
            case RANDOM_DATA: {
              setRandomData(other.getRandomData());
              break;
            }
            case INPUT_DATA_FILE: {
              inputDataTypeCase_ = 5;
              inputDataType_ = other.inputDataType_;
              onChanged();
              break;
            }
            case INPUTDATATYPE_NOT_SET: {
              break;
            }
          }
          onChanged();
          return this;
        }

        public final boolean isInitialized() {
          return true;
        }

        public Builder mergeFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws java.io.IOException {
          ModelConfigOuterClass.ModelWarmup.Input parsedMessage = null;
          try {
            parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
          } catch (com.google.protobuf.InvalidProtocolBufferException e) {
            parsedMessage = (ModelConfigOuterClass.ModelWarmup.Input) e.getUnfinishedMessage();
            throw e.unwrapIOException();
          } finally {
            if (parsedMessage != null) {
              mergeFrom(parsedMessage);
            }
          }
          return this;
        }
        private int inputDataTypeCase_ = 0;
        private Object inputDataType_;
        public InputDataTypeCase
            getInputDataTypeCase() {
          return InputDataTypeCase.forNumber(
              inputDataTypeCase_);
        }

        public Builder clearInputDataType() {
          inputDataTypeCase_ = 0;
          inputDataType_ = null;
          onChanged();
          return this;
        }

        private int bitField0_;

        private int dataType_ = 0;
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The data-type of the input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 1;</code>
         */
        public int getDataTypeValue() {
          return dataType_;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The data-type of the input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 1;</code>
         */
        public Builder setDataTypeValue(int value) {
          dataType_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The data-type of the input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 1;</code>
         */
        public ModelConfigOuterClass.DataType getDataType() {
          ModelConfigOuterClass.DataType result = ModelConfigOuterClass.DataType.valueOf(dataType_);
          return result == null ? ModelConfigOuterClass.DataType.UNRECOGNIZED : result;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The data-type of the input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 1;</code>
         */
        public Builder setDataType(ModelConfigOuterClass.DataType value) {
          if (value == null) {
            throw new NullPointerException();
          }

          dataType_ = value.getNumber();
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: DataType data_type
         *&#64;&#64;
         *&#64;&#64;       The data-type of the input.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional .inference.DataType data_type = 1;</code>
         */
        public Builder clearDataType() {

          dataType_ = 0;
          onChanged();
          return this;
        }

        private java.util.List<Long> dims_ = java.util.Collections.emptyList();
        private void ensureDimsIsMutable() {
          if (!((bitField0_ & 0x00000002) == 0x00000002)) {
            dims_ = new java.util.ArrayList<Long>(dims_);
            bitField0_ |= 0x00000002;
           }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public java.util.List<Long>
            getDimsList() {
          return java.util.Collections.unmodifiableList(dims_);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public int getDimsCount() {
          return dims_.size();
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public long getDims(int index) {
          return dims_.get(index);
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public Builder setDims(
            int index, long value) {
          ensureDimsIsMutable();
          dims_.set(index, value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public Builder addDims(long value) {
          ensureDimsIsMutable();
          dims_.add(value);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public Builder addAllDims(
            Iterable<? extends Long> values) {
          ensureDimsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, dims_);
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: int64 dims (repeated)
         *&#64;&#64;
         *&#64;&#64;       The shape of the input tensor, not including the batch dimension.
         *&#64;&#64;
         * </pre>
         *
         * <code>repeated int64 dims = 2;</code>
         */
        public Builder clearDims() {
          dims_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
          return this;
        }

        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool zero_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using zeros as input data. Note that the
         *&#64;&#64;       value of 'zero_data' will not be checked, instead, zero data
         *&#64;&#64;       will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool zero_data = 3;</code>
         */
        public boolean getZeroData() {
          if (inputDataTypeCase_ == 3) {
            return (Boolean) inputDataType_;
          }
          return false;
        }
        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool zero_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using zeros as input data. Note that the
         *&#64;&#64;       value of 'zero_data' will not be checked, instead, zero data
         *&#64;&#64;       will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool zero_data = 3;</code>
         */
        public Builder setZeroData(boolean value) {
          inputDataTypeCase_ = 3;
          inputDataType_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool zero_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using zeros as input data. Note that the
         *&#64;&#64;       value of 'zero_data' will not be checked, instead, zero data
         *&#64;&#64;       will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool zero_data = 3;</code>
         */
        public Builder clearZeroData() {
          if (inputDataTypeCase_ == 3) {
            inputDataTypeCase_ = 0;
            inputDataType_ = null;
            onChanged();
          }
          return this;
        }

        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool random_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using random data as input data. Note that
         *&#64;&#64;       the value of 'random_data' will not be checked, instead,
         *&#64;&#64;       random data will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool random_data = 4;</code>
         */
        public boolean getRandomData() {
          if (inputDataTypeCase_ == 4) {
            return (Boolean) inputDataType_;
          }
          return false;
        }
        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool random_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using random data as input data. Note that
         *&#64;&#64;       the value of 'random_data' will not be checked, instead,
         *&#64;&#64;       random data will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool random_data = 4;</code>
         */
        public Builder setRandomData(boolean value) {
          inputDataTypeCase_ = 4;
          inputDataType_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;
         *&#64;&#64;    .. cpp:var:: bool random_data
         *&#64;&#64;
         *&#64;&#64;       The identifier for using random data as input data. Note that
         *&#64;&#64;       the value of 'random_data' will not be checked, instead,
         *&#64;&#64;       random data will be used as long as the field is set.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional bool random_data = 4;</code>
         */
        public Builder clearRandomData() {
          if (inputDataTypeCase_ == 4) {
            inputDataTypeCase_ = 0;
            inputDataType_ = null;
            onChanged();
          }
          return this;
        }

        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string input_data_file
         *&#64;&#64;
         *&#64;&#64;       The file whose content will be used as raw input data in
         *&#64;&#64;       row-major order. The file must be provided in a sub-directory
         *&#64;&#64;       'warmup' under the model directory.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string input_data_file = 5;</code>
         */
        public String getInputDataFile() {
          Object ref = "";
          if (inputDataTypeCase_ == 5) {
            ref = inputDataType_;
          }
          if (!(ref instanceof String)) {
            com.google.protobuf.ByteString bs =
                (com.google.protobuf.ByteString) ref;
            String s = bs.toStringUtf8();
            if (inputDataTypeCase_ == 5) {
              inputDataType_ = s;
            }
            return s;
          } else {
            return (String) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string input_data_file
         *&#64;&#64;
         *&#64;&#64;       The file whose content will be used as raw input data in
         *&#64;&#64;       row-major order. The file must be provided in a sub-directory
         *&#64;&#64;       'warmup' under the model directory.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string input_data_file = 5;</code>
         */
        public com.google.protobuf.ByteString
            getInputDataFileBytes() {
          Object ref = "";
          if (inputDataTypeCase_ == 5) {
            ref = inputDataType_;
          }
          if (ref instanceof String) {
            com.google.protobuf.ByteString b =
                com.google.protobuf.ByteString.copyFromUtf8(
                    (String) ref);
            if (inputDataTypeCase_ == 5) {
              inputDataType_ = b;
            }
            return b;
          } else {
            return (com.google.protobuf.ByteString) ref;
          }
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string input_data_file
         *&#64;&#64;
         *&#64;&#64;       The file whose content will be used as raw input data in
         *&#64;&#64;       row-major order. The file must be provided in a sub-directory
         *&#64;&#64;       'warmup' under the model directory.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string input_data_file = 5;</code>
         */
        public Builder setInputDataFile(
            String value) {
          if (value == null) {
    throw new NullPointerException();
  }
  inputDataTypeCase_ = 5;
          inputDataType_ = value;
          onChanged();
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string input_data_file
         *&#64;&#64;
         *&#64;&#64;       The file whose content will be used as raw input data in
         *&#64;&#64;       row-major order. The file must be provided in a sub-directory
         *&#64;&#64;       'warmup' under the model directory.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string input_data_file = 5;</code>
         */
        public Builder clearInputDataFile() {
          if (inputDataTypeCase_ == 5) {
            inputDataTypeCase_ = 0;
            inputDataType_ = null;
            onChanged();
          }
          return this;
        }
        /**
         * <pre>
         *&#64;&#64;    .. cpp:var:: string input_data_file
         *&#64;&#64;
         *&#64;&#64;       The file whose content will be used as raw input data in
         *&#64;&#64;       row-major order. The file must be provided in a sub-directory
         *&#64;&#64;       'warmup' under the model directory.
         *&#64;&#64;
         * </pre>
         *
         * <code>optional string input_data_file = 5;</code>
         */
        public Builder setInputDataFileBytes(
            com.google.protobuf.ByteString value) {
          if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
          inputDataTypeCase_ = 5;
          inputDataType_ = value;
          onChanged();
          return this;
        }
        public final Builder setUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }

        public final Builder mergeUnknownFields(
            final com.google.protobuf.UnknownFieldSet unknownFields) {
          return this;
        }


        // @@protoc_insertion_point(builder_scope:inference.ModelWarmup.Input)
      }

      // @@protoc_insertion_point(class_scope:inference.ModelWarmup.Input)
      private static final ModelConfigOuterClass.ModelWarmup.Input DEFAULT_INSTANCE;
      static {
        DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelWarmup.Input();
      }

      public static ModelConfigOuterClass.ModelWarmup.Input getDefaultInstance() {
        return DEFAULT_INSTANCE;
      }

      private static final com.google.protobuf.Parser<Input>
          PARSER = new com.google.protobuf.AbstractParser<Input>() {
        public Input parsePartialFrom(
            com.google.protobuf.CodedInputStream input,
            com.google.protobuf.ExtensionRegistryLite extensionRegistry)
            throws com.google.protobuf.InvalidProtocolBufferException {
            return new Input(input, extensionRegistry);
        }
      };

      public static com.google.protobuf.Parser<Input> parser() {
        return PARSER;
      }

      @Override
      public com.google.protobuf.Parser<Input> getParserForType() {
        return PARSER;
      }

      public ModelConfigOuterClass.ModelWarmup.Input getDefaultInstanceForType() {
        return DEFAULT_INSTANCE;
      }

    }

    private int bitField0_;
    public static final int NAME_FIELD_NUMBER = 1;
    private volatile Object name_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the request sample.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the request sample.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BATCH_SIZE_FIELD_NUMBER = 2;
    private int batchSize_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: uint32 batch_size
     *&#64;&#64;
     *&#64;&#64;     The batch size of the inference request. This must be &gt;= 1. For
     *&#64;&#64;     models that don't support batching, batch_size must be 1. If
     *&#64;&#64;     batch_size &gt; 1, the 'inputs' specified below will be duplicated to
     *&#64;&#64;     match the batch size requested.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional uint32 batch_size = 2;</code>
     */
    public int getBatchSize() {
      return batchSize_;
    }

    public static final int INPUTS_FIELD_NUMBER = 3;
    private static final class InputsDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          String, ModelConfigOuterClass.ModelWarmup.Input> defaultEntry =
              com.google.protobuf.MapEntry
              .<String, ModelConfigOuterClass.ModelWarmup.Input>newDefaultInstance(
                  ModelConfigOuterClass.internal_static_inference_ModelWarmup_InputsEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  ModelConfigOuterClass.ModelWarmup.Input.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        String, ModelConfigOuterClass.ModelWarmup.Input> inputs_;
    private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelWarmup.Input>
    internalGetInputs() {
      if (inputs_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            InputsDefaultEntryHolder.defaultEntry);
      }
      return inputs_;
    }

    public int getInputsCount() {
      return internalGetInputs().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    public boolean containsInputs(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      return internalGetInputs().getMap().containsKey(key);
    }
    /**
     * Use {@link #getInputsMap()} instead.
     */
    @Deprecated
    public java.util.Map<String, Input> getInputs() {
      return getInputsMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    public java.util.Map<String, Input> getInputsMap() {
      return internalGetInputs().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    public ModelConfigOuterClass.ModelWarmup.Input getInputsOrDefault(
        String key,
        ModelConfigOuterClass.ModelWarmup.Input defaultValue) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, Input> map =
          internalGetInputs().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
     *&#64;&#64;
     *&#64;&#64;     The warmup meta data associated with every model input, including
     *&#64;&#64;     control tensors.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
     */

    public ModelConfigOuterClass.ModelWarmup.Input getInputsOrThrow(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, Input> map =
          internalGetInputs().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (batchSize_ != 0) {
        output.writeUInt32(2, batchSize_);
      }
      for (java.util.Map.Entry<String, Input> entry
           : internalGetInputs().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelWarmup.Input>
        inputs = InputsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        output.writeMessage(3, inputs);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (batchSize_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeUInt32Size(2, batchSize_);
      }
      for (java.util.Map.Entry<String, Input> entry
           : internalGetInputs().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelWarmup.Input>
        inputs = InputsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(3, inputs);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelWarmup)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelWarmup other = (ModelConfigOuterClass.ModelWarmup) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && (getBatchSize()
          == other.getBatchSize());
      result = result && internalGetInputs().equals(
          other.internalGetInputs());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + BATCH_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + getBatchSize();
      if (!internalGetInputs().getMap().isEmpty()) {
        hash = (37 * hash) + INPUTS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetInputs().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelWarmup parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelWarmup parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelWarmup parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelWarmup prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelWarmup
     *&#64;&#64;
     *&#64;&#64;   Settings used to construct the request sample for model warmup.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelWarmup}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelWarmup)
        ModelConfigOuterClass.ModelWarmupOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelWarmup_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 3:
            return internalGetInputs();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 3:
            return internalGetMutableInputs();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelWarmup_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelWarmup.class, ModelConfigOuterClass.ModelWarmup.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelWarmup.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        name_ = "";

        batchSize_ = 0;

        internalGetMutableInputs().clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelWarmup_descriptor;
      }

      public ModelConfigOuterClass.ModelWarmup getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelWarmup.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelWarmup build() {
        ModelConfigOuterClass.ModelWarmup result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelWarmup buildPartial() {
        ModelConfigOuterClass.ModelWarmup result = new ModelConfigOuterClass.ModelWarmup(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.name_ = name_;
        result.batchSize_ = batchSize_;
        result.inputs_ = internalGetInputs();
        result.inputs_.makeImmutable();
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelWarmup) {
          return mergeFrom((ModelConfigOuterClass.ModelWarmup)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelWarmup other) {
        if (other == ModelConfigOuterClass.ModelWarmup.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (other.getBatchSize() != 0) {
          setBatchSize(other.getBatchSize());
        }
        internalGetMutableInputs().mergeFrom(
            other.internalGetInputs());
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelWarmup parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelWarmup) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the request sample.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the request sample.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the request sample.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the request sample.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {

        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the request sample.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        name_ = value;
        onChanged();
        return this;
      }

      private int batchSize_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 batch_size
       *&#64;&#64;
       *&#64;&#64;     The batch size of the inference request. This must be &gt;= 1. For
       *&#64;&#64;     models that don't support batching, batch_size must be 1. If
       *&#64;&#64;     batch_size &gt; 1, the 'inputs' specified below will be duplicated to
       *&#64;&#64;     match the batch size requested.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 batch_size = 2;</code>
       */
      public int getBatchSize() {
        return batchSize_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 batch_size
       *&#64;&#64;
       *&#64;&#64;     The batch size of the inference request. This must be &gt;= 1. For
       *&#64;&#64;     models that don't support batching, batch_size must be 1. If
       *&#64;&#64;     batch_size &gt; 1, the 'inputs' specified below will be duplicated to
       *&#64;&#64;     match the batch size requested.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 batch_size = 2;</code>
       */
      public Builder setBatchSize(int value) {

        batchSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: uint32 batch_size
       *&#64;&#64;
       *&#64;&#64;     The batch size of the inference request. This must be &gt;= 1. For
       *&#64;&#64;     models that don't support batching, batch_size must be 1. If
       *&#64;&#64;     batch_size &gt; 1, the 'inputs' specified below will be duplicated to
       *&#64;&#64;     match the batch size requested.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional uint32 batch_size = 2;</code>
       */
      public Builder clearBatchSize() {

        batchSize_ = 0;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          String, ModelConfigOuterClass.ModelWarmup.Input> inputs_;
      private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelWarmup.Input>
      internalGetInputs() {
        if (inputs_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              InputsDefaultEntryHolder.defaultEntry);
        }
        return inputs_;
      }
      private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelWarmup.Input>
      internalGetMutableInputs() {
        onChanged();;
        if (inputs_ == null) {
          inputs_ = com.google.protobuf.MapField.newMapField(
              InputsDefaultEntryHolder.defaultEntry);
        }
        if (!inputs_.isMutable()) {
          inputs_ = inputs_.copy();
        }
        return inputs_;
      }

      public int getInputsCount() {
        return internalGetInputs().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public boolean containsInputs(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetInputs().getMap().containsKey(key);
      }
      /**
       * Use {@link #getInputsMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, Input> getInputs() {
        return getInputsMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public java.util.Map<String, Input> getInputsMap() {
        return internalGetInputs().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public ModelConfigOuterClass.ModelWarmup.Input getInputsOrDefault(
          String key,
          ModelConfigOuterClass.ModelWarmup.Input defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, Input> map =
            internalGetInputs().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public ModelConfigOuterClass.ModelWarmup.Input getInputsOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, Input> map =
            internalGetInputs().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearInputs() {
        getMutableInputs().clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public Builder removeInputs(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        getMutableInputs().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<String, Input>
      getMutableInputs() {
        return internalGetMutableInputs().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */
      public Builder putInputs(
          String key,
          ModelConfigOuterClass.ModelWarmup.Input value) {
        if (key == null) { throw new NullPointerException(); }
        if (value == null) { throw new NullPointerException(); }
        getMutableInputs().put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string, Input&gt; inputs
       *&#64;&#64;
       *&#64;&#64;     The warmup meta data associated with every model input, including
       *&#64;&#64;     control tensors.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelWarmup.Input&gt; inputs = 3;</code>
       */

      public Builder putAllInputs(
          java.util.Map<String, Input> values) {
        getMutableInputs().putAll(values);
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelWarmup)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelWarmup)
    private static final ModelConfigOuterClass.ModelWarmup DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelWarmup();
    }

    public static ModelConfigOuterClass.ModelWarmup getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelWarmup>
        PARSER = new com.google.protobuf.AbstractParser<ModelWarmup>() {
      public ModelWarmup parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelWarmup(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelWarmup> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelWarmup> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelWarmup getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelOperationsOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelOperations)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    java.util.List<String>
        getOpLibraryFilenameList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    int getOpLibraryFilenameCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    String getOpLibraryFilename(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    com.google.protobuf.ByteString
        getOpLibraryFilenameBytes(int index);
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64; .. cpp:var:: message ModelOperations
   *&#64;&#64;
   *&#64;&#64;    The metadata of libraries providing custom operations for this model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelOperations}
   */
  public  static final class ModelOperations extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelOperations)
      ModelOperationsOrBuilder {
    // Use ModelOperations.newBuilder() to construct.
    private ModelOperations(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelOperations() {
      opLibraryFilename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelOperations(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                opLibraryFilename_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              opLibraryFilename_.add(s);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          opLibraryFilename_ = opLibraryFilename_.getUnmodifiableView();
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelOperations_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelOperations_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelOperations.class, ModelConfigOuterClass.ModelOperations.Builder.class);
    }

    public static final int OP_LIBRARY_FILENAME_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList opLibraryFilename_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getOpLibraryFilenameList() {
      return opLibraryFilename_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    public int getOpLibraryFilenameCount() {
      return opLibraryFilename_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    public String getOpLibraryFilename(int index) {
      return opLibraryFilename_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string op_library_filename
     *&#64;&#64;
     *&#64;&#64;     Optional paths of the libraries providing custom operations for
     *&#64;&#64;     this model. Valid only for ONNX models.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated string op_library_filename = 1;</code>
     */
    public com.google.protobuf.ByteString
        getOpLibraryFilenameBytes(int index) {
      return opLibraryFilename_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < opLibraryFilename_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, opLibraryFilename_.getRaw(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < opLibraryFilename_.size(); i++) {
          dataSize += computeStringSizeNoTag(opLibraryFilename_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getOpLibraryFilenameList().size();
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelOperations)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelOperations other = (ModelConfigOuterClass.ModelOperations) obj;

      boolean result = true;
      result = result && getOpLibraryFilenameList()
          .equals(other.getOpLibraryFilenameList());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getOpLibraryFilenameCount() > 0) {
        hash = (37 * hash) + OP_LIBRARY_FILENAME_FIELD_NUMBER;
        hash = (53 * hash) + getOpLibraryFilenameList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelOperations parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOperations parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOperations parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelOperations parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelOperations prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64; .. cpp:var:: message ModelOperations
     *&#64;&#64;
     *&#64;&#64;    The metadata of libraries providing custom operations for this model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelOperations}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelOperations)
        ModelConfigOuterClass.ModelOperationsOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelOperations_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelOperations_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelOperations.class, ModelConfigOuterClass.ModelOperations.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelOperations.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        opLibraryFilename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelOperations_descriptor;
      }

      public ModelConfigOuterClass.ModelOperations getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelOperations.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelOperations build() {
        ModelConfigOuterClass.ModelOperations result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelOperations buildPartial() {
        ModelConfigOuterClass.ModelOperations result = new ModelConfigOuterClass.ModelOperations(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          opLibraryFilename_ = opLibraryFilename_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.opLibraryFilename_ = opLibraryFilename_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelOperations) {
          return mergeFrom((ModelConfigOuterClass.ModelOperations)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelOperations other) {
        if (other == ModelConfigOuterClass.ModelOperations.getDefaultInstance()) return this;
        if (!other.opLibraryFilename_.isEmpty()) {
          if (opLibraryFilename_.isEmpty()) {
            opLibraryFilename_ = other.opLibraryFilename_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureOpLibraryFilenameIsMutable();
            opLibraryFilename_.addAll(other.opLibraryFilename_);
          }
          onChanged();
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelOperations parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelOperations) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList opLibraryFilename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureOpLibraryFilenameIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          opLibraryFilename_ = new com.google.protobuf.LazyStringArrayList(opLibraryFilename_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getOpLibraryFilenameList() {
        return opLibraryFilename_.getUnmodifiableView();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public int getOpLibraryFilenameCount() {
        return opLibraryFilename_.size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public String getOpLibraryFilename(int index) {
        return opLibraryFilename_.get(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public com.google.protobuf.ByteString
          getOpLibraryFilenameBytes(int index) {
        return opLibraryFilename_.getByteString(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public Builder setOpLibraryFilename(
          int index, String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOpLibraryFilenameIsMutable();
        opLibraryFilename_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public Builder addOpLibraryFilename(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureOpLibraryFilenameIsMutable();
        opLibraryFilename_.add(value);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public Builder addAllOpLibraryFilename(
          Iterable<String> values) {
        ensureOpLibraryFilenameIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, opLibraryFilename_);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public Builder clearOpLibraryFilename() {
        opLibraryFilename_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string op_library_filename
       *&#64;&#64;
       *&#64;&#64;     Optional paths of the libraries providing custom operations for
       *&#64;&#64;     this model. Valid only for ONNX models.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated string op_library_filename = 1;</code>
       */
      public Builder addOpLibraryFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        ensureOpLibraryFilenameIsMutable();
        opLibraryFilename_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelOperations)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelOperations)
    private static final ModelConfigOuterClass.ModelOperations DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelOperations();
    }

    public static ModelConfigOuterClass.ModelOperations getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelOperations>
        PARSER = new com.google.protobuf.AbstractParser<ModelOperations>() {
      public ModelOperations parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelOperations(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelOperations> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelOperations> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelOperations getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelTransactionPolicyOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelTransactionPolicy)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool decoupled
     *&#64;&#64;
     *&#64;&#64;     Indicates whether responses generated by the model are decoupled with
     *&#64;&#64;     the requests issued to it, which means the number of responses
     *&#64;&#64;     generated by model may differ from number of requests issued, and
     *&#64;&#64;     that the responses may be out of order relative to the order of
     *&#64;&#64;     requests. The default is false, which means the model will generate
     *&#64;&#64;     exactly one response for each request.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool decoupled = 1;</code>
     */
    boolean getDecoupled();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64; .. cpp:var:: message ModelTransactionPolicy
   *&#64;&#64;
   *&#64;&#64;    The specification that describes the nature of transactions
   *&#64;&#64;    to be expected from the model.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelTransactionPolicy}
   */
  public  static final class ModelTransactionPolicy extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelTransactionPolicy)
      ModelTransactionPolicyOrBuilder {
    // Use ModelTransactionPolicy.newBuilder() to construct.
    private ModelTransactionPolicy(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelTransactionPolicy() {
      decoupled_ = false;
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelTransactionPolicy(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {

              decoupled_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelTransactionPolicy_descriptor;
    }

    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelTransactionPolicy_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelTransactionPolicy.class, ModelConfigOuterClass.ModelTransactionPolicy.Builder.class);
    }

    public static final int DECOUPLED_FIELD_NUMBER = 1;
    private boolean decoupled_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: bool decoupled
     *&#64;&#64;
     *&#64;&#64;     Indicates whether responses generated by the model are decoupled with
     *&#64;&#64;     the requests issued to it, which means the number of responses
     *&#64;&#64;     generated by model may differ from number of requests issued, and
     *&#64;&#64;     that the responses may be out of order relative to the order of
     *&#64;&#64;     requests. The default is false, which means the model will generate
     *&#64;&#64;     exactly one response for each request.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional bool decoupled = 1;</code>
     */
    public boolean getDecoupled() {
      return decoupled_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (decoupled_ != false) {
        output.writeBool(1, decoupled_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (decoupled_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(1, decoupled_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelTransactionPolicy)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelTransactionPolicy other = (ModelConfigOuterClass.ModelTransactionPolicy) obj;

      boolean result = true;
      result = result && (getDecoupled()
          == other.getDecoupled());
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + DECOUPLED_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getDecoupled());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelTransactionPolicy parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelTransactionPolicy prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64; .. cpp:var:: message ModelTransactionPolicy
     *&#64;&#64;
     *&#64;&#64;    The specification that describes the nature of transactions
     *&#64;&#64;    to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelTransactionPolicy}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelTransactionPolicy)
        ModelConfigOuterClass.ModelTransactionPolicyOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelTransactionPolicy_descriptor;
      }

      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelTransactionPolicy_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelTransactionPolicy.class, ModelConfigOuterClass.ModelTransactionPolicy.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelTransactionPolicy.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        decoupled_ = false;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelTransactionPolicy_descriptor;
      }

      public ModelConfigOuterClass.ModelTransactionPolicy getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelTransactionPolicy.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelTransactionPolicy build() {
        ModelConfigOuterClass.ModelTransactionPolicy result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelTransactionPolicy buildPartial() {
        ModelConfigOuterClass.ModelTransactionPolicy result = new ModelConfigOuterClass.ModelTransactionPolicy(this);
        result.decoupled_ = decoupled_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelTransactionPolicy) {
          return mergeFrom((ModelConfigOuterClass.ModelTransactionPolicy)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelTransactionPolicy other) {
        if (other == ModelConfigOuterClass.ModelTransactionPolicy.getDefaultInstance()) return this;
        if (other.getDecoupled() != false) {
          setDecoupled(other.getDecoupled());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelTransactionPolicy parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelTransactionPolicy) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private boolean decoupled_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool decoupled
       *&#64;&#64;
       *&#64;&#64;     Indicates whether responses generated by the model are decoupled with
       *&#64;&#64;     the requests issued to it, which means the number of responses
       *&#64;&#64;     generated by model may differ from number of requests issued, and
       *&#64;&#64;     that the responses may be out of order relative to the order of
       *&#64;&#64;     requests. The default is false, which means the model will generate
       *&#64;&#64;     exactly one response for each request.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool decoupled = 1;</code>
       */
      public boolean getDecoupled() {
        return decoupled_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool decoupled
       *&#64;&#64;
       *&#64;&#64;     Indicates whether responses generated by the model are decoupled with
       *&#64;&#64;     the requests issued to it, which means the number of responses
       *&#64;&#64;     generated by model may differ from number of requests issued, and
       *&#64;&#64;     that the responses may be out of order relative to the order of
       *&#64;&#64;     requests. The default is false, which means the model will generate
       *&#64;&#64;     exactly one response for each request.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool decoupled = 1;</code>
       */
      public Builder setDecoupled(boolean value) {

        decoupled_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: bool decoupled
       *&#64;&#64;
       *&#64;&#64;     Indicates whether responses generated by the model are decoupled with
       *&#64;&#64;     the requests issued to it, which means the number of responses
       *&#64;&#64;     generated by model may differ from number of requests issued, and
       *&#64;&#64;     that the responses may be out of order relative to the order of
       *&#64;&#64;     requests. The default is false, which means the model will generate
       *&#64;&#64;     exactly one response for each request.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional bool decoupled = 1;</code>
       */
      public Builder clearDecoupled() {

        decoupled_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelTransactionPolicy)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelTransactionPolicy)
    private static final ModelConfigOuterClass.ModelTransactionPolicy DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelTransactionPolicy();
    }

    public static ModelConfigOuterClass.ModelTransactionPolicy getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelTransactionPolicy>
        PARSER = new com.google.protobuf.AbstractParser<ModelTransactionPolicy>() {
      public ModelTransactionPolicy parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelTransactionPolicy(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelTransactionPolicy> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelTransactionPolicy> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelTransactionPolicy getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ModelConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:inference.ModelConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    String getName();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     The framework for the model. Possible values are
     *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
     *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
     *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string platform = 2;</code>
     */
    String getPlatform();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     The framework for the model. Possible values are
     *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
     *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
     *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string platform = 2;</code>
     */
    com.google.protobuf.ByteString
        getPlatformBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string backend = 17;</code>
     */
    String getBackend();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string backend = 17;</code>
     */
    com.google.protobuf.ByteString
        getBackendBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    boolean hasVersionPolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicy getVersionPolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    ModelConfigOuterClass.ModelVersionPolicyOrBuilder getVersionPolicyOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 max_batch_size
     *&#64;&#64;
     *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *&#64;&#64;     indicates that batching is not allowed for the model and the
     *&#64;&#64;     dimension/shape of the input and output tensors must exactly
     *&#64;&#64;     match what is specified in the input and output configuration. A
     *&#64;&#64;     max_batch_size value &gt; 0 indicates that batching is allowed and
     *&#64;&#64;     so the model expects the input tensors to have an additional
     *&#64;&#64;     initial dimension for the batching that is not specified in the
     *&#64;&#64;     input (for example, if the model supports batched inputs of
     *&#64;&#64;     2-dimensional tensors then the model configuration will specify
     *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size &gt; 0
     *&#64;&#64;     returned outputs will also have an additional initial dimension
     *&#64;&#64;     for the batch.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional int32 max_batch_size = 4;</code>
     */
    int getMaxBatchSize();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    java.util.List<ModelInput>
        getInputList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    ModelConfigOuterClass.ModelInput getInput(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    int getInputCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    java.util.List<? extends ModelInputOrBuilder>
        getInputOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    ModelConfigOuterClass.ModelInputOrBuilder getInputOrBuilder(
        int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    java.util.List<ModelOutput>
        getOutputList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    ModelConfigOuterClass.ModelOutput getOutput(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    int getOutputCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    java.util.List<? extends ModelOutputOrBuilder>
        getOutputOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    ModelConfigOuterClass.ModelOutputOrBuilder getOutputOrBuilder(
        int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    boolean hasOptimization();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicy getOptimization();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder getOptimizationOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
     */
    ModelConfigOuterClass.ModelDynamicBatching getDynamicBatching();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
     */
    ModelConfigOuterClass.ModelDynamicBatchingOrBuilder getDynamicBatchingOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatching getSequenceBatching();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
     */
    ModelConfigOuterClass.ModelSequenceBatchingOrBuilder getSequenceBatchingOrBuilder();

    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
     */
    ModelConfigOuterClass.ModelEnsembling getEnsembleScheduling();
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
     */
    ModelConfigOuterClass.ModelEnsemblingOrBuilder getEnsembleSchedulingOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    java.util.List<ModelInstanceGroup>
        getInstanceGroupList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    ModelConfigOuterClass.ModelInstanceGroup getInstanceGroup(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    int getInstanceGroupCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    java.util.List<? extends ModelInstanceGroupOrBuilder>
        getInstanceGroupOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    ModelConfigOuterClass.ModelInstanceGroupOrBuilder getInstanceGroupOrBuilder(
        int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.netdef' depending on the model type.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string default_model_filename = 8;</code>
     */
    String getDefaultModelFilename();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.netdef' depending on the model type.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string default_model_filename = 8;</code>
     */
    com.google.protobuf.ByteString
        getDefaultModelFilenameBytes();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */
    int getCcModelFilenamesCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */
    boolean containsCcModelFilenames(
        String key);
    /**
     * Use {@link #getCcModelFilenamesMap()} instead.
     */
    @Deprecated
    java.util.Map<String, String>
    getCcModelFilenames();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */
    java.util.Map<String, String>
    getCcModelFilenamesMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    String getCcModelFilenamesOrDefault(
        String key,
        String defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    String getCcModelFilenamesOrThrow(
        String key);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */
    int getMetricTagsCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */
    boolean containsMetricTags(
        String key);
    /**
     * Use {@link #getMetricTagsMap()} instead.
     */
    @Deprecated
    java.util.Map<String, String>
    getMetricTags();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */
    java.util.Map<String, String>
    getMetricTagsMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    String getMetricTagsOrDefault(
        String key,
        String defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    String getMetricTagsOrThrow(
        String key);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */
    int getParametersCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */
    boolean containsParameters(
        String key);
    /**
     * Use {@link #getParametersMap()} instead.
     */
    @Deprecated
    java.util.Map<String, ModelParameter>
    getParameters();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */
    java.util.Map<String, ModelParameter>
    getParametersMap();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    ModelConfigOuterClass.ModelParameter getParametersOrDefault(
        String key,
        ModelConfigOuterClass.ModelParameter defaultValue);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    ModelConfigOuterClass.ModelParameter getParametersOrThrow(
        String key);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    java.util.List<ModelWarmup>
        getModelWarmupList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    ModelConfigOuterClass.ModelWarmup getModelWarmup(int index);
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    int getModelWarmupCount();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    java.util.List<? extends ModelWarmupOrBuilder>
        getModelWarmupOrBuilderList();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    ModelConfigOuterClass.ModelWarmupOrBuilder getModelWarmupOrBuilder(
        int index);

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    boolean hasModelOperations();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    ModelConfigOuterClass.ModelOperations getModelOperations();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    ModelConfigOuterClass.ModelOperationsOrBuilder getModelOperationsOrBuilder();

    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    boolean hasModelTransactionPolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    ModelConfigOuterClass.ModelTransactionPolicy getModelTransactionPolicy();
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    ModelConfigOuterClass.ModelTransactionPolicyOrBuilder getModelTransactionPolicyOrBuilder();

    public ModelConfigOuterClass.ModelConfig.SchedulingChoiceCase getSchedulingChoiceCase();
  }
  /**
   * <pre>
   *&#64;&#64;
   *&#64;&#64;.. cpp:var:: message ModelConfig
   *&#64;&#64;
   *&#64;&#64;   A model configuration.
   *&#64;&#64;
   * </pre>
   *
   * Protobuf type {@code inference.ModelConfig}
   */
  public  static final class ModelConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:inference.ModelConfig)
      ModelConfigOrBuilder {
    // Use ModelConfig.newBuilder() to construct.
    private ModelConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ModelConfig() {
      name_ = "";
      platform_ = "";
      backend_ = "";
      maxBatchSize_ = 0;
      input_ = java.util.Collections.emptyList();
      output_ = java.util.Collections.emptyList();
      instanceGroup_ = java.util.Collections.emptyList();
      defaultModelFilename_ = "";
      modelWarmup_ = java.util.Collections.emptyList();
    }

    @Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private ModelConfig(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              String s = input.readStringRequireUtf8();

              name_ = s;
              break;
            }
            case 18: {
              String s = input.readStringRequireUtf8();

              platform_ = s;
              break;
            }
            case 26: {
              ModelConfigOuterClass.ModelVersionPolicy.Builder subBuilder = null;
              if (versionPolicy_ != null) {
                subBuilder = versionPolicy_.toBuilder();
              }
              versionPolicy_ = input.readMessage(ModelConfigOuterClass.ModelVersionPolicy.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(versionPolicy_);
                versionPolicy_ = subBuilder.buildPartial();
              }

              break;
            }
            case 32: {

              maxBatchSize_ = input.readInt32();
              break;
            }
            case 42: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                input_ = new java.util.ArrayList<ModelInput>();
                mutable_bitField0_ |= 0x00000020;
              }
              input_.add(
                  input.readMessage(ModelConfigOuterClass.ModelInput.parser(), extensionRegistry));
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                output_ = new java.util.ArrayList<ModelOutput>();
                mutable_bitField0_ |= 0x00000040;
              }
              output_.add(
                  input.readMessage(ModelConfigOuterClass.ModelOutput.parser(), extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
                instanceGroup_ = new java.util.ArrayList<ModelInstanceGroup>();
                mutable_bitField0_ |= 0x00000800;
              }
              instanceGroup_.add(
                  input.readMessage(ModelConfigOuterClass.ModelInstanceGroup.parser(), extensionRegistry));
              break;
            }
            case 66: {
              String s = input.readStringRequireUtf8();

              defaultModelFilename_ = s;
              break;
            }
            case 74: {
              if (!((mutable_bitField0_ & 0x00002000) == 0x00002000)) {
                ccModelFilenames_ = com.google.protobuf.MapField.newMapField(
                    CcModelFilenamesDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00002000;
              }
              com.google.protobuf.MapEntry<String, String>
              ccModelFilenames = input.readMessage(
                  CcModelFilenamesDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              ccModelFilenames_.getMutableMap().put(ccModelFilenames.getKey(), ccModelFilenames.getValue());
              break;
            }
            case 82: {
              if (!((mutable_bitField0_ & 0x00004000) == 0x00004000)) {
                metricTags_ = com.google.protobuf.MapField.newMapField(
                    MetricTagsDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00004000;
              }
              com.google.protobuf.MapEntry<String, String>
              metricTags = input.readMessage(
                  MetricTagsDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              metricTags_.getMutableMap().put(metricTags.getKey(), metricTags.getValue());
              break;
            }
            case 90: {
              ModelConfigOuterClass.ModelDynamicBatching.Builder subBuilder = null;
              if (schedulingChoiceCase_ == 11) {
                subBuilder = ((ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_).toBuilder();
              }
              schedulingChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelDynamicBatching.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_);
                schedulingChoice_ = subBuilder.buildPartial();
              }
              schedulingChoiceCase_ = 11;
              break;
            }
            case 98: {
              ModelConfigOuterClass.ModelOptimizationPolicy.Builder subBuilder = null;
              if (optimization_ != null) {
                subBuilder = optimization_.toBuilder();
              }
              optimization_ = input.readMessage(ModelConfigOuterClass.ModelOptimizationPolicy.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(optimization_);
                optimization_ = subBuilder.buildPartial();
              }

              break;
            }
            case 106: {
              ModelConfigOuterClass.ModelSequenceBatching.Builder subBuilder = null;
              if (schedulingChoiceCase_ == 13) {
                subBuilder = ((ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_).toBuilder();
              }
              schedulingChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelSequenceBatching.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_);
                schedulingChoice_ = subBuilder.buildPartial();
              }
              schedulingChoiceCase_ = 13;
              break;
            }
            case 114: {
              if (!((mutable_bitField0_ & 0x00008000) == 0x00008000)) {
                parameters_ = com.google.protobuf.MapField.newMapField(
                    ParametersDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00008000;
              }
              com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelParameter>
              parameters = input.readMessage(
                  ParametersDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              parameters_.getMutableMap().put(parameters.getKey(), parameters.getValue());
              break;
            }
            case 122: {
              ModelConfigOuterClass.ModelEnsembling.Builder subBuilder = null;
              if (schedulingChoiceCase_ == 15) {
                subBuilder = ((ModelConfigOuterClass.ModelEnsembling) schedulingChoice_).toBuilder();
              }
              schedulingChoice_ =
                  input.readMessage(ModelConfigOuterClass.ModelEnsembling.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((ModelConfigOuterClass.ModelEnsembling) schedulingChoice_);
                schedulingChoice_ = subBuilder.buildPartial();
              }
              schedulingChoiceCase_ = 15;
              break;
            }
            case 130: {
              if (!((mutable_bitField0_ & 0x00010000) == 0x00010000)) {
                modelWarmup_ = new java.util.ArrayList<ModelWarmup>();
                mutable_bitField0_ |= 0x00010000;
              }
              modelWarmup_.add(
                  input.readMessage(ModelConfigOuterClass.ModelWarmup.parser(), extensionRegistry));
              break;
            }
            case 138: {
              String s = input.readStringRequireUtf8();

              backend_ = s;
              break;
            }
            case 146: {
              ModelConfigOuterClass.ModelOperations.Builder subBuilder = null;
              if (modelOperations_ != null) {
                subBuilder = modelOperations_.toBuilder();
              }
              modelOperations_ = input.readMessage(ModelConfigOuterClass.ModelOperations.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modelOperations_);
                modelOperations_ = subBuilder.buildPartial();
              }

              break;
            }
            case 154: {
              ModelConfigOuterClass.ModelTransactionPolicy.Builder subBuilder = null;
              if (modelTransactionPolicy_ != null) {
                subBuilder = modelTransactionPolicy_.toBuilder();
              }
              modelTransactionPolicy_ = input.readMessage(ModelConfigOuterClass.ModelTransactionPolicy.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(modelTransactionPolicy_);
                modelTransactionPolicy_ = subBuilder.buildPartial();
              }

              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          input_ = java.util.Collections.unmodifiableList(input_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          output_ = java.util.Collections.unmodifiableList(output_);
        }
        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
          instanceGroup_ = java.util.Collections.unmodifiableList(instanceGroup_);
        }
        if (((mutable_bitField0_ & 0x00010000) == 0x00010000)) {
          modelWarmup_ = java.util.Collections.unmodifiableList(modelWarmup_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return ModelConfigOuterClass.internal_static_inference_ModelConfig_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 9:
          return internalGetCcModelFilenames();
        case 10:
          return internalGetMetricTags();
        case 14:
          return internalGetParameters();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    protected FieldAccessorTable
        internalGetFieldAccessorTable() {
      return ModelConfigOuterClass.internal_static_inference_ModelConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              ModelConfigOuterClass.ModelConfig.class, ModelConfigOuterClass.ModelConfig.Builder.class);
    }

    private int bitField0_;
    private int schedulingChoiceCase_ = 0;
    private Object schedulingChoice_;
    public enum SchedulingChoiceCase
        implements com.google.protobuf.Internal.EnumLite {
      DYNAMIC_BATCHING(11),
      SEQUENCE_BATCHING(13),
      ENSEMBLE_SCHEDULING(15),
      SCHEDULINGCHOICE_NOT_SET(0);
      private final int value;
      private SchedulingChoiceCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @Deprecated
      public static SchedulingChoiceCase valueOf(int value) {
        return forNumber(value);
      }

      public static SchedulingChoiceCase forNumber(int value) {
        switch (value) {
          case 11: return DYNAMIC_BATCHING;
          case 13: return SEQUENCE_BATCHING;
          case 15: return ENSEMBLE_SCHEDULING;
          case 0: return SCHEDULINGCHOICE_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public SchedulingChoiceCase
    getSchedulingChoiceCase() {
      return SchedulingChoiceCase.forNumber(
          schedulingChoiceCase_);
    }

    public static final int NAME_FIELD_NUMBER = 1;
    private volatile Object name_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public String getName() {
      Object ref = name_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        name_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string name
     *&#64;&#64;
     *&#64;&#64;     The name of the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string name = 1;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      Object ref = name_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PLATFORM_FIELD_NUMBER = 2;
    private volatile Object platform_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     The framework for the model. Possible values are
     *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
     *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
     *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string platform = 2;</code>
     */
    public String getPlatform() {
      Object ref = platform_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        platform_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string platform
     *&#64;&#64;
     *&#64;&#64;     The framework for the model. Possible values are
     *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
     *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
     *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string platform = 2;</code>
     */
    public com.google.protobuf.ByteString
        getPlatformBytes() {
      Object ref = platform_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        platform_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int BACKEND_FIELD_NUMBER = 17;
    private volatile Object backend_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string backend = 17;</code>
     */
    public String getBackend() {
      Object ref = backend_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        backend_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string backend
     *&#64;&#64;
     *&#64;&#64;     The backend used by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string backend = 17;</code>
     */
    public com.google.protobuf.ByteString
        getBackendBytes() {
      Object ref = backend_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        backend_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VERSION_POLICY_FIELD_NUMBER = 3;
    private ModelConfigOuterClass.ModelVersionPolicy versionPolicy_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    public boolean hasVersionPolicy() {
      return versionPolicy_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicy getVersionPolicy() {
      return versionPolicy_ == null ? ModelConfigOuterClass.ModelVersionPolicy.getDefaultInstance() : versionPolicy_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
     *&#64;&#64;
     *&#64;&#64;     Policy indicating which version(s) of the model will be served.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
     */
    public ModelConfigOuterClass.ModelVersionPolicyOrBuilder getVersionPolicyOrBuilder() {
      return getVersionPolicy();
    }

    public static final int MAX_BATCH_SIZE_FIELD_NUMBER = 4;
    private int maxBatchSize_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: int32 max_batch_size
     *&#64;&#64;
     *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
     *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
     *&#64;&#64;     indicates that batching is not allowed for the model and the
     *&#64;&#64;     dimension/shape of the input and output tensors must exactly
     *&#64;&#64;     match what is specified in the input and output configuration. A
     *&#64;&#64;     max_batch_size value &gt; 0 indicates that batching is allowed and
     *&#64;&#64;     so the model expects the input tensors to have an additional
     *&#64;&#64;     initial dimension for the batching that is not specified in the
     *&#64;&#64;     input (for example, if the model supports batched inputs of
     *&#64;&#64;     2-dimensional tensors then the model configuration will specify
     *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
     *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size &gt; 0
     *&#64;&#64;     returned outputs will also have an additional initial dimension
     *&#64;&#64;     for the batch.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional int32 max_batch_size = 4;</code>
     */
    public int getMaxBatchSize() {
      return maxBatchSize_;
    }

    public static final int INPUT_FIELD_NUMBER = 5;
    private java.util.List<ModelInput> input_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    public java.util.List<ModelInput> getInputList() {
      return input_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    public java.util.List<? extends ModelInputOrBuilder>
        getInputOrBuilderList() {
      return input_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    public int getInputCount() {
      return input_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    public ModelConfigOuterClass.ModelInput getInput(int index) {
      return input_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
     *&#64;&#64;
     *&#64;&#64;     The inputs request by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInput input = 5;</code>
     */
    public ModelConfigOuterClass.ModelInputOrBuilder getInputOrBuilder(
        int index) {
      return input_.get(index);
    }

    public static final int OUTPUT_FIELD_NUMBER = 6;
    private java.util.List<ModelOutput> output_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    public java.util.List<ModelOutput> getOutputList() {
      return output_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    public java.util.List<? extends ModelOutputOrBuilder>
        getOutputOrBuilderList() {
      return output_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    public int getOutputCount() {
      return output_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    public ModelConfigOuterClass.ModelOutput getOutput(int index) {
      return output_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
     *&#64;&#64;
     *&#64;&#64;     The outputs produced by the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelOutput output = 6;</code>
     */
    public ModelConfigOuterClass.ModelOutputOrBuilder getOutputOrBuilder(
        int index) {
      return output_.get(index);
    }

    public static final int OPTIMIZATION_FIELD_NUMBER = 12;
    private ModelConfigOuterClass.ModelOptimizationPolicy optimization_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    public boolean hasOptimization() {
      return optimization_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicy getOptimization() {
      return optimization_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.getDefaultInstance() : optimization_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
     *&#64;&#64;
     *&#64;&#64;     Optimization configuration for the model. If not specified
     *&#64;&#64;     then default optimization policy is used.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
     */
    public ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder getOptimizationOrBuilder() {
      return getOptimization();
    }

    public static final int DYNAMIC_BATCHING_FIELD_NUMBER = 11;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
     */
    public ModelConfigOuterClass.ModelDynamicBatching getDynamicBatching() {
      if (schedulingChoiceCase_ == 11) {
         return (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the dynamic-batching scheduling
     *&#64;&#64;       policy. With dynamic-batching the scheduler may group
     *&#64;&#64;       together independent requests into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
     */
    public ModelConfigOuterClass.ModelDynamicBatchingOrBuilder getDynamicBatchingOrBuilder() {
      if (schedulingChoiceCase_ == 11) {
         return (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
    }

    public static final int SEQUENCE_BATCHING_FIELD_NUMBER = 13;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatching getSequenceBatching() {
      if (schedulingChoiceCase_ == 13) {
         return (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the sequence-batching scheduling
     *&#64;&#64;       policy. With sequence-batching, inference requests
     *&#64;&#64;       with the same correlation ID are routed to the same
     *&#64;&#64;       model instance. Multiple sequences of inference requests
     *&#64;&#64;       may be batched together into a single batch to
     *&#64;&#64;       improve inference throughput.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
     */
    public ModelConfigOuterClass.ModelSequenceBatchingOrBuilder getSequenceBatchingOrBuilder() {
      if (schedulingChoiceCase_ == 13) {
         return (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
    }

    public static final int ENSEMBLE_SCHEDULING_FIELD_NUMBER = 15;
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
     */
    public ModelConfigOuterClass.ModelEnsembling getEnsembleScheduling() {
      if (schedulingChoiceCase_ == 15) {
         return (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
    }
    /**
     * <pre>
     *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
     *&#64;&#64;
     *&#64;&#64;       If specified, enables the model-ensembling scheduling
     *&#64;&#64;       policy. With model-ensembling, inference requests
     *&#64;&#64;       will be processed according to the specification, such as an
     *&#64;&#64;       execution sequence of models. The input specified in this model
     *&#64;&#64;       config will be the input for the ensemble, and the output
     *&#64;&#64;       specified will be the output of the ensemble.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
     */
    public ModelConfigOuterClass.ModelEnsemblingOrBuilder getEnsembleSchedulingOrBuilder() {
      if (schedulingChoiceCase_ == 15) {
         return (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_;
      }
      return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
    }

    public static final int INSTANCE_GROUP_FIELD_NUMBER = 7;
    private java.util.List<ModelInstanceGroup> instanceGroup_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    public java.util.List<ModelInstanceGroup> getInstanceGroupList() {
      return instanceGroup_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    public java.util.List<? extends ModelInstanceGroupOrBuilder>
        getInstanceGroupOrBuilderList() {
      return instanceGroup_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    public int getInstanceGroupCount() {
      return instanceGroup_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    public ModelConfigOuterClass.ModelInstanceGroup getInstanceGroup(int index) {
      return instanceGroup_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
     *&#64;&#64;
     *&#64;&#64;     Instances of this model. If not specified, one instance
     *&#64;&#64;     of the model will be instantiated on each available GPU.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
     */
    public ModelConfigOuterClass.ModelInstanceGroupOrBuilder getInstanceGroupOrBuilder(
        int index) {
      return instanceGroup_.get(index);
    }

    public static final int DEFAULT_MODEL_FILENAME_FIELD_NUMBER = 8;
    private volatile Object defaultModelFilename_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.netdef' depending on the model type.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string default_model_filename = 8;</code>
     */
    public String getDefaultModelFilename() {
      Object ref = defaultModelFilename_;
      if (ref instanceof String) {
        return (String) ref;
      } else {
        com.google.protobuf.ByteString bs =
            (com.google.protobuf.ByteString) ref;
        String s = bs.toStringUtf8();
        defaultModelFilename_ = s;
        return s;
      }
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: string default_model_filename
     *&#64;&#64;
     *&#64;&#64;     Optional filename of the model file to use if a
     *&#64;&#64;     compute-capability specific model is not specified in
     *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
     *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
     *&#64;&#64;     'model.netdef' depending on the model type.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional string default_model_filename = 8;</code>
     */
    public com.google.protobuf.ByteString
        getDefaultModelFilenameBytes() {
      Object ref = defaultModelFilename_;
      if (ref instanceof String) {
        com.google.protobuf.ByteString b =
            com.google.protobuf.ByteString.copyFromUtf8(
                (String) ref);
        defaultModelFilename_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CC_MODEL_FILENAMES_FIELD_NUMBER = 9;
    private static final class CcModelFilenamesDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          String, String> defaultEntry =
              com.google.protobuf.MapEntry
              .<String, String>newDefaultInstance(
                  ModelConfigOuterClass.internal_static_inference_ModelConfig_CcModelFilenamesEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        String, String> ccModelFilenames_;
    private com.google.protobuf.MapField<String, String>
    internalGetCcModelFilenames() {
      if (ccModelFilenames_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            CcModelFilenamesDefaultEntryHolder.defaultEntry);
      }
      return ccModelFilenames_;
    }

    public int getCcModelFilenamesCount() {
      return internalGetCcModelFilenames().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    public boolean containsCcModelFilenames(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      return internalGetCcModelFilenames().getMap().containsKey(key);
    }
    /**
     * Use {@link #getCcModelFilenamesMap()} instead.
     */
    @Deprecated
    public java.util.Map<String, String> getCcModelFilenames() {
      return getCcModelFilenamesMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    public java.util.Map<String, String> getCcModelFilenamesMap() {
      return internalGetCcModelFilenames().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    public String getCcModelFilenamesOrDefault(
        String key,
        String defaultValue) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, String> map =
          internalGetCcModelFilenames().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
     *&#64;&#64;
     *&#64;&#64;     Optional map from CUDA compute capability to the filename of
     *&#64;&#64;     the model that supports that compute capability. The filename
     *&#64;&#64;     refers to a file within the model version directory.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
     */

    public String getCcModelFilenamesOrThrow(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, String> map =
          internalGetCcModelFilenames().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int METRIC_TAGS_FIELD_NUMBER = 10;
    private static final class MetricTagsDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          String, String> defaultEntry =
              com.google.protobuf.MapEntry
              .<String, String>newDefaultInstance(
                  ModelConfigOuterClass.internal_static_inference_ModelConfig_MetricTagsEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        String, String> metricTags_;
    private com.google.protobuf.MapField<String, String>
    internalGetMetricTags() {
      if (metricTags_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            MetricTagsDefaultEntryHolder.defaultEntry);
      }
      return metricTags_;
    }

    public int getMetricTagsCount() {
      return internalGetMetricTags().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    public boolean containsMetricTags(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      return internalGetMetricTags().getMap().containsKey(key);
    }
    /**
     * Use {@link #getMetricTagsMap()} instead.
     */
    @Deprecated
    public java.util.Map<String, String> getMetricTags() {
      return getMetricTagsMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    public java.util.Map<String, String> getMetricTagsMap() {
      return internalGetMetricTags().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    public String getMetricTagsOrDefault(
        String key,
        String defaultValue) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, String> map =
          internalGetMetricTags().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
     *&#64;&#64;
     *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
     *&#64;&#64;     reported for this model. These tags are applied to the metrics
     *&#64;&#64;     reported on the HTTP metrics port.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, string&gt; metric_tags = 10;</code>
     */

    public String getMetricTagsOrThrow(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, String> map =
          internalGetMetricTags().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int PARAMETERS_FIELD_NUMBER = 14;
    private static final class ParametersDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          String, ModelConfigOuterClass.ModelParameter> defaultEntry =
              com.google.protobuf.MapEntry
              .<String, ModelConfigOuterClass.ModelParameter>newDefaultInstance(
                  ModelConfigOuterClass.internal_static_inference_ModelConfig_ParametersEntry_descriptor,
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.MESSAGE,
                  ModelConfigOuterClass.ModelParameter.getDefaultInstance());
    }
    private com.google.protobuf.MapField<
        String, ModelConfigOuterClass.ModelParameter> parameters_;
    private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelParameter>
    internalGetParameters() {
      if (parameters_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            ParametersDefaultEntryHolder.defaultEntry);
      }
      return parameters_;
    }

    public int getParametersCount() {
      return internalGetParameters().getMap().size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    public boolean containsParameters(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      return internalGetParameters().getMap().containsKey(key);
    }
    /**
     * Use {@link #getParametersMap()} instead.
     */
    @Deprecated
    public java.util.Map<String, ModelParameter> getParameters() {
      return getParametersMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    public java.util.Map<String, ModelParameter> getParametersMap() {
      return internalGetParameters().getMap();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    public ModelConfigOuterClass.ModelParameter getParametersOrDefault(
        String key,
        ModelConfigOuterClass.ModelParameter defaultValue) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, ModelParameter> map =
          internalGetParameters().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
     *&#64;&#64;
     *&#64;&#64;     Optional model parameters. User-specified parameter values that
     *&#64;&#64;     are made available to custom backends.
     *&#64;&#64;
     * </pre>
     *
     * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
     */

    public ModelConfigOuterClass.ModelParameter getParametersOrThrow(
        String key) {
      if (key == null) { throw new NullPointerException(); }
      java.util.Map<String, ModelParameter> map =
          internalGetParameters().getMap();
      if (!map.containsKey(key)) {
        throw new IllegalArgumentException();
      }
      return map.get(key);
    }

    public static final int MODEL_WARMUP_FIELD_NUMBER = 16;
    private java.util.List<ModelWarmup> modelWarmup_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    public java.util.List<ModelWarmup> getModelWarmupList() {
      return modelWarmup_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    public java.util.List<? extends ModelWarmupOrBuilder>
        getModelWarmupOrBuilderList() {
      return modelWarmup_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    public int getModelWarmupCount() {
      return modelWarmup_.size();
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    public ModelConfigOuterClass.ModelWarmup getModelWarmup(int index) {
      return modelWarmup_.get(index);
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
     *&#64;&#64;
     *&#64;&#64;     Warmup setting of this model. If specified, all instances
     *&#64;&#64;     will be run with the request samples in sequence before
     *&#64;&#64;     serving the model.
     *&#64;&#64;     This field can only be specified if the model is not an ensemble
     *&#64;&#64;     model.
     *&#64;&#64;
     * </pre>
     *
     * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
     */
    public ModelConfigOuterClass.ModelWarmupOrBuilder getModelWarmupOrBuilder(
        int index) {
      return modelWarmup_.get(index);
    }

    public static final int MODEL_OPERATIONS_FIELD_NUMBER = 18;
    private ModelConfigOuterClass.ModelOperations modelOperations_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    public boolean hasModelOperations() {
      return modelOperations_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    public ModelConfigOuterClass.ModelOperations getModelOperations() {
      return modelOperations_ == null ? ModelConfigOuterClass.ModelOperations.getDefaultInstance() : modelOperations_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
     *&#64;&#64;
     *&#64;&#64;     Optional metadata of the libraries providing custom operations for
     *&#64;&#64;     this model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelOperations model_operations = 18;</code>
     */
    public ModelConfigOuterClass.ModelOperationsOrBuilder getModelOperationsOrBuilder() {
      return getModelOperations();
    }

    public static final int MODEL_TRANSACTION_POLICY_FIELD_NUMBER = 19;
    private ModelConfigOuterClass.ModelTransactionPolicy modelTransactionPolicy_;
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    public boolean hasModelTransactionPolicy() {
      return modelTransactionPolicy_ != null;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    public ModelConfigOuterClass.ModelTransactionPolicy getModelTransactionPolicy() {
      return modelTransactionPolicy_ == null ? ModelConfigOuterClass.ModelTransactionPolicy.getDefaultInstance() : modelTransactionPolicy_;
    }
    /**
     * <pre>
     *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
     *&#64;&#64;
     *&#64;&#64;     Optional specification that describes the nature of transactions
     *&#64;&#64;     to be expected from the model.
     *&#64;&#64;
     * </pre>
     *
     * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
     */
    public ModelConfigOuterClass.ModelTransactionPolicyOrBuilder getModelTransactionPolicyOrBuilder() {
      return getModelTransactionPolicy();
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getNameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, name_);
      }
      if (!getPlatformBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, platform_);
      }
      if (versionPolicy_ != null) {
        output.writeMessage(3, getVersionPolicy());
      }
      if (maxBatchSize_ != 0) {
        output.writeInt32(4, maxBatchSize_);
      }
      for (int i = 0; i < input_.size(); i++) {
        output.writeMessage(5, input_.get(i));
      }
      for (int i = 0; i < output_.size(); i++) {
        output.writeMessage(6, output_.get(i));
      }
      for (int i = 0; i < instanceGroup_.size(); i++) {
        output.writeMessage(7, instanceGroup_.get(i));
      }
      if (!getDefaultModelFilenameBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, defaultModelFilename_);
      }
      for (java.util.Map.Entry<String, String> entry
           : internalGetCcModelFilenames().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, String>
        ccModelFilenames = CcModelFilenamesDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        output.writeMessage(9, ccModelFilenames);
      }
      for (java.util.Map.Entry<String, String> entry
           : internalGetMetricTags().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, String>
        metricTags = MetricTagsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        output.writeMessage(10, metricTags);
      }
      if (schedulingChoiceCase_ == 11) {
        output.writeMessage(11, (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_);
      }
      if (optimization_ != null) {
        output.writeMessage(12, getOptimization());
      }
      if (schedulingChoiceCase_ == 13) {
        output.writeMessage(13, (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_);
      }
      for (java.util.Map.Entry<String, ModelParameter> entry
           : internalGetParameters().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelParameter>
        parameters = ParametersDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        output.writeMessage(14, parameters);
      }
      if (schedulingChoiceCase_ == 15) {
        output.writeMessage(15, (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_);
      }
      for (int i = 0; i < modelWarmup_.size(); i++) {
        output.writeMessage(16, modelWarmup_.get(i));
      }
      if (!getBackendBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 17, backend_);
      }
      if (modelOperations_ != null) {
        output.writeMessage(18, getModelOperations());
      }
      if (modelTransactionPolicy_ != null) {
        output.writeMessage(19, getModelTransactionPolicy());
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getNameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, name_);
      }
      if (!getPlatformBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, platform_);
      }
      if (versionPolicy_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getVersionPolicy());
      }
      if (maxBatchSize_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, maxBatchSize_);
      }
      for (int i = 0; i < input_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, input_.get(i));
      }
      for (int i = 0; i < output_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, output_.get(i));
      }
      for (int i = 0; i < instanceGroup_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, instanceGroup_.get(i));
      }
      if (!getDefaultModelFilenameBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, defaultModelFilename_);
      }
      for (java.util.Map.Entry<String, String> entry
           : internalGetCcModelFilenames().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, String>
        ccModelFilenames = CcModelFilenamesDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(9, ccModelFilenames);
      }
      for (java.util.Map.Entry<String, String> entry
           : internalGetMetricTags().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, String>
        metricTags = MetricTagsDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(10, metricTags);
      }
      if (schedulingChoiceCase_ == 11) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(11, (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_);
      }
      if (optimization_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(12, getOptimization());
      }
      if (schedulingChoiceCase_ == 13) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(13, (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_);
      }
      for (java.util.Map.Entry<String, ModelParameter> entry
           : internalGetParameters().getMap().entrySet()) {
        com.google.protobuf.MapEntry<String, ModelConfigOuterClass.ModelParameter>
        parameters = ParametersDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(14, parameters);
      }
      if (schedulingChoiceCase_ == 15) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_);
      }
      for (int i = 0; i < modelWarmup_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, modelWarmup_.get(i));
      }
      if (!getBackendBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(17, backend_);
      }
      if (modelOperations_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(18, getModelOperations());
      }
      if (modelTransactionPolicy_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, getModelTransactionPolicy());
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @Override
    public boolean equals(final Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof ModelConfigOuterClass.ModelConfig)) {
        return super.equals(obj);
      }
      ModelConfigOuterClass.ModelConfig other = (ModelConfigOuterClass.ModelConfig) obj;

      boolean result = true;
      result = result && getName()
          .equals(other.getName());
      result = result && getPlatform()
          .equals(other.getPlatform());
      result = result && getBackend()
          .equals(other.getBackend());
      result = result && (hasVersionPolicy() == other.hasVersionPolicy());
      if (hasVersionPolicy()) {
        result = result && getVersionPolicy()
            .equals(other.getVersionPolicy());
      }
      result = result && (getMaxBatchSize()
          == other.getMaxBatchSize());
      result = result && getInputList()
          .equals(other.getInputList());
      result = result && getOutputList()
          .equals(other.getOutputList());
      result = result && (hasOptimization() == other.hasOptimization());
      if (hasOptimization()) {
        result = result && getOptimization()
            .equals(other.getOptimization());
      }
      result = result && getInstanceGroupList()
          .equals(other.getInstanceGroupList());
      result = result && getDefaultModelFilename()
          .equals(other.getDefaultModelFilename());
      result = result && internalGetCcModelFilenames().equals(
          other.internalGetCcModelFilenames());
      result = result && internalGetMetricTags().equals(
          other.internalGetMetricTags());
      result = result && internalGetParameters().equals(
          other.internalGetParameters());
      result = result && getModelWarmupList()
          .equals(other.getModelWarmupList());
      result = result && (hasModelOperations() == other.hasModelOperations());
      if (hasModelOperations()) {
        result = result && getModelOperations()
            .equals(other.getModelOperations());
      }
      result = result && (hasModelTransactionPolicy() == other.hasModelTransactionPolicy());
      if (hasModelTransactionPolicy()) {
        result = result && getModelTransactionPolicy()
            .equals(other.getModelTransactionPolicy());
      }
      result = result && getSchedulingChoiceCase().equals(
          other.getSchedulingChoiceCase());
      if (!result) return false;
      switch (schedulingChoiceCase_) {
        case 11:
          result = result && getDynamicBatching()
              .equals(other.getDynamicBatching());
          break;
        case 13:
          result = result && getSequenceBatching()
              .equals(other.getSequenceBatching());
          break;
        case 15:
          result = result && getEnsembleScheduling()
              .equals(other.getEnsembleScheduling());
          break;
        case 0:
        default:
      }
      return result;
    }

    @Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + NAME_FIELD_NUMBER;
      hash = (53 * hash) + getName().hashCode();
      hash = (37 * hash) + PLATFORM_FIELD_NUMBER;
      hash = (53 * hash) + getPlatform().hashCode();
      hash = (37 * hash) + BACKEND_FIELD_NUMBER;
      hash = (53 * hash) + getBackend().hashCode();
      if (hasVersionPolicy()) {
        hash = (37 * hash) + VERSION_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + getVersionPolicy().hashCode();
      }
      hash = (37 * hash) + MAX_BATCH_SIZE_FIELD_NUMBER;
      hash = (53 * hash) + getMaxBatchSize();
      if (getInputCount() > 0) {
        hash = (37 * hash) + INPUT_FIELD_NUMBER;
        hash = (53 * hash) + getInputList().hashCode();
      }
      if (getOutputCount() > 0) {
        hash = (37 * hash) + OUTPUT_FIELD_NUMBER;
        hash = (53 * hash) + getOutputList().hashCode();
      }
      if (hasOptimization()) {
        hash = (37 * hash) + OPTIMIZATION_FIELD_NUMBER;
        hash = (53 * hash) + getOptimization().hashCode();
      }
      if (getInstanceGroupCount() > 0) {
        hash = (37 * hash) + INSTANCE_GROUP_FIELD_NUMBER;
        hash = (53 * hash) + getInstanceGroupList().hashCode();
      }
      hash = (37 * hash) + DEFAULT_MODEL_FILENAME_FIELD_NUMBER;
      hash = (53 * hash) + getDefaultModelFilename().hashCode();
      if (!internalGetCcModelFilenames().getMap().isEmpty()) {
        hash = (37 * hash) + CC_MODEL_FILENAMES_FIELD_NUMBER;
        hash = (53 * hash) + internalGetCcModelFilenames().hashCode();
      }
      if (!internalGetMetricTags().getMap().isEmpty()) {
        hash = (37 * hash) + METRIC_TAGS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetMetricTags().hashCode();
      }
      if (!internalGetParameters().getMap().isEmpty()) {
        hash = (37 * hash) + PARAMETERS_FIELD_NUMBER;
        hash = (53 * hash) + internalGetParameters().hashCode();
      }
      if (getModelWarmupCount() > 0) {
        hash = (37 * hash) + MODEL_WARMUP_FIELD_NUMBER;
        hash = (53 * hash) + getModelWarmupList().hashCode();
      }
      if (hasModelOperations()) {
        hash = (37 * hash) + MODEL_OPERATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getModelOperations().hashCode();
      }
      if (hasModelTransactionPolicy()) {
        hash = (37 * hash) + MODEL_TRANSACTION_POLICY_FIELD_NUMBER;
        hash = (53 * hash) + getModelTransactionPolicy().hashCode();
      }
      switch (schedulingChoiceCase_) {
        case 11:
          hash = (37 * hash) + DYNAMIC_BATCHING_FIELD_NUMBER;
          hash = (53 * hash) + getDynamicBatching().hashCode();
          break;
        case 13:
          hash = (37 * hash) + SEQUENCE_BATCHING_FIELD_NUMBER;
          hash = (53 * hash) + getSequenceBatching().hashCode();
          break;
        case 15:
          hash = (37 * hash) + ENSEMBLE_SCHEDULING_FIELD_NUMBER;
          hash = (53 * hash) + getEnsembleScheduling().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static ModelConfigOuterClass.ModelConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static ModelConfigOuterClass.ModelConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(ModelConfigOuterClass.ModelConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @Override
    protected Builder newBuilderForType(
        BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#64;&#64;
     *&#64;&#64;.. cpp:var:: message ModelConfig
     *&#64;&#64;
     *&#64;&#64;   A model configuration.
     *&#64;&#64;
     * </pre>
     *
     * Protobuf type {@code inference.ModelConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:inference.ModelConfig)
        ModelConfigOuterClass.ModelConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return ModelConfigOuterClass.internal_static_inference_ModelConfig_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 9:
            return internalGetCcModelFilenames();
          case 10:
            return internalGetMetricTags();
          case 14:
            return internalGetParameters();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 9:
            return internalGetMutableCcModelFilenames();
          case 10:
            return internalGetMutableMetricTags();
          case 14:
            return internalGetMutableParameters();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected FieldAccessorTable
          internalGetFieldAccessorTable() {
        return ModelConfigOuterClass.internal_static_inference_ModelConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                ModelConfigOuterClass.ModelConfig.class, ModelConfigOuterClass.ModelConfig.Builder.class);
      }

      // Construct using ModelConfigOuterClass.ModelConfig.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getInputFieldBuilder();
          getOutputFieldBuilder();
          getInstanceGroupFieldBuilder();
          getModelWarmupFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        name_ = "";

        platform_ = "";

        backend_ = "";

        if (versionPolicyBuilder_ == null) {
          versionPolicy_ = null;
        } else {
          versionPolicy_ = null;
          versionPolicyBuilder_ = null;
        }
        maxBatchSize_ = 0;

        if (inputBuilder_ == null) {
          input_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          inputBuilder_.clear();
        }
        if (outputBuilder_ == null) {
          output_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          outputBuilder_.clear();
        }
        if (optimizationBuilder_ == null) {
          optimization_ = null;
        } else {
          optimization_ = null;
          optimizationBuilder_ = null;
        }
        if (instanceGroupBuilder_ == null) {
          instanceGroup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
        } else {
          instanceGroupBuilder_.clear();
        }
        defaultModelFilename_ = "";

        internalGetMutableCcModelFilenames().clear();
        internalGetMutableMetricTags().clear();
        internalGetMutableParameters().clear();
        if (modelWarmupBuilder_ == null) {
          modelWarmup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00010000);
        } else {
          modelWarmupBuilder_.clear();
        }
        if (modelOperationsBuilder_ == null) {
          modelOperations_ = null;
        } else {
          modelOperations_ = null;
          modelOperationsBuilder_ = null;
        }
        if (modelTransactionPolicyBuilder_ == null) {
          modelTransactionPolicy_ = null;
        } else {
          modelTransactionPolicy_ = null;
          modelTransactionPolicyBuilder_ = null;
        }
        schedulingChoiceCase_ = 0;
        schedulingChoice_ = null;
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return ModelConfigOuterClass.internal_static_inference_ModelConfig_descriptor;
      }

      public ModelConfigOuterClass.ModelConfig getDefaultInstanceForType() {
        return ModelConfigOuterClass.ModelConfig.getDefaultInstance();
      }

      public ModelConfigOuterClass.ModelConfig build() {
        ModelConfigOuterClass.ModelConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public ModelConfigOuterClass.ModelConfig buildPartial() {
        ModelConfigOuterClass.ModelConfig result = new ModelConfigOuterClass.ModelConfig(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.name_ = name_;
        result.platform_ = platform_;
        result.backend_ = backend_;
        if (versionPolicyBuilder_ == null) {
          result.versionPolicy_ = versionPolicy_;
        } else {
          result.versionPolicy_ = versionPolicyBuilder_.build();
        }
        result.maxBatchSize_ = maxBatchSize_;
        if (inputBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            input_ = java.util.Collections.unmodifiableList(input_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.input_ = input_;
        } else {
          result.input_ = inputBuilder_.build();
        }
        if (outputBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            output_ = java.util.Collections.unmodifiableList(output_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.output_ = output_;
        } else {
          result.output_ = outputBuilder_.build();
        }
        if (optimizationBuilder_ == null) {
          result.optimization_ = optimization_;
        } else {
          result.optimization_ = optimizationBuilder_.build();
        }
        if (schedulingChoiceCase_ == 11) {
          if (dynamicBatchingBuilder_ == null) {
            result.schedulingChoice_ = schedulingChoice_;
          } else {
            result.schedulingChoice_ = dynamicBatchingBuilder_.build();
          }
        }
        if (schedulingChoiceCase_ == 13) {
          if (sequenceBatchingBuilder_ == null) {
            result.schedulingChoice_ = schedulingChoice_;
          } else {
            result.schedulingChoice_ = sequenceBatchingBuilder_.build();
          }
        }
        if (schedulingChoiceCase_ == 15) {
          if (ensembleSchedulingBuilder_ == null) {
            result.schedulingChoice_ = schedulingChoice_;
          } else {
            result.schedulingChoice_ = ensembleSchedulingBuilder_.build();
          }
        }
        if (instanceGroupBuilder_ == null) {
          if (((bitField0_ & 0x00000800) == 0x00000800)) {
            instanceGroup_ = java.util.Collections.unmodifiableList(instanceGroup_);
            bitField0_ = (bitField0_ & ~0x00000800);
          }
          result.instanceGroup_ = instanceGroup_;
        } else {
          result.instanceGroup_ = instanceGroupBuilder_.build();
        }
        result.defaultModelFilename_ = defaultModelFilename_;
        result.ccModelFilenames_ = internalGetCcModelFilenames();
        result.ccModelFilenames_.makeImmutable();
        result.metricTags_ = internalGetMetricTags();
        result.metricTags_.makeImmutable();
        result.parameters_ = internalGetParameters();
        result.parameters_.makeImmutable();
        if (modelWarmupBuilder_ == null) {
          if (((bitField0_ & 0x00010000) == 0x00010000)) {
            modelWarmup_ = java.util.Collections.unmodifiableList(modelWarmup_);
            bitField0_ = (bitField0_ & ~0x00010000);
          }
          result.modelWarmup_ = modelWarmup_;
        } else {
          result.modelWarmup_ = modelWarmupBuilder_.build();
        }
        if (modelOperationsBuilder_ == null) {
          result.modelOperations_ = modelOperations_;
        } else {
          result.modelOperations_ = modelOperationsBuilder_.build();
        }
        if (modelTransactionPolicyBuilder_ == null) {
          result.modelTransactionPolicy_ = modelTransactionPolicy_;
        } else {
          result.modelTransactionPolicy_ = modelTransactionPolicyBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        result.schedulingChoiceCase_ = schedulingChoiceCase_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof ModelConfigOuterClass.ModelConfig) {
          return mergeFrom((ModelConfigOuterClass.ModelConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(ModelConfigOuterClass.ModelConfig other) {
        if (other == ModelConfigOuterClass.ModelConfig.getDefaultInstance()) return this;
        if (!other.getName().isEmpty()) {
          name_ = other.name_;
          onChanged();
        }
        if (!other.getPlatform().isEmpty()) {
          platform_ = other.platform_;
          onChanged();
        }
        if (!other.getBackend().isEmpty()) {
          backend_ = other.backend_;
          onChanged();
        }
        if (other.hasVersionPolicy()) {
          mergeVersionPolicy(other.getVersionPolicy());
        }
        if (other.getMaxBatchSize() != 0) {
          setMaxBatchSize(other.getMaxBatchSize());
        }
        if (inputBuilder_ == null) {
          if (!other.input_.isEmpty()) {
            if (input_.isEmpty()) {
              input_ = other.input_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureInputIsMutable();
              input_.addAll(other.input_);
            }
            onChanged();
          }
        } else {
          if (!other.input_.isEmpty()) {
            if (inputBuilder_.isEmpty()) {
              inputBuilder_.dispose();
              inputBuilder_ = null;
              input_ = other.input_;
              bitField0_ = (bitField0_ & ~0x00000020);
              inputBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getInputFieldBuilder() : null;
            } else {
              inputBuilder_.addAllMessages(other.input_);
            }
          }
        }
        if (outputBuilder_ == null) {
          if (!other.output_.isEmpty()) {
            if (output_.isEmpty()) {
              output_ = other.output_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureOutputIsMutable();
              output_.addAll(other.output_);
            }
            onChanged();
          }
        } else {
          if (!other.output_.isEmpty()) {
            if (outputBuilder_.isEmpty()) {
              outputBuilder_.dispose();
              outputBuilder_ = null;
              output_ = other.output_;
              bitField0_ = (bitField0_ & ~0x00000040);
              outputBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getOutputFieldBuilder() : null;
            } else {
              outputBuilder_.addAllMessages(other.output_);
            }
          }
        }
        if (other.hasOptimization()) {
          mergeOptimization(other.getOptimization());
        }
        if (instanceGroupBuilder_ == null) {
          if (!other.instanceGroup_.isEmpty()) {
            if (instanceGroup_.isEmpty()) {
              instanceGroup_ = other.instanceGroup_;
              bitField0_ = (bitField0_ & ~0x00000800);
            } else {
              ensureInstanceGroupIsMutable();
              instanceGroup_.addAll(other.instanceGroup_);
            }
            onChanged();
          }
        } else {
          if (!other.instanceGroup_.isEmpty()) {
            if (instanceGroupBuilder_.isEmpty()) {
              instanceGroupBuilder_.dispose();
              instanceGroupBuilder_ = null;
              instanceGroup_ = other.instanceGroup_;
              bitField0_ = (bitField0_ & ~0x00000800);
              instanceGroupBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getInstanceGroupFieldBuilder() : null;
            } else {
              instanceGroupBuilder_.addAllMessages(other.instanceGroup_);
            }
          }
        }
        if (!other.getDefaultModelFilename().isEmpty()) {
          defaultModelFilename_ = other.defaultModelFilename_;
          onChanged();
        }
        internalGetMutableCcModelFilenames().mergeFrom(
            other.internalGetCcModelFilenames());
        internalGetMutableMetricTags().mergeFrom(
            other.internalGetMetricTags());
        internalGetMutableParameters().mergeFrom(
            other.internalGetParameters());
        if (modelWarmupBuilder_ == null) {
          if (!other.modelWarmup_.isEmpty()) {
            if (modelWarmup_.isEmpty()) {
              modelWarmup_ = other.modelWarmup_;
              bitField0_ = (bitField0_ & ~0x00010000);
            } else {
              ensureModelWarmupIsMutable();
              modelWarmup_.addAll(other.modelWarmup_);
            }
            onChanged();
          }
        } else {
          if (!other.modelWarmup_.isEmpty()) {
            if (modelWarmupBuilder_.isEmpty()) {
              modelWarmupBuilder_.dispose();
              modelWarmupBuilder_ = null;
              modelWarmup_ = other.modelWarmup_;
              bitField0_ = (bitField0_ & ~0x00010000);
              modelWarmupBuilder_ =
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getModelWarmupFieldBuilder() : null;
            } else {
              modelWarmupBuilder_.addAllMessages(other.modelWarmup_);
            }
          }
        }
        if (other.hasModelOperations()) {
          mergeModelOperations(other.getModelOperations());
        }
        if (other.hasModelTransactionPolicy()) {
          mergeModelTransactionPolicy(other.getModelTransactionPolicy());
        }
        switch (other.getSchedulingChoiceCase()) {
          case DYNAMIC_BATCHING: {
            mergeDynamicBatching(other.getDynamicBatching());
            break;
          }
          case SEQUENCE_BATCHING: {
            mergeSequenceBatching(other.getSequenceBatching());
            break;
          }
          case ENSEMBLE_SCHEDULING: {
            mergeEnsembleScheduling(other.getEnsembleScheduling());
            break;
          }
          case SCHEDULINGCHOICE_NOT_SET: {
            break;
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        ModelConfigOuterClass.ModelConfig parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (ModelConfigOuterClass.ModelConfig) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int schedulingChoiceCase_ = 0;
      private Object schedulingChoice_;
      public SchedulingChoiceCase
          getSchedulingChoiceCase() {
        return SchedulingChoiceCase.forNumber(
            schedulingChoiceCase_);
      }

      public Builder clearSchedulingChoice() {
        schedulingChoiceCase_ = 0;
        schedulingChoice_ = null;
        onChanged();
        return this;
      }

      private int bitField0_;

      private Object name_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public String getName() {
        Object ref = name_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          name_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setName(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder clearName() {

        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string name
       *&#64;&#64;
       *&#64;&#64;     The name of the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string name = 1;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        name_ = value;
        onChanged();
        return this;
      }

      private Object platform_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string platform
       *&#64;&#64;
       *&#64;&#64;     The framework for the model. Possible values are
       *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
       *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
       *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string platform = 2;</code>
       */
      public String getPlatform() {
        Object ref = platform_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          platform_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string platform
       *&#64;&#64;
       *&#64;&#64;     The framework for the model. Possible values are
       *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
       *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
       *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string platform = 2;</code>
       */
      public com.google.protobuf.ByteString
          getPlatformBytes() {
        Object ref = platform_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          platform_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string platform
       *&#64;&#64;
       *&#64;&#64;     The framework for the model. Possible values are
       *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
       *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
       *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string platform = 2;</code>
       */
      public Builder setPlatform(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        platform_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string platform
       *&#64;&#64;
       *&#64;&#64;     The framework for the model. Possible values are
       *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
       *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
       *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string platform = 2;</code>
       */
      public Builder clearPlatform() {

        platform_ = getDefaultInstance().getPlatform();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string platform
       *&#64;&#64;
       *&#64;&#64;     The framework for the model. Possible values are
       *&#64;&#64;     "tensorrt_plan", "tensorflow_graphdef",
       *&#64;&#64;     "tensorflow_savedmodel", "caffe2_netdef",
       *&#64;&#64;     "onnxruntime_onnx", "pytorch_libtorch" and "custom".
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string platform = 2;</code>
       */
      public Builder setPlatformBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        platform_ = value;
        onChanged();
        return this;
      }

      private Object backend_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string backend
       *&#64;&#64;
       *&#64;&#64;     The backend used by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string backend = 17;</code>
       */
      public String getBackend() {
        Object ref = backend_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          backend_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string backend
       *&#64;&#64;
       *&#64;&#64;     The backend used by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string backend = 17;</code>
       */
      public com.google.protobuf.ByteString
          getBackendBytes() {
        Object ref = backend_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          backend_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string backend
       *&#64;&#64;
       *&#64;&#64;     The backend used by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string backend = 17;</code>
       */
      public Builder setBackend(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        backend_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string backend
       *&#64;&#64;
       *&#64;&#64;     The backend used by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string backend = 17;</code>
       */
      public Builder clearBackend() {

        backend_ = getDefaultInstance().getBackend();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string backend
       *&#64;&#64;
       *&#64;&#64;     The backend used by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string backend = 17;</code>
       */
      public Builder setBackendBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        backend_ = value;
        onChanged();
        return this;
      }

      private ModelConfigOuterClass.ModelVersionPolicy versionPolicy_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy, ModelConfigOuterClass.ModelVersionPolicy.Builder, ModelConfigOuterClass.ModelVersionPolicyOrBuilder> versionPolicyBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public boolean hasVersionPolicy() {
        return versionPolicyBuilder_ != null || versionPolicy_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy getVersionPolicy() {
        if (versionPolicyBuilder_ == null) {
          return versionPolicy_ == null ? ModelConfigOuterClass.ModelVersionPolicy.getDefaultInstance() : versionPolicy_;
        } else {
          return versionPolicyBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public Builder setVersionPolicy(ModelConfigOuterClass.ModelVersionPolicy value) {
        if (versionPolicyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          versionPolicy_ = value;
          onChanged();
        } else {
          versionPolicyBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public Builder setVersionPolicy(
          ModelConfigOuterClass.ModelVersionPolicy.Builder builderForValue) {
        if (versionPolicyBuilder_ == null) {
          versionPolicy_ = builderForValue.build();
          onChanged();
        } else {
          versionPolicyBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public Builder mergeVersionPolicy(ModelConfigOuterClass.ModelVersionPolicy value) {
        if (versionPolicyBuilder_ == null) {
          if (versionPolicy_ != null) {
            versionPolicy_ =
              ModelConfigOuterClass.ModelVersionPolicy.newBuilder(versionPolicy_).mergeFrom(value).buildPartial();
          } else {
            versionPolicy_ = value;
          }
          onChanged();
        } else {
          versionPolicyBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public Builder clearVersionPolicy() {
        if (versionPolicyBuilder_ == null) {
          versionPolicy_ = null;
          onChanged();
        } else {
          versionPolicy_ = null;
          versionPolicyBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicy.Builder getVersionPolicyBuilder() {

        onChanged();
        return getVersionPolicyFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      public ModelConfigOuterClass.ModelVersionPolicyOrBuilder getVersionPolicyOrBuilder() {
        if (versionPolicyBuilder_ != null) {
          return versionPolicyBuilder_.getMessageOrBuilder();
        } else {
          return versionPolicy_ == null ?
              ModelConfigOuterClass.ModelVersionPolicy.getDefaultInstance() : versionPolicy_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelVersionPolicy version_policy
       *&#64;&#64;
       *&#64;&#64;     Policy indicating which version(s) of the model will be served.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelVersionPolicy version_policy = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelVersionPolicy, ModelConfigOuterClass.ModelVersionPolicy.Builder, ModelConfigOuterClass.ModelVersionPolicyOrBuilder>
          getVersionPolicyFieldBuilder() {
        if (versionPolicyBuilder_ == null) {
          versionPolicyBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelVersionPolicy, ModelConfigOuterClass.ModelVersionPolicy.Builder, ModelConfigOuterClass.ModelVersionPolicyOrBuilder>(
                  getVersionPolicy(),
                  getParentForChildren(),
                  isClean());
          versionPolicy_ = null;
        }
        return versionPolicyBuilder_;
      }

      private int maxBatchSize_ ;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 max_batch_size
       *&#64;&#64;
       *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
       *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
       *&#64;&#64;     indicates that batching is not allowed for the model and the
       *&#64;&#64;     dimension/shape of the input and output tensors must exactly
       *&#64;&#64;     match what is specified in the input and output configuration. A
       *&#64;&#64;     max_batch_size value &gt; 0 indicates that batching is allowed and
       *&#64;&#64;     so the model expects the input tensors to have an additional
       *&#64;&#64;     initial dimension for the batching that is not specified in the
       *&#64;&#64;     input (for example, if the model supports batched inputs of
       *&#64;&#64;     2-dimensional tensors then the model configuration will specify
       *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
       *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size &gt; 0
       *&#64;&#64;     returned outputs will also have an additional initial dimension
       *&#64;&#64;     for the batch.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 max_batch_size = 4;</code>
       */
      public int getMaxBatchSize() {
        return maxBatchSize_;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 max_batch_size
       *&#64;&#64;
       *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
       *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
       *&#64;&#64;     indicates that batching is not allowed for the model and the
       *&#64;&#64;     dimension/shape of the input and output tensors must exactly
       *&#64;&#64;     match what is specified in the input and output configuration. A
       *&#64;&#64;     max_batch_size value &gt; 0 indicates that batching is allowed and
       *&#64;&#64;     so the model expects the input tensors to have an additional
       *&#64;&#64;     initial dimension for the batching that is not specified in the
       *&#64;&#64;     input (for example, if the model supports batched inputs of
       *&#64;&#64;     2-dimensional tensors then the model configuration will specify
       *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
       *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size &gt; 0
       *&#64;&#64;     returned outputs will also have an additional initial dimension
       *&#64;&#64;     for the batch.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 max_batch_size = 4;</code>
       */
      public Builder setMaxBatchSize(int value) {

        maxBatchSize_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: int32 max_batch_size
       *&#64;&#64;
       *&#64;&#64;     Maximum batch size allowed for inference. This can only decrease
       *&#64;&#64;     what is allowed by the model itself. A max_batch_size value of 0
       *&#64;&#64;     indicates that batching is not allowed for the model and the
       *&#64;&#64;     dimension/shape of the input and output tensors must exactly
       *&#64;&#64;     match what is specified in the input and output configuration. A
       *&#64;&#64;     max_batch_size value &gt; 0 indicates that batching is allowed and
       *&#64;&#64;     so the model expects the input tensors to have an additional
       *&#64;&#64;     initial dimension for the batching that is not specified in the
       *&#64;&#64;     input (for example, if the model supports batched inputs of
       *&#64;&#64;     2-dimensional tensors then the model configuration will specify
       *&#64;&#64;     the input shape as [ X, Y ] but the model will expect the actual
       *&#64;&#64;     input tensors to have shape [ N, X, Y ]). For max_batch_size &gt; 0
       *&#64;&#64;     returned outputs will also have an additional initial dimension
       *&#64;&#64;     for the batch.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional int32 max_batch_size = 4;</code>
       */
      public Builder clearMaxBatchSize() {

        maxBatchSize_ = 0;
        onChanged();
        return this;
      }

      private java.util.List<ModelInput> input_ =
        java.util.Collections.emptyList();
      private void ensureInputIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          input_ = new java.util.ArrayList<ModelInput>(input_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelInput, ModelConfigOuterClass.ModelInput.Builder, ModelConfigOuterClass.ModelInputOrBuilder> inputBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public java.util.List<ModelInput> getInputList() {
        if (inputBuilder_ == null) {
          return java.util.Collections.unmodifiableList(input_);
        } else {
          return inputBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public int getInputCount() {
        if (inputBuilder_ == null) {
          return input_.size();
        } else {
          return inputBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public ModelConfigOuterClass.ModelInput getInput(int index) {
        if (inputBuilder_ == null) {
          return input_.get(index);
        } else {
          return inputBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder setInput(
          int index, ModelConfigOuterClass.ModelInput value) {
        if (inputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInputIsMutable();
          input_.set(index, value);
          onChanged();
        } else {
          inputBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder setInput(
          int index, ModelConfigOuterClass.ModelInput.Builder builderForValue) {
        if (inputBuilder_ == null) {
          ensureInputIsMutable();
          input_.set(index, builderForValue.build());
          onChanged();
        } else {
          inputBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder addInput(ModelConfigOuterClass.ModelInput value) {
        if (inputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInputIsMutable();
          input_.add(value);
          onChanged();
        } else {
          inputBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder addInput(
          int index, ModelConfigOuterClass.ModelInput value) {
        if (inputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInputIsMutable();
          input_.add(index, value);
          onChanged();
        } else {
          inputBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder addInput(
          ModelConfigOuterClass.ModelInput.Builder builderForValue) {
        if (inputBuilder_ == null) {
          ensureInputIsMutable();
          input_.add(builderForValue.build());
          onChanged();
        } else {
          inputBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder addInput(
          int index, ModelConfigOuterClass.ModelInput.Builder builderForValue) {
        if (inputBuilder_ == null) {
          ensureInputIsMutable();
          input_.add(index, builderForValue.build());
          onChanged();
        } else {
          inputBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder addAllInput(
          Iterable<? extends ModelInput> values) {
        if (inputBuilder_ == null) {
          ensureInputIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, input_);
          onChanged();
        } else {
          inputBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder clearInput() {
        if (inputBuilder_ == null) {
          input_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          inputBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public Builder removeInput(int index) {
        if (inputBuilder_ == null) {
          ensureInputIsMutable();
          input_.remove(index);
          onChanged();
        } else {
          inputBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public ModelConfigOuterClass.ModelInput.Builder getInputBuilder(
          int index) {
        return getInputFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public ModelConfigOuterClass.ModelInputOrBuilder getInputOrBuilder(
          int index) {
        if (inputBuilder_ == null) {
          return input_.get(index);  } else {
          return inputBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public java.util.List<? extends ModelInputOrBuilder>
           getInputOrBuilderList() {
        if (inputBuilder_ != null) {
          return inputBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(input_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public ModelConfigOuterClass.ModelInput.Builder addInputBuilder() {
        return getInputFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelInput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public ModelConfigOuterClass.ModelInput.Builder addInputBuilder(
          int index) {
        return getInputFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelInput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInput input (repeated)
       *&#64;&#64;
       *&#64;&#64;     The inputs request by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInput input = 5;</code>
       */
      public java.util.List<ModelInput.Builder>
           getInputBuilderList() {
        return getInputFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelInput, ModelConfigOuterClass.ModelInput.Builder, ModelConfigOuterClass.ModelInputOrBuilder>
          getInputFieldBuilder() {
        if (inputBuilder_ == null) {
          inputBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelInput, ModelConfigOuterClass.ModelInput.Builder, ModelConfigOuterClass.ModelInputOrBuilder>(
                  input_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          input_ = null;
        }
        return inputBuilder_;
      }

      private java.util.List<ModelOutput> output_ =
        java.util.Collections.emptyList();
      private void ensureOutputIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          output_ = new java.util.ArrayList<ModelOutput>(output_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelOutput, ModelConfigOuterClass.ModelOutput.Builder, ModelConfigOuterClass.ModelOutputOrBuilder> outputBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public java.util.List<ModelOutput> getOutputList() {
        if (outputBuilder_ == null) {
          return java.util.Collections.unmodifiableList(output_);
        } else {
          return outputBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public int getOutputCount() {
        if (outputBuilder_ == null) {
          return output_.size();
        } else {
          return outputBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public ModelConfigOuterClass.ModelOutput getOutput(int index) {
        if (outputBuilder_ == null) {
          return output_.get(index);
        } else {
          return outputBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder setOutput(
          int index, ModelConfigOuterClass.ModelOutput value) {
        if (outputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOutputIsMutable();
          output_.set(index, value);
          onChanged();
        } else {
          outputBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder setOutput(
          int index, ModelConfigOuterClass.ModelOutput.Builder builderForValue) {
        if (outputBuilder_ == null) {
          ensureOutputIsMutable();
          output_.set(index, builderForValue.build());
          onChanged();
        } else {
          outputBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder addOutput(ModelConfigOuterClass.ModelOutput value) {
        if (outputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOutputIsMutable();
          output_.add(value);
          onChanged();
        } else {
          outputBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder addOutput(
          int index, ModelConfigOuterClass.ModelOutput value) {
        if (outputBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureOutputIsMutable();
          output_.add(index, value);
          onChanged();
        } else {
          outputBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder addOutput(
          ModelConfigOuterClass.ModelOutput.Builder builderForValue) {
        if (outputBuilder_ == null) {
          ensureOutputIsMutable();
          output_.add(builderForValue.build());
          onChanged();
        } else {
          outputBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder addOutput(
          int index, ModelConfigOuterClass.ModelOutput.Builder builderForValue) {
        if (outputBuilder_ == null) {
          ensureOutputIsMutable();
          output_.add(index, builderForValue.build());
          onChanged();
        } else {
          outputBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder addAllOutput(
          Iterable<? extends ModelOutput> values) {
        if (outputBuilder_ == null) {
          ensureOutputIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, output_);
          onChanged();
        } else {
          outputBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder clearOutput() {
        if (outputBuilder_ == null) {
          output_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          outputBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public Builder removeOutput(int index) {
        if (outputBuilder_ == null) {
          ensureOutputIsMutable();
          output_.remove(index);
          onChanged();
        } else {
          outputBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public ModelConfigOuterClass.ModelOutput.Builder getOutputBuilder(
          int index) {
        return getOutputFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public ModelConfigOuterClass.ModelOutputOrBuilder getOutputOrBuilder(
          int index) {
        if (outputBuilder_ == null) {
          return output_.get(index);  } else {
          return outputBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public java.util.List<? extends ModelOutputOrBuilder>
           getOutputOrBuilderList() {
        if (outputBuilder_ != null) {
          return outputBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(output_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public ModelConfigOuterClass.ModelOutput.Builder addOutputBuilder() {
        return getOutputFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelOutput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public ModelConfigOuterClass.ModelOutput.Builder addOutputBuilder(
          int index) {
        return getOutputFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelOutput.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOutput output (repeated)
       *&#64;&#64;
       *&#64;&#64;     The outputs produced by the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelOutput output = 6;</code>
       */
      public java.util.List<ModelOutput.Builder>
           getOutputBuilderList() {
        return getOutputFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelOutput, ModelConfigOuterClass.ModelOutput.Builder, ModelConfigOuterClass.ModelOutputOrBuilder>
          getOutputFieldBuilder() {
        if (outputBuilder_ == null) {
          outputBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelOutput, ModelConfigOuterClass.ModelOutput.Builder, ModelConfigOuterClass.ModelOutputOrBuilder>(
                  output_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          output_ = null;
        }
        return outputBuilder_;
      }

      private ModelConfigOuterClass.ModelOptimizationPolicy optimization_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy, ModelConfigOuterClass.ModelOptimizationPolicy.Builder, ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder> optimizationBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public boolean hasOptimization() {
        return optimizationBuilder_ != null || optimization_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy getOptimization() {
        if (optimizationBuilder_ == null) {
          return optimization_ == null ? ModelConfigOuterClass.ModelOptimizationPolicy.getDefaultInstance() : optimization_;
        } else {
          return optimizationBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public Builder setOptimization(ModelConfigOuterClass.ModelOptimizationPolicy value) {
        if (optimizationBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          optimization_ = value;
          onChanged();
        } else {
          optimizationBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public Builder setOptimization(
          ModelConfigOuterClass.ModelOptimizationPolicy.Builder builderForValue) {
        if (optimizationBuilder_ == null) {
          optimization_ = builderForValue.build();
          onChanged();
        } else {
          optimizationBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public Builder mergeOptimization(ModelConfigOuterClass.ModelOptimizationPolicy value) {
        if (optimizationBuilder_ == null) {
          if (optimization_ != null) {
            optimization_ =
              ModelConfigOuterClass.ModelOptimizationPolicy.newBuilder(optimization_).mergeFrom(value).buildPartial();
          } else {
            optimization_ = value;
          }
          onChanged();
        } else {
          optimizationBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public Builder clearOptimization() {
        if (optimizationBuilder_ == null) {
          optimization_ = null;
          onChanged();
        } else {
          optimization_ = null;
          optimizationBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicy.Builder getOptimizationBuilder() {

        onChanged();
        return getOptimizationFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      public ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder getOptimizationOrBuilder() {
        if (optimizationBuilder_ != null) {
          return optimizationBuilder_.getMessageOrBuilder();
        } else {
          return optimization_ == null ?
              ModelConfigOuterClass.ModelOptimizationPolicy.getDefaultInstance() : optimization_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOptimizationPolicy optimization
       *&#64;&#64;
       *&#64;&#64;     Optimization configuration for the model. If not specified
       *&#64;&#64;     then default optimization policy is used.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOptimizationPolicy optimization = 12;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOptimizationPolicy, ModelConfigOuterClass.ModelOptimizationPolicy.Builder, ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder>
          getOptimizationFieldBuilder() {
        if (optimizationBuilder_ == null) {
          optimizationBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOptimizationPolicy, ModelConfigOuterClass.ModelOptimizationPolicy.Builder, ModelConfigOuterClass.ModelOptimizationPolicyOrBuilder>(
                  getOptimization(),
                  getParentForChildren(),
                  isClean());
          optimization_ = null;
        }
        return optimizationBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelDynamicBatching, ModelConfigOuterClass.ModelDynamicBatching.Builder, ModelConfigOuterClass.ModelDynamicBatchingOrBuilder> dynamicBatchingBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public ModelConfigOuterClass.ModelDynamicBatching getDynamicBatching() {
        if (dynamicBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 11) {
            return (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
        } else {
          if (schedulingChoiceCase_ == 11) {
            return dynamicBatchingBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public Builder setDynamicBatching(ModelConfigOuterClass.ModelDynamicBatching value) {
        if (dynamicBatchingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          schedulingChoice_ = value;
          onChanged();
        } else {
          dynamicBatchingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 11;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public Builder setDynamicBatching(
          ModelConfigOuterClass.ModelDynamicBatching.Builder builderForValue) {
        if (dynamicBatchingBuilder_ == null) {
          schedulingChoice_ = builderForValue.build();
          onChanged();
        } else {
          dynamicBatchingBuilder_.setMessage(builderForValue.build());
        }
        schedulingChoiceCase_ = 11;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public Builder mergeDynamicBatching(ModelConfigOuterClass.ModelDynamicBatching value) {
        if (dynamicBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 11 &&
              schedulingChoice_ != ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance()) {
            schedulingChoice_ = ModelConfigOuterClass.ModelDynamicBatching.newBuilder((ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            schedulingChoice_ = value;
          }
          onChanged();
        } else {
          if (schedulingChoiceCase_ == 11) {
            dynamicBatchingBuilder_.mergeFrom(value);
          }
          dynamicBatchingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 11;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public Builder clearDynamicBatching() {
        if (dynamicBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 11) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
            onChanged();
          }
        } else {
          if (schedulingChoiceCase_ == 11) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
          }
          dynamicBatchingBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public ModelConfigOuterClass.ModelDynamicBatching.Builder getDynamicBatchingBuilder() {
        return getDynamicBatchingFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      public ModelConfigOuterClass.ModelDynamicBatchingOrBuilder getDynamicBatchingOrBuilder() {
        if ((schedulingChoiceCase_ == 11) && (dynamicBatchingBuilder_ != null)) {
          return dynamicBatchingBuilder_.getMessageOrBuilder();
        } else {
          if (schedulingChoiceCase_ == 11) {
            return (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelDynamicBatching dynamic_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the dynamic-batching scheduling
       *&#64;&#64;       policy. With dynamic-batching the scheduler may group
       *&#64;&#64;       together independent requests into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelDynamicBatching dynamic_batching = 11;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelDynamicBatching, ModelConfigOuterClass.ModelDynamicBatching.Builder, ModelConfigOuterClass.ModelDynamicBatchingOrBuilder>
          getDynamicBatchingFieldBuilder() {
        if (dynamicBatchingBuilder_ == null) {
          if (!(schedulingChoiceCase_ == 11)) {
            schedulingChoice_ = ModelConfigOuterClass.ModelDynamicBatching.getDefaultInstance();
          }
          dynamicBatchingBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelDynamicBatching, ModelConfigOuterClass.ModelDynamicBatching.Builder, ModelConfigOuterClass.ModelDynamicBatchingOrBuilder>(
                  (ModelConfigOuterClass.ModelDynamicBatching) schedulingChoice_,
                  getParentForChildren(),
                  isClean());
          schedulingChoice_ = null;
        }
        schedulingChoiceCase_ = 11;
        onChanged();;
        return dynamicBatchingBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching, ModelConfigOuterClass.ModelSequenceBatching.Builder, ModelConfigOuterClass.ModelSequenceBatchingOrBuilder> sequenceBatchingBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching getSequenceBatching() {
        if (sequenceBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 13) {
            return (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
        } else {
          if (schedulingChoiceCase_ == 13) {
            return sequenceBatchingBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public Builder setSequenceBatching(ModelConfigOuterClass.ModelSequenceBatching value) {
        if (sequenceBatchingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          schedulingChoice_ = value;
          onChanged();
        } else {
          sequenceBatchingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 13;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public Builder setSequenceBatching(
          ModelConfigOuterClass.ModelSequenceBatching.Builder builderForValue) {
        if (sequenceBatchingBuilder_ == null) {
          schedulingChoice_ = builderForValue.build();
          onChanged();
        } else {
          sequenceBatchingBuilder_.setMessage(builderForValue.build());
        }
        schedulingChoiceCase_ = 13;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public Builder mergeSequenceBatching(ModelConfigOuterClass.ModelSequenceBatching value) {
        if (sequenceBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 13 &&
              schedulingChoice_ != ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance()) {
            schedulingChoice_ = ModelConfigOuterClass.ModelSequenceBatching.newBuilder((ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            schedulingChoice_ = value;
          }
          onChanged();
        } else {
          if (schedulingChoiceCase_ == 13) {
            sequenceBatchingBuilder_.mergeFrom(value);
          }
          sequenceBatchingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 13;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public Builder clearSequenceBatching() {
        if (sequenceBatchingBuilder_ == null) {
          if (schedulingChoiceCase_ == 13) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
            onChanged();
          }
        } else {
          if (schedulingChoiceCase_ == 13) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
          }
          sequenceBatchingBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatching.Builder getSequenceBatchingBuilder() {
        return getSequenceBatchingFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      public ModelConfigOuterClass.ModelSequenceBatchingOrBuilder getSequenceBatchingOrBuilder() {
        if ((schedulingChoiceCase_ == 13) && (sequenceBatchingBuilder_ != null)) {
          return sequenceBatchingBuilder_.getMessageOrBuilder();
        } else {
          if (schedulingChoiceCase_ == 13) {
            return (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelSequenceBatching sequence_batching
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the sequence-batching scheduling
       *&#64;&#64;       policy. With sequence-batching, inference requests
       *&#64;&#64;       with the same correlation ID are routed to the same
       *&#64;&#64;       model instance. Multiple sequences of inference requests
       *&#64;&#64;       may be batched together into a single batch to
       *&#64;&#64;       improve inference throughput.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelSequenceBatching sequence_batching = 13;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelSequenceBatching, ModelConfigOuterClass.ModelSequenceBatching.Builder, ModelConfigOuterClass.ModelSequenceBatchingOrBuilder>
          getSequenceBatchingFieldBuilder() {
        if (sequenceBatchingBuilder_ == null) {
          if (!(schedulingChoiceCase_ == 13)) {
            schedulingChoice_ = ModelConfigOuterClass.ModelSequenceBatching.getDefaultInstance();
          }
          sequenceBatchingBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelSequenceBatching, ModelConfigOuterClass.ModelSequenceBatching.Builder, ModelConfigOuterClass.ModelSequenceBatchingOrBuilder>(
                  (ModelConfigOuterClass.ModelSequenceBatching) schedulingChoice_,
                  getParentForChildren(),
                  isClean());
          schedulingChoice_ = null;
        }
        schedulingChoiceCase_ = 13;
        onChanged();;
        return sequenceBatchingBuilder_;
      }

      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelEnsembling, ModelConfigOuterClass.ModelEnsembling.Builder, ModelConfigOuterClass.ModelEnsemblingOrBuilder> ensembleSchedulingBuilder_;
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling getEnsembleScheduling() {
        if (ensembleSchedulingBuilder_ == null) {
          if (schedulingChoiceCase_ == 15) {
            return (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
        } else {
          if (schedulingChoiceCase_ == 15) {
            return ensembleSchedulingBuilder_.getMessage();
          }
          return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public Builder setEnsembleScheduling(ModelConfigOuterClass.ModelEnsembling value) {
        if (ensembleSchedulingBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          schedulingChoice_ = value;
          onChanged();
        } else {
          ensembleSchedulingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 15;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public Builder setEnsembleScheduling(
          ModelConfigOuterClass.ModelEnsembling.Builder builderForValue) {
        if (ensembleSchedulingBuilder_ == null) {
          schedulingChoice_ = builderForValue.build();
          onChanged();
        } else {
          ensembleSchedulingBuilder_.setMessage(builderForValue.build());
        }
        schedulingChoiceCase_ = 15;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public Builder mergeEnsembleScheduling(ModelConfigOuterClass.ModelEnsembling value) {
        if (ensembleSchedulingBuilder_ == null) {
          if (schedulingChoiceCase_ == 15 &&
              schedulingChoice_ != ModelConfigOuterClass.ModelEnsembling.getDefaultInstance()) {
            schedulingChoice_ = ModelConfigOuterClass.ModelEnsembling.newBuilder((ModelConfigOuterClass.ModelEnsembling) schedulingChoice_)
                .mergeFrom(value).buildPartial();
          } else {
            schedulingChoice_ = value;
          }
          onChanged();
        } else {
          if (schedulingChoiceCase_ == 15) {
            ensembleSchedulingBuilder_.mergeFrom(value);
          }
          ensembleSchedulingBuilder_.setMessage(value);
        }
        schedulingChoiceCase_ = 15;
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public Builder clearEnsembleScheduling() {
        if (ensembleSchedulingBuilder_ == null) {
          if (schedulingChoiceCase_ == 15) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
            onChanged();
          }
        } else {
          if (schedulingChoiceCase_ == 15) {
            schedulingChoiceCase_ = 0;
            schedulingChoice_ = null;
          }
          ensembleSchedulingBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public ModelConfigOuterClass.ModelEnsembling.Builder getEnsembleSchedulingBuilder() {
        return getEnsembleSchedulingFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      public ModelConfigOuterClass.ModelEnsemblingOrBuilder getEnsembleSchedulingOrBuilder() {
        if ((schedulingChoiceCase_ == 15) && (ensembleSchedulingBuilder_ != null)) {
          return ensembleSchedulingBuilder_.getMessageOrBuilder();
        } else {
          if (schedulingChoiceCase_ == 15) {
            return (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_;
          }
          return ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
        }
      }
      /**
       * <pre>
       *&#64;&#64;    .. cpp:var:: ModelEnsembling ensemble_scheduling
       *&#64;&#64;
       *&#64;&#64;       If specified, enables the model-ensembling scheduling
       *&#64;&#64;       policy. With model-ensembling, inference requests
       *&#64;&#64;       will be processed according to the specification, such as an
       *&#64;&#64;       execution sequence of models. The input specified in this model
       *&#64;&#64;       config will be the input for the ensemble, and the output
       *&#64;&#64;       specified will be the output of the ensemble.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelEnsembling ensemble_scheduling = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelEnsembling, ModelConfigOuterClass.ModelEnsembling.Builder, ModelConfigOuterClass.ModelEnsemblingOrBuilder>
          getEnsembleSchedulingFieldBuilder() {
        if (ensembleSchedulingBuilder_ == null) {
          if (!(schedulingChoiceCase_ == 15)) {
            schedulingChoice_ = ModelConfigOuterClass.ModelEnsembling.getDefaultInstance();
          }
          ensembleSchedulingBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelEnsembling, ModelConfigOuterClass.ModelEnsembling.Builder, ModelConfigOuterClass.ModelEnsemblingOrBuilder>(
                  (ModelConfigOuterClass.ModelEnsembling) schedulingChoice_,
                  getParentForChildren(),
                  isClean());
          schedulingChoice_ = null;
        }
        schedulingChoiceCase_ = 15;
        onChanged();;
        return ensembleSchedulingBuilder_;
      }

      private java.util.List<ModelInstanceGroup> instanceGroup_ =
        java.util.Collections.emptyList();
      private void ensureInstanceGroupIsMutable() {
        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
          instanceGroup_ = new java.util.ArrayList<ModelInstanceGroup>(instanceGroup_);
          bitField0_ |= 0x00000800;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelInstanceGroup, ModelConfigOuterClass.ModelInstanceGroup.Builder, ModelConfigOuterClass.ModelInstanceGroupOrBuilder> instanceGroupBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public java.util.List<ModelInstanceGroup> getInstanceGroupList() {
        if (instanceGroupBuilder_ == null) {
          return java.util.Collections.unmodifiableList(instanceGroup_);
        } else {
          return instanceGroupBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public int getInstanceGroupCount() {
        if (instanceGroupBuilder_ == null) {
          return instanceGroup_.size();
        } else {
          return instanceGroupBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroup getInstanceGroup(int index) {
        if (instanceGroupBuilder_ == null) {
          return instanceGroup_.get(index);
        } else {
          return instanceGroupBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder setInstanceGroup(
          int index, ModelConfigOuterClass.ModelInstanceGroup value) {
        if (instanceGroupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstanceGroupIsMutable();
          instanceGroup_.set(index, value);
          onChanged();
        } else {
          instanceGroupBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder setInstanceGroup(
          int index, ModelConfigOuterClass.ModelInstanceGroup.Builder builderForValue) {
        if (instanceGroupBuilder_ == null) {
          ensureInstanceGroupIsMutable();
          instanceGroup_.set(index, builderForValue.build());
          onChanged();
        } else {
          instanceGroupBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder addInstanceGroup(ModelConfigOuterClass.ModelInstanceGroup value) {
        if (instanceGroupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstanceGroupIsMutable();
          instanceGroup_.add(value);
          onChanged();
        } else {
          instanceGroupBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder addInstanceGroup(
          int index, ModelConfigOuterClass.ModelInstanceGroup value) {
        if (instanceGroupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureInstanceGroupIsMutable();
          instanceGroup_.add(index, value);
          onChanged();
        } else {
          instanceGroupBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder addInstanceGroup(
          ModelConfigOuterClass.ModelInstanceGroup.Builder builderForValue) {
        if (instanceGroupBuilder_ == null) {
          ensureInstanceGroupIsMutable();
          instanceGroup_.add(builderForValue.build());
          onChanged();
        } else {
          instanceGroupBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder addInstanceGroup(
          int index, ModelConfigOuterClass.ModelInstanceGroup.Builder builderForValue) {
        if (instanceGroupBuilder_ == null) {
          ensureInstanceGroupIsMutable();
          instanceGroup_.add(index, builderForValue.build());
          onChanged();
        } else {
          instanceGroupBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder addAllInstanceGroup(
          Iterable<? extends ModelInstanceGroup> values) {
        if (instanceGroupBuilder_ == null) {
          ensureInstanceGroupIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, instanceGroup_);
          onChanged();
        } else {
          instanceGroupBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder clearInstanceGroup() {
        if (instanceGroupBuilder_ == null) {
          instanceGroup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000800);
          onChanged();
        } else {
          instanceGroupBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public Builder removeInstanceGroup(int index) {
        if (instanceGroupBuilder_ == null) {
          ensureInstanceGroupIsMutable();
          instanceGroup_.remove(index);
          onChanged();
        } else {
          instanceGroupBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroup.Builder getInstanceGroupBuilder(
          int index) {
        return getInstanceGroupFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroupOrBuilder getInstanceGroupOrBuilder(
          int index) {
        if (instanceGroupBuilder_ == null) {
          return instanceGroup_.get(index);  } else {
          return instanceGroupBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public java.util.List<? extends ModelInstanceGroupOrBuilder>
           getInstanceGroupOrBuilderList() {
        if (instanceGroupBuilder_ != null) {
          return instanceGroupBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(instanceGroup_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroup.Builder addInstanceGroupBuilder() {
        return getInstanceGroupFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelInstanceGroup.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public ModelConfigOuterClass.ModelInstanceGroup.Builder addInstanceGroupBuilder(
          int index) {
        return getInstanceGroupFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelInstanceGroup.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelInstanceGroup instance_group (repeated)
       *&#64;&#64;
       *&#64;&#64;     Instances of this model. If not specified, one instance
       *&#64;&#64;     of the model will be instantiated on each available GPU.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelInstanceGroup instance_group = 7;</code>
       */
      public java.util.List<ModelInstanceGroup.Builder>
           getInstanceGroupBuilderList() {
        return getInstanceGroupFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelInstanceGroup, ModelConfigOuterClass.ModelInstanceGroup.Builder, ModelConfigOuterClass.ModelInstanceGroupOrBuilder>
          getInstanceGroupFieldBuilder() {
        if (instanceGroupBuilder_ == null) {
          instanceGroupBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelInstanceGroup, ModelConfigOuterClass.ModelInstanceGroup.Builder, ModelConfigOuterClass.ModelInstanceGroupOrBuilder>(
                  instanceGroup_,
                  ((bitField0_ & 0x00000800) == 0x00000800),
                  getParentForChildren(),
                  isClean());
          instanceGroup_ = null;
        }
        return instanceGroupBuilder_;
      }

      private Object defaultModelFilename_ = "";
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string default_model_filename
       *&#64;&#64;
       *&#64;&#64;     Optional filename of the model file to use if a
       *&#64;&#64;     compute-capability specific model is not specified in
       *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
       *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
       *&#64;&#64;     'model.netdef' depending on the model type.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string default_model_filename = 8;</code>
       */
      public String getDefaultModelFilename() {
        Object ref = defaultModelFilename_;
        if (!(ref instanceof String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          String s = bs.toStringUtf8();
          defaultModelFilename_ = s;
          return s;
        } else {
          return (String) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string default_model_filename
       *&#64;&#64;
       *&#64;&#64;     Optional filename of the model file to use if a
       *&#64;&#64;     compute-capability specific model is not specified in
       *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
       *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
       *&#64;&#64;     'model.netdef' depending on the model type.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string default_model_filename = 8;</code>
       */
      public com.google.protobuf.ByteString
          getDefaultModelFilenameBytes() {
        Object ref = defaultModelFilename_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b =
              com.google.protobuf.ByteString.copyFromUtf8(
                  (String) ref);
          defaultModelFilename_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string default_model_filename
       *&#64;&#64;
       *&#64;&#64;     Optional filename of the model file to use if a
       *&#64;&#64;     compute-capability specific model is not specified in
       *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
       *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
       *&#64;&#64;     'model.netdef' depending on the model type.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string default_model_filename = 8;</code>
       */
      public Builder setDefaultModelFilename(
          String value) {
        if (value == null) {
    throw new NullPointerException();
  }

        defaultModelFilename_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string default_model_filename
       *&#64;&#64;
       *&#64;&#64;     Optional filename of the model file to use if a
       *&#64;&#64;     compute-capability specific model is not specified in
       *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
       *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
       *&#64;&#64;     'model.netdef' depending on the model type.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string default_model_filename = 8;</code>
       */
      public Builder clearDefaultModelFilename() {

        defaultModelFilename_ = getDefaultInstance().getDefaultModelFilename();
        onChanged();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: string default_model_filename
       *&#64;&#64;
       *&#64;&#64;     Optional filename of the model file to use if a
       *&#64;&#64;     compute-capability specific model is not specified in
       *&#64;&#64;     :cpp:var:`cc_model_filenames`. If not specified the default name
       *&#64;&#64;     is 'model.graphdef', 'model.savedmodel', 'model.plan' or
       *&#64;&#64;     'model.netdef' depending on the model type.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional string default_model_filename = 8;</code>
       */
      public Builder setDefaultModelFilenameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);

        defaultModelFilename_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          String, String> ccModelFilenames_;
      private com.google.protobuf.MapField<String, String>
      internalGetCcModelFilenames() {
        if (ccModelFilenames_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              CcModelFilenamesDefaultEntryHolder.defaultEntry);
        }
        return ccModelFilenames_;
      }
      private com.google.protobuf.MapField<String, String>
      internalGetMutableCcModelFilenames() {
        onChanged();;
        if (ccModelFilenames_ == null) {
          ccModelFilenames_ = com.google.protobuf.MapField.newMapField(
              CcModelFilenamesDefaultEntryHolder.defaultEntry);
        }
        if (!ccModelFilenames_.isMutable()) {
          ccModelFilenames_ = ccModelFilenames_.copy();
        }
        return ccModelFilenames_;
      }

      public int getCcModelFilenamesCount() {
        return internalGetCcModelFilenames().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public boolean containsCcModelFilenames(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetCcModelFilenames().getMap().containsKey(key);
      }
      /**
       * Use {@link #getCcModelFilenamesMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, String> getCcModelFilenames() {
        return getCcModelFilenamesMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public java.util.Map<String, String> getCcModelFilenamesMap() {
        return internalGetCcModelFilenames().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public String getCcModelFilenamesOrDefault(
          String key,
          String defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetCcModelFilenames().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public String getCcModelFilenamesOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetCcModelFilenames().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearCcModelFilenames() {
        getMutableCcModelFilenames().clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public Builder removeCcModelFilenames(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        getMutableCcModelFilenames().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<String, String>
      getMutableCcModelFilenames() {
        return internalGetMutableCcModelFilenames().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */
      public Builder putCcModelFilenames(
          String key,
          String value) {
        if (key == null) { throw new NullPointerException(); }
        if (value == null) { throw new NullPointerException(); }
        getMutableCcModelFilenames().put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; cc_model_filenames
       *&#64;&#64;
       *&#64;&#64;     Optional map from CUDA compute capability to the filename of
       *&#64;&#64;     the model that supports that compute capability. The filename
       *&#64;&#64;     refers to a file within the model version directory.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; cc_model_filenames = 9;</code>
       */

      public Builder putAllCcModelFilenames(
          java.util.Map<String, String> values) {
        getMutableCcModelFilenames().putAll(values);
        return this;
      }

      private com.google.protobuf.MapField<
          String, String> metricTags_;
      private com.google.protobuf.MapField<String, String>
      internalGetMetricTags() {
        if (metricTags_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              MetricTagsDefaultEntryHolder.defaultEntry);
        }
        return metricTags_;
      }
      private com.google.protobuf.MapField<String, String>
      internalGetMutableMetricTags() {
        onChanged();;
        if (metricTags_ == null) {
          metricTags_ = com.google.protobuf.MapField.newMapField(
              MetricTagsDefaultEntryHolder.defaultEntry);
        }
        if (!metricTags_.isMutable()) {
          metricTags_ = metricTags_.copy();
        }
        return metricTags_;
      }

      public int getMetricTagsCount() {
        return internalGetMetricTags().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public boolean containsMetricTags(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetMetricTags().getMap().containsKey(key);
      }
      /**
       * Use {@link #getMetricTagsMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, String> getMetricTags() {
        return getMetricTagsMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public java.util.Map<String, String> getMetricTagsMap() {
        return internalGetMetricTags().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public String getMetricTagsOrDefault(
          String key,
          String defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetMetricTags().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public String getMetricTagsOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, String> map =
            internalGetMetricTags().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearMetricTags() {
        getMutableMetricTags().clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public Builder removeMetricTags(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        getMutableMetricTags().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<String, String>
      getMutableMetricTags() {
        return internalGetMutableMetricTags().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */
      public Builder putMetricTags(
          String key,
          String value) {
        if (key == null) { throw new NullPointerException(); }
        if (value == null) { throw new NullPointerException(); }
        getMutableMetricTags().put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,string&gt; metric_tags
       *&#64;&#64;
       *&#64;&#64;     Optional metric tags. User-specific key-value pairs for metrics
       *&#64;&#64;     reported for this model. These tags are applied to the metrics
       *&#64;&#64;     reported on the HTTP metrics port.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, string&gt; metric_tags = 10;</code>
       */

      public Builder putAllMetricTags(
          java.util.Map<String, String> values) {
        getMutableMetricTags().putAll(values);
        return this;
      }

      private com.google.protobuf.MapField<
          String, ModelConfigOuterClass.ModelParameter> parameters_;
      private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelParameter>
      internalGetParameters() {
        if (parameters_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              ParametersDefaultEntryHolder.defaultEntry);
        }
        return parameters_;
      }
      private com.google.protobuf.MapField<String, ModelConfigOuterClass.ModelParameter>
      internalGetMutableParameters() {
        onChanged();;
        if (parameters_ == null) {
          parameters_ = com.google.protobuf.MapField.newMapField(
              ParametersDefaultEntryHolder.defaultEntry);
        }
        if (!parameters_.isMutable()) {
          parameters_ = parameters_.copy();
        }
        return parameters_;
      }

      public int getParametersCount() {
        return internalGetParameters().getMap().size();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public boolean containsParameters(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        return internalGetParameters().getMap().containsKey(key);
      }
      /**
       * Use {@link #getParametersMap()} instead.
       */
      @Deprecated
      public java.util.Map<String, ModelParameter> getParameters() {
        return getParametersMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public java.util.Map<String, ModelParameter> getParametersMap() {
        return internalGetParameters().getMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public ModelConfigOuterClass.ModelParameter getParametersOrDefault(
          String key,
          ModelConfigOuterClass.ModelParameter defaultValue) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, ModelParameter> map =
            internalGetParameters().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public ModelConfigOuterClass.ModelParameter getParametersOrThrow(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        java.util.Map<String, ModelParameter> map =
            internalGetParameters().getMap();
        if (!map.containsKey(key)) {
          throw new IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearParameters() {
        getMutableParameters().clear();
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public Builder removeParameters(
          String key) {
        if (key == null) { throw new NullPointerException(); }
        getMutableParameters().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @Deprecated
      public java.util.Map<String, ModelParameter>
      getMutableParameters() {
        return internalGetMutableParameters().getMutableMap();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */
      public Builder putParameters(
          String key,
          ModelConfigOuterClass.ModelParameter value) {
        if (key == null) { throw new NullPointerException(); }
        if (value == null) { throw new NullPointerException(); }
        getMutableParameters().put(key, value);
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: map&lt;string,ModelParameter&gt; parameters
       *&#64;&#64;
       *&#64;&#64;     Optional model parameters. User-specified parameter values that
       *&#64;&#64;     are made available to custom backends.
       *&#64;&#64;
       * </pre>
       *
       * <code>map&lt;string, .inference.ModelParameter&gt; parameters = 14;</code>
       */

      public Builder putAllParameters(
          java.util.Map<String, ModelParameter> values) {
        getMutableParameters().putAll(values);
        return this;
      }

      private java.util.List<ModelWarmup> modelWarmup_ =
        java.util.Collections.emptyList();
      private void ensureModelWarmupIsMutable() {
        if (!((bitField0_ & 0x00010000) == 0x00010000)) {
          modelWarmup_ = new java.util.ArrayList<ModelWarmup>(modelWarmup_);
          bitField0_ |= 0x00010000;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelWarmup, ModelConfigOuterClass.ModelWarmup.Builder, ModelConfigOuterClass.ModelWarmupOrBuilder> modelWarmupBuilder_;

      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public java.util.List<ModelWarmup> getModelWarmupList() {
        if (modelWarmupBuilder_ == null) {
          return java.util.Collections.unmodifiableList(modelWarmup_);
        } else {
          return modelWarmupBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public int getModelWarmupCount() {
        if (modelWarmupBuilder_ == null) {
          return modelWarmup_.size();
        } else {
          return modelWarmupBuilder_.getCount();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public ModelConfigOuterClass.ModelWarmup getModelWarmup(int index) {
        if (modelWarmupBuilder_ == null) {
          return modelWarmup_.get(index);
        } else {
          return modelWarmupBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder setModelWarmup(
          int index, ModelConfigOuterClass.ModelWarmup value) {
        if (modelWarmupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelWarmupIsMutable();
          modelWarmup_.set(index, value);
          onChanged();
        } else {
          modelWarmupBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder setModelWarmup(
          int index, ModelConfigOuterClass.ModelWarmup.Builder builderForValue) {
        if (modelWarmupBuilder_ == null) {
          ensureModelWarmupIsMutable();
          modelWarmup_.set(index, builderForValue.build());
          onChanged();
        } else {
          modelWarmupBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder addModelWarmup(ModelConfigOuterClass.ModelWarmup value) {
        if (modelWarmupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelWarmupIsMutable();
          modelWarmup_.add(value);
          onChanged();
        } else {
          modelWarmupBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder addModelWarmup(
          int index, ModelConfigOuterClass.ModelWarmup value) {
        if (modelWarmupBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureModelWarmupIsMutable();
          modelWarmup_.add(index, value);
          onChanged();
        } else {
          modelWarmupBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder addModelWarmup(
          ModelConfigOuterClass.ModelWarmup.Builder builderForValue) {
        if (modelWarmupBuilder_ == null) {
          ensureModelWarmupIsMutable();
          modelWarmup_.add(builderForValue.build());
          onChanged();
        } else {
          modelWarmupBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder addModelWarmup(
          int index, ModelConfigOuterClass.ModelWarmup.Builder builderForValue) {
        if (modelWarmupBuilder_ == null) {
          ensureModelWarmupIsMutable();
          modelWarmup_.add(index, builderForValue.build());
          onChanged();
        } else {
          modelWarmupBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder addAllModelWarmup(
          Iterable<? extends ModelWarmup> values) {
        if (modelWarmupBuilder_ == null) {
          ensureModelWarmupIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, modelWarmup_);
          onChanged();
        } else {
          modelWarmupBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder clearModelWarmup() {
        if (modelWarmupBuilder_ == null) {
          modelWarmup_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00010000);
          onChanged();
        } else {
          modelWarmupBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public Builder removeModelWarmup(int index) {
        if (modelWarmupBuilder_ == null) {
          ensureModelWarmupIsMutable();
          modelWarmup_.remove(index);
          onChanged();
        } else {
          modelWarmupBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public ModelConfigOuterClass.ModelWarmup.Builder getModelWarmupBuilder(
          int index) {
        return getModelWarmupFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public ModelConfigOuterClass.ModelWarmupOrBuilder getModelWarmupOrBuilder(
          int index) {
        if (modelWarmupBuilder_ == null) {
          return modelWarmup_.get(index);  } else {
          return modelWarmupBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public java.util.List<? extends ModelWarmupOrBuilder>
           getModelWarmupOrBuilderList() {
        if (modelWarmupBuilder_ != null) {
          return modelWarmupBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(modelWarmup_);
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public ModelConfigOuterClass.ModelWarmup.Builder addModelWarmupBuilder() {
        return getModelWarmupFieldBuilder().addBuilder(
            ModelConfigOuterClass.ModelWarmup.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public ModelConfigOuterClass.ModelWarmup.Builder addModelWarmupBuilder(
          int index) {
        return getModelWarmupFieldBuilder().addBuilder(
            index, ModelConfigOuterClass.ModelWarmup.getDefaultInstance());
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelWarmup model_warmup (repeated)
       *&#64;&#64;
       *&#64;&#64;     Warmup setting of this model. If specified, all instances
       *&#64;&#64;     will be run with the request samples in sequence before
       *&#64;&#64;     serving the model.
       *&#64;&#64;     This field can only be specified if the model is not an ensemble
       *&#64;&#64;     model.
       *&#64;&#64;
       * </pre>
       *
       * <code>repeated .inference.ModelWarmup model_warmup = 16;</code>
       */
      public java.util.List<ModelWarmup.Builder>
           getModelWarmupBuilderList() {
        return getModelWarmupFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          ModelConfigOuterClass.ModelWarmup, ModelConfigOuterClass.ModelWarmup.Builder, ModelConfigOuterClass.ModelWarmupOrBuilder>
          getModelWarmupFieldBuilder() {
        if (modelWarmupBuilder_ == null) {
          modelWarmupBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              ModelConfigOuterClass.ModelWarmup, ModelConfigOuterClass.ModelWarmup.Builder, ModelConfigOuterClass.ModelWarmupOrBuilder>(
                  modelWarmup_,
                  ((bitField0_ & 0x00010000) == 0x00010000),
                  getParentForChildren(),
                  isClean());
          modelWarmup_ = null;
        }
        return modelWarmupBuilder_;
      }

      private ModelConfigOuterClass.ModelOperations modelOperations_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOperations, ModelConfigOuterClass.ModelOperations.Builder, ModelConfigOuterClass.ModelOperationsOrBuilder> modelOperationsBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public boolean hasModelOperations() {
        return modelOperationsBuilder_ != null || modelOperations_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public ModelConfigOuterClass.ModelOperations getModelOperations() {
        if (modelOperationsBuilder_ == null) {
          return modelOperations_ == null ? ModelConfigOuterClass.ModelOperations.getDefaultInstance() : modelOperations_;
        } else {
          return modelOperationsBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public Builder setModelOperations(ModelConfigOuterClass.ModelOperations value) {
        if (modelOperationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modelOperations_ = value;
          onChanged();
        } else {
          modelOperationsBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public Builder setModelOperations(
          ModelConfigOuterClass.ModelOperations.Builder builderForValue) {
        if (modelOperationsBuilder_ == null) {
          modelOperations_ = builderForValue.build();
          onChanged();
        } else {
          modelOperationsBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public Builder mergeModelOperations(ModelConfigOuterClass.ModelOperations value) {
        if (modelOperationsBuilder_ == null) {
          if (modelOperations_ != null) {
            modelOperations_ =
              ModelConfigOuterClass.ModelOperations.newBuilder(modelOperations_).mergeFrom(value).buildPartial();
          } else {
            modelOperations_ = value;
          }
          onChanged();
        } else {
          modelOperationsBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public Builder clearModelOperations() {
        if (modelOperationsBuilder_ == null) {
          modelOperations_ = null;
          onChanged();
        } else {
          modelOperations_ = null;
          modelOperationsBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public ModelConfigOuterClass.ModelOperations.Builder getModelOperationsBuilder() {

        onChanged();
        return getModelOperationsFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      public ModelConfigOuterClass.ModelOperationsOrBuilder getModelOperationsOrBuilder() {
        if (modelOperationsBuilder_ != null) {
          return modelOperationsBuilder_.getMessageOrBuilder();
        } else {
          return modelOperations_ == null ?
              ModelConfigOuterClass.ModelOperations.getDefaultInstance() : modelOperations_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelOperations model_operations
       *&#64;&#64;
       *&#64;&#64;     Optional metadata of the libraries providing custom operations for
       *&#64;&#64;     this model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelOperations model_operations = 18;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelOperations, ModelConfigOuterClass.ModelOperations.Builder, ModelConfigOuterClass.ModelOperationsOrBuilder>
          getModelOperationsFieldBuilder() {
        if (modelOperationsBuilder_ == null) {
          modelOperationsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelOperations, ModelConfigOuterClass.ModelOperations.Builder, ModelConfigOuterClass.ModelOperationsOrBuilder>(
                  getModelOperations(),
                  getParentForChildren(),
                  isClean());
          modelOperations_ = null;
        }
        return modelOperationsBuilder_;
      }

      private ModelConfigOuterClass.ModelTransactionPolicy modelTransactionPolicy_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTransactionPolicy, ModelConfigOuterClass.ModelTransactionPolicy.Builder, ModelConfigOuterClass.ModelTransactionPolicyOrBuilder> modelTransactionPolicyBuilder_;
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public boolean hasModelTransactionPolicy() {
        return modelTransactionPolicyBuilder_ != null || modelTransactionPolicy_ != null;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public ModelConfigOuterClass.ModelTransactionPolicy getModelTransactionPolicy() {
        if (modelTransactionPolicyBuilder_ == null) {
          return modelTransactionPolicy_ == null ? ModelConfigOuterClass.ModelTransactionPolicy.getDefaultInstance() : modelTransactionPolicy_;
        } else {
          return modelTransactionPolicyBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public Builder setModelTransactionPolicy(ModelConfigOuterClass.ModelTransactionPolicy value) {
        if (modelTransactionPolicyBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          modelTransactionPolicy_ = value;
          onChanged();
        } else {
          modelTransactionPolicyBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public Builder setModelTransactionPolicy(
          ModelConfigOuterClass.ModelTransactionPolicy.Builder builderForValue) {
        if (modelTransactionPolicyBuilder_ == null) {
          modelTransactionPolicy_ = builderForValue.build();
          onChanged();
        } else {
          modelTransactionPolicyBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public Builder mergeModelTransactionPolicy(ModelConfigOuterClass.ModelTransactionPolicy value) {
        if (modelTransactionPolicyBuilder_ == null) {
          if (modelTransactionPolicy_ != null) {
            modelTransactionPolicy_ =
              ModelConfigOuterClass.ModelTransactionPolicy.newBuilder(modelTransactionPolicy_).mergeFrom(value).buildPartial();
          } else {
            modelTransactionPolicy_ = value;
          }
          onChanged();
        } else {
          modelTransactionPolicyBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public Builder clearModelTransactionPolicy() {
        if (modelTransactionPolicyBuilder_ == null) {
          modelTransactionPolicy_ = null;
          onChanged();
        } else {
          modelTransactionPolicy_ = null;
          modelTransactionPolicyBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public ModelConfigOuterClass.ModelTransactionPolicy.Builder getModelTransactionPolicyBuilder() {

        onChanged();
        return getModelTransactionPolicyFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      public ModelConfigOuterClass.ModelTransactionPolicyOrBuilder getModelTransactionPolicyOrBuilder() {
        if (modelTransactionPolicyBuilder_ != null) {
          return modelTransactionPolicyBuilder_.getMessageOrBuilder();
        } else {
          return modelTransactionPolicy_ == null ?
              ModelConfigOuterClass.ModelTransactionPolicy.getDefaultInstance() : modelTransactionPolicy_;
        }
      }
      /**
       * <pre>
       *&#64;&#64;  .. cpp:var:: ModelTransactionPolicy model_transaction_policy
       *&#64;&#64;
       *&#64;&#64;     Optional specification that describes the nature of transactions
       *&#64;&#64;     to be expected from the model.
       *&#64;&#64;
       * </pre>
       *
       * <code>optional .inference.ModelTransactionPolicy model_transaction_policy = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          ModelConfigOuterClass.ModelTransactionPolicy, ModelConfigOuterClass.ModelTransactionPolicy.Builder, ModelConfigOuterClass.ModelTransactionPolicyOrBuilder>
          getModelTransactionPolicyFieldBuilder() {
        if (modelTransactionPolicyBuilder_ == null) {
          modelTransactionPolicyBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              ModelConfigOuterClass.ModelTransactionPolicy, ModelConfigOuterClass.ModelTransactionPolicy.Builder, ModelConfigOuterClass.ModelTransactionPolicyOrBuilder>(
                  getModelTransactionPolicy(),
                  getParentForChildren(),
                  isClean());
          modelTransactionPolicy_ = null;
        }
        return modelTransactionPolicyBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:inference.ModelConfig)
    }

    // @@protoc_insertion_point(class_scope:inference.ModelConfig)
    private static final ModelConfigOuterClass.ModelConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new ModelConfigOuterClass.ModelConfig();
    }

    public static ModelConfigOuterClass.ModelConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<ModelConfig>
        PARSER = new com.google.protobuf.AbstractParser<ModelConfig>() {
      public ModelConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ModelConfig(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ModelConfig> parser() {
      return PARSER;
    }

    @Override
    public com.google.protobuf.Parser<ModelConfig> getParserForType() {
      return PARSER;
    }

    public ModelConfigOuterClass.ModelConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelInstanceGroup_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelInstanceGroup_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelTensorReshape_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelTensorReshape_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelInput_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelInput_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOutput_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOutput_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelVersionPolicy_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelVersionPolicy_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelVersionPolicy_Latest_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelVersionPolicy_Latest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelVersionPolicy_All_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelVersionPolicy_All_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelVersionPolicy_Specific_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelVersionPolicy_Specific_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_Graph_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_Graph_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_Cuda_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelQueuePolicy_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelQueuePolicy_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelDynamicBatching_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelDynamicBatching_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelSequenceBatching_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelSequenceBatching_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelSequenceBatching_Control_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelSequenceBatching_Control_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelSequenceBatching_ControlInput_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelSequenceBatching_ControlInput_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelSequenceBatching_StrategyDirect_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelSequenceBatching_StrategyOldest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelEnsembling_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelEnsembling_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelEnsembling_Step_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelEnsembling_Step_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelEnsembling_Step_InputMapEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelEnsembling_Step_InputMapEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelEnsembling_Step_OutputMapEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelEnsembling_Step_OutputMapEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelParameter_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelParameter_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelWarmup_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelWarmup_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelWarmup_Input_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelWarmup_Input_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelWarmup_InputsEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelWarmup_InputsEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelOperations_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelOperations_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelTransactionPolicy_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelTransactionPolicy_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelConfig_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelConfig_CcModelFilenamesEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelConfig_CcModelFilenamesEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelConfig_MetricTagsEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelConfig_MetricTagsEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_inference_ModelConfig_ParametersEntry_descriptor;
  private static final
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_inference_ModelConfig_ParametersEntry_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    String[] descriptorData = {
      "\n\022model_config.proto\022\tinference\"\305\001\n\022Mode" +
      "lInstanceGroup\022\014\n\004name\030\001 \001(\t\0220\n\004kind\030\004 \001" +
      "(\0162\".inference.ModelInstanceGroup.Kind\022\r" +
      "\n\005count\030\002 \001(\005\022\014\n\004gpus\030\003 \003(\005\022\017\n\007profile\030\005" +
      " \003(\t\"A\n\004Kind\022\r\n\tKIND_AUTO\020\000\022\014\n\010KIND_GPU\020" +
      "\001\022\014\n\010KIND_CPU\020\002\022\016\n\nKIND_MODEL\020\003\"#\n\022Model" +
      "TensorReshape\022\r\n\005shape\030\001 \003(\003\"\240\002\n\nModelIn" +
      "put\022\014\n\004name\030\001 \001(\t\022&\n\tdata_type\030\002 \001(\0162\023.i" +
      "nference.DataType\022,\n\006format\030\003 \001(\0162\034.infe" +
      "rence.ModelInput.Format\022\014\n\004dims\030\004 \003(\003\022.\n",
      "\007reshape\030\005 \001(\0132\035.inference.ModelTensorRe" +
      "shape\022\027\n\017is_shape_tensor\030\006 \001(\010\022\032\n\022allow_" +
      "ragged_batch\030\007 \001(\010\";\n\006Format\022\017\n\013FORMAT_N" +
      "ONE\020\000\022\017\n\013FORMAT_NHWC\020\001\022\017\n\013FORMAT_NCHW\020\002\"" +
      "\262\001\n\013ModelOutput\022\014\n\004name\030\001 \001(\t\022&\n\tdata_ty" +
      "pe\030\002 \001(\0162\023.inference.DataType\022\014\n\004dims\030\003 " +
      "\003(\003\022.\n\007reshape\030\005 \001(\0132\035.inference.ModelTe" +
      "nsorReshape\022\026\n\016label_filename\030\004 \001(\t\022\027\n\017i" +
      "s_shape_tensor\030\006 \001(\010\"\220\002\n\022ModelVersionPol" +
      "icy\0226\n\006latest\030\001 \001(\0132$.inference.ModelVer",
      "sionPolicy.LatestH\000\0220\n\003all\030\002 \001(\0132!.infer" +
      "ence.ModelVersionPolicy.AllH\000\022:\n\010specifi" +
      "c\030\003 \001(\0132&.inference.ModelVersionPolicy.S" +
      "pecificH\000\032\036\n\006Latest\022\024\n\014num_versions\030\001 \001(" +
      "\r\032\005\n\003All\032\034\n\010Specific\022\020\n\010versions\030\001 \003(\003B\017" +
      "\n\rpolicy_choice\"\262\010\n\027ModelOptimizationPol" +
      "icy\0227\n\005graph\030\001 \001(\0132(.inference.ModelOpti" +
      "mizationPolicy.Graph\022B\n\010priority\030\002 \001(\01620" +
      ".inference.ModelOptimizationPolicy.Model" +
      "Priority\0225\n\004cuda\030\003 \001(\0132\'.inference.Model",
      "OptimizationPolicy.Cuda\022X\n\026execution_acc" +
      "elerators\030\004 \001(\01328.inference.ModelOptimiz" +
      "ationPolicy.ExecutionAccelerators\022R\n\023inp" +
      "ut_pinned_memory\030\005 \001(\01325.inference.Model" +
      "OptimizationPolicy.PinnedMemoryBuffer\022S\n" +
      "\024output_pinned_memory\030\006 \001(\01325.inference." +
      "ModelOptimizationPolicy.PinnedMemoryBuff" +
      "er\032\026\n\005Graph\022\r\n\005level\030\001 \001(\005\0320\n\004Cuda\022\016\n\006gr" +
      "aphs\030\001 \001(\010\022\030\n\020busy_wait_events\030\002 \001(\010\032\244\003\n" +
      "\025ExecutionAccelerators\022g\n\031gpu_execution_",
      "accelerator\030\001 \003(\0132D.inference.ModelOptim" +
      "izationPolicy.ExecutionAccelerators.Acce" +
      "lerator\022g\n\031cpu_execution_accelerator\030\002 \003" +
      "(\0132D.inference.ModelOptimizationPolicy.E" +
      "xecutionAccelerators.Accelerator\032\270\001\n\013Acc" +
      "elerator\022\014\n\004name\030\001 \001(\t\022h\n\nparameters\030\002 \003" +
      "(\0132T.inference.ModelOptimizationPolicy.E" +
      "xecutionAccelerators.Accelerator.Paramet" +
      "ersEntry\0321\n\017ParametersEntry\022\013\n\003key\030\001 \001(\t" +
      "\022\r\n\005value\030\002 \001(\t:\0028\001\032$\n\022PinnedMemoryBuffe",
      "r\022\016\n\006enable\030\001 \001(\010\"I\n\rModelPriority\022\024\n\020PR" +
      "IORITY_DEFAULT\020\000\022\020\n\014PRIORITY_MAX\020\001\022\020\n\014PR" +
      "IORITY_MIN\020\002\"\333\001\n\020ModelQueuePolicy\022A\n\016tim" +
      "eout_action\030\001 \001(\0162).inference.ModelQueue" +
      "Policy.TimeoutAction\022$\n\034default_timeout_" +
      "microseconds\030\002 \001(\004\022\036\n\026allow_timeout_over" +
      "ride\030\003 \001(\010\022\026\n\016max_queue_size\030\004 \001(\r\"&\n\rTi" +
      "meoutAction\022\n\n\006REJECT\020\000\022\t\n\005DELAY\020\001\"\233\003\n\024M" +
      "odelDynamicBatching\022\034\n\024preferred_batch_s" +
      "ize\030\001 \003(\005\022$\n\034max_queue_delay_microsecond",
      "s\030\002 \001(\004\022\031\n\021preserve_ordering\030\003 \001(\010\022\027\n\017pr" +
      "iority_levels\030\004 \001(\r\022\036\n\026default_priority_" +
      "level\030\005 \001(\r\0229\n\024default_queue_policy\030\006 \001(" +
      "\0132\033.inference.ModelQueuePolicy\022W\n\025priori" +
      "ty_queue_policy\030\007 \003(\01328.inference.ModelD" +
      "ynamicBatching.PriorityQueuePolicyEntry\032" +
      "W\n\030PriorityQueuePolicyEntry\022\013\n\003key\030\001 \001(\r" +
      "\022*\n\005value\030\002 \001(\0132\033.inference.ModelQueuePo" +
      "licy:\0028\001\"\233\006\n\025ModelSequenceBatching\022A\n\006di" +
      "rect\030\003 \001(\0132/.inference.ModelSequenceBatc",
      "hing.StrategyDirectH\000\022A\n\006oldest\030\004 \001(\0132/." +
      "inference.ModelSequenceBatching.Strategy" +
      "OldestH\000\022&\n\036max_sequence_idle_microsecon" +
      "ds\030\001 \001(\004\022D\n\rcontrol_input\030\002 \003(\0132-.infere" +
      "nce.ModelSequenceBatching.ControlInput\032\230" +
      "\002\n\007Control\022;\n\004kind\030\001 \001(\0162-.inference.Mod" +
      "elSequenceBatching.Control.Kind\022\030\n\020int32" +
      "_false_true\030\002 \003(\005\022\027\n\017fp32_false_true\030\003 \003" +
      "(\002\022&\n\tdata_type\030\004 \001(\0162\023.inference.DataTy" +
      "pe\"u\n\004Kind\022\032\n\026CONTROL_SEQUENCE_START\020\000\022\032",
      "\n\026CONTROL_SEQUENCE_READY\020\001\022\030\n\024CONTROL_SE" +
      "QUENCE_END\020\002\022\033\n\027CONTROL_SEQUENCE_CORRID\020" +
      "\003\032W\n\014ControlInput\022\014\n\004name\030\001 \001(\t\0229\n\007contr" +
      "ol\030\002 \003(\0132(.inference.ModelSequenceBatchi" +
      "ng.Control\032\020\n\016StrategyDirect\032u\n\016Strategy" +
      "Oldest\022\037\n\027max_candidate_sequences\030\001 \001(\005\022" +
      "\034\n\024preferred_batch_size\030\002 \003(\005\022$\n\034max_que" +
      "ue_delay_microseconds\030\003 \001(\004B\021\n\017strategy_" +
      "choice\"\335\002\n\017ModelEnsembling\022-\n\004step\030\001 \003(\013" +
      "2\037.inference.ModelEnsembling.Step\032\232\002\n\004St",
      "ep\022\022\n\nmodel_name\030\001 \001(\t\022\025\n\rmodel_version\030" +
      "\002 \001(\003\022@\n\tinput_map\030\003 \003(\0132-.inference.Mod" +
      "elEnsembling.Step.InputMapEntry\022B\n\noutpu" +
      "t_map\030\004 \003(\0132..inference.ModelEnsembling." +
      "Step.OutputMapEntry\032/\n\rInputMapEntry\022\013\n\003" +
      "key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\0320\n\016OutputMa" +
      "pEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\"&" +
      "\n\016ModelParameter\022\024\n\014string_value\030\001 \001(\t\"\312" +
      "\002\n\013ModelWarmup\022\014\n\004name\030\001 \001(\t\022\022\n\nbatch_si" +
      "ze\030\002 \001(\r\0222\n\006inputs\030\003 \003(\0132\".inference.Mod",
      "elWarmup.InputsEntry\032\227\001\n\005Input\022&\n\tdata_t" +
      "ype\030\001 \001(\0162\023.inference.DataType\022\014\n\004dims\030\002" +
      " \003(\003\022\023\n\tzero_data\030\003 \001(\010H\000\022\025\n\013random_data" +
      "\030\004 \001(\010H\000\022\031\n\017input_data_file\030\005 \001(\tH\000B\021\n\017i" +
      "nput_data_type\032K\n\013InputsEntry\022\013\n\003key\030\001 \001" +
      "(\t\022+\n\005value\030\002 \001(\0132\034.inference.ModelWarmu" +
      "p.Input:\0028\001\".\n\017ModelOperations\022\033\n\023op_lib" +
      "rary_filename\030\001 \003(\t\"+\n\026ModelTransactionP" +
      "olicy\022\021\n\tdecoupled\030\001 \001(\010\"\336\010\n\013ModelConfig" +
      "\022\014\n\004name\030\001 \001(\t\022\020\n\010platform\030\002 \001(\t\022\017\n\007back",
      "end\030\021 \001(\t\0225\n\016version_policy\030\003 \001(\0132\035.infe" +
      "rence.ModelVersionPolicy\022\026\n\016max_batch_si" +
      "ze\030\004 \001(\005\022$\n\005input\030\005 \003(\0132\025.inference.Mode" +
      "lInput\022&\n\006output\030\006 \003(\0132\026.inference.Model" +
      "Output\0228\n\014optimization\030\014 \001(\0132\".inference" +
      ".ModelOptimizationPolicy\022;\n\020dynamic_batc" +
      "hing\030\013 \001(\0132\037.inference.ModelDynamicBatch" +
      "ingH\000\022=\n\021sequence_batching\030\r \001(\0132 .infer" +
      "ence.ModelSequenceBatchingH\000\0229\n\023ensemble" +
      "_scheduling\030\017 \001(\0132\032.inference.ModelEnsem",
      "blingH\000\0225\n\016instance_group\030\007 \003(\0132\035.infere" +
      "nce.ModelInstanceGroup\022\036\n\026default_model_" +
      "filename\030\010 \001(\t\022H\n\022cc_model_filenames\030\t \003" +
      "(\0132,.inference.ModelConfig.CcModelFilena" +
      "mesEntry\022;\n\013metric_tags\030\n \003(\0132&.inferenc" +
      "e.ModelConfig.MetricTagsEntry\022:\n\nparamet" +
      "ers\030\016 \003(\0132&.inference.ModelConfig.Parame" +
      "tersEntry\022,\n\014model_warmup\030\020 \003(\0132\026.infere" +
      "nce.ModelWarmup\0224\n\020model_operations\030\022 \001(" +
      "\0132\032.inference.ModelOperations\022C\n\030model_t",
      "ransaction_policy\030\023 \001(\0132!.inference.Mode" +
      "lTransactionPolicy\0327\n\025CcModelFilenamesEn" +
      "try\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\t:\0028\001\0321\n\017M" +
      "etricTagsEntry\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001" +
      "(\t:\0028\001\032L\n\017ParametersEntry\022\013\n\003key\030\001 \001(\t\022(" +
      "\n\005value\030\002 \001(\0132\031.inference.ModelParameter" +
      ":\0028\001B\023\n\021scheduling_choice*\353\001\n\010DataType\022\020" +
      "\n\014TYPE_INVALID\020\000\022\r\n\tTYPE_BOOL\020\001\022\016\n\nTYPE_" +
      "UINT8\020\002\022\017\n\013TYPE_UINT16\020\003\022\017\n\013TYPE_UINT32\020" +
      "\004\022\017\n\013TYPE_UINT64\020\005\022\r\n\tTYPE_INT8\020\006\022\016\n\nTYP",
      "E_INT16\020\007\022\016\n\nTYPE_INT32\020\010\022\016\n\nTYPE_INT64\020" +
      "\t\022\r\n\tTYPE_FP16\020\n\022\r\n\tTYPE_FP32\020\013\022\r\n\tTYPE_" +
      "FP64\020\014\022\017\n\013TYPE_STRING\020\rb\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
        }, assigner);
    internal_static_inference_ModelInstanceGroup_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_inference_ModelInstanceGroup_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelInstanceGroup_descriptor,
        new String[] { "Name", "Kind", "Count", "Gpus", "Profile", });
    internal_static_inference_ModelTensorReshape_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_inference_ModelTensorReshape_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelTensorReshape_descriptor,
        new String[] { "Shape", });
    internal_static_inference_ModelInput_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_inference_ModelInput_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelInput_descriptor,
        new String[] { "Name", "DataType", "Format", "Dims", "Reshape", "IsShapeTensor", "AllowRaggedBatch", });
    internal_static_inference_ModelOutput_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_inference_ModelOutput_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOutput_descriptor,
        new String[] { "Name", "DataType", "Dims", "Reshape", "LabelFilename", "IsShapeTensor", });
    internal_static_inference_ModelVersionPolicy_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_inference_ModelVersionPolicy_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelVersionPolicy_descriptor,
        new String[] { "Latest", "All", "Specific", "PolicyChoice", });
    internal_static_inference_ModelVersionPolicy_Latest_descriptor =
      internal_static_inference_ModelVersionPolicy_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelVersionPolicy_Latest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelVersionPolicy_Latest_descriptor,
        new String[] { "NumVersions", });
    internal_static_inference_ModelVersionPolicy_All_descriptor =
      internal_static_inference_ModelVersionPolicy_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelVersionPolicy_All_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelVersionPolicy_All_descriptor,
        new String[] { });
    internal_static_inference_ModelVersionPolicy_Specific_descriptor =
      internal_static_inference_ModelVersionPolicy_descriptor.getNestedTypes().get(2);
    internal_static_inference_ModelVersionPolicy_Specific_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelVersionPolicy_Specific_descriptor,
        new String[] { "Versions", });
    internal_static_inference_ModelOptimizationPolicy_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_inference_ModelOptimizationPolicy_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_descriptor,
        new String[] { "Graph", "Priority", "Cuda", "ExecutionAccelerators", "InputPinnedMemory", "OutputPinnedMemory", });
    internal_static_inference_ModelOptimizationPolicy_Graph_descriptor =
      internal_static_inference_ModelOptimizationPolicy_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelOptimizationPolicy_Graph_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_Graph_descriptor,
        new String[] { "Level", });
    internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor =
      internal_static_inference_ModelOptimizationPolicy_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelOptimizationPolicy_Cuda_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_Cuda_descriptor,
        new String[] { "Graphs", "BusyWaitEvents", });
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor =
      internal_static_inference_ModelOptimizationPolicy_descriptor.getNestedTypes().get(2);
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor,
        new String[] { "GpuExecutionAccelerator", "CpuExecutionAccelerator", });
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor =
      internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor,
        new String[] { "Name", "Parameters", });
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_descriptor =
      internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_ExecutionAccelerators_Accelerator_ParametersEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor =
      internal_static_inference_ModelOptimizationPolicy_descriptor.getNestedTypes().get(3);
    internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOptimizationPolicy_PinnedMemoryBuffer_descriptor,
        new String[] { "Enable", });
    internal_static_inference_ModelQueuePolicy_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_inference_ModelQueuePolicy_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelQueuePolicy_descriptor,
        new String[] { "TimeoutAction", "DefaultTimeoutMicroseconds", "AllowTimeoutOverride", "MaxQueueSize", });
    internal_static_inference_ModelDynamicBatching_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_inference_ModelDynamicBatching_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelDynamicBatching_descriptor,
        new String[] { "PreferredBatchSize", "MaxQueueDelayMicroseconds", "PreserveOrdering", "PriorityLevels", "DefaultPriorityLevel", "DefaultQueuePolicy", "PriorityQueuePolicy", });
    internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_descriptor =
      internal_static_inference_ModelDynamicBatching_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelDynamicBatching_PriorityQueuePolicyEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelSequenceBatching_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_inference_ModelSequenceBatching_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelSequenceBatching_descriptor,
        new String[] { "Direct", "Oldest", "MaxSequenceIdleMicroseconds", "ControlInput", "StrategyChoice", });
    internal_static_inference_ModelSequenceBatching_Control_descriptor =
      internal_static_inference_ModelSequenceBatching_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelSequenceBatching_Control_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelSequenceBatching_Control_descriptor,
        new String[] { "Kind", "Int32FalseTrue", "Fp32FalseTrue", "DataType", });
    internal_static_inference_ModelSequenceBatching_ControlInput_descriptor =
      internal_static_inference_ModelSequenceBatching_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelSequenceBatching_ControlInput_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelSequenceBatching_ControlInput_descriptor,
        new String[] { "Name", "Control", });
    internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor =
      internal_static_inference_ModelSequenceBatching_descriptor.getNestedTypes().get(2);
    internal_static_inference_ModelSequenceBatching_StrategyDirect_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelSequenceBatching_StrategyDirect_descriptor,
        new String[] { });
    internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor =
      internal_static_inference_ModelSequenceBatching_descriptor.getNestedTypes().get(3);
    internal_static_inference_ModelSequenceBatching_StrategyOldest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelSequenceBatching_StrategyOldest_descriptor,
        new String[] { "MaxCandidateSequences", "PreferredBatchSize", "MaxQueueDelayMicroseconds", });
    internal_static_inference_ModelEnsembling_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_inference_ModelEnsembling_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelEnsembling_descriptor,
        new String[] { "Step", });
    internal_static_inference_ModelEnsembling_Step_descriptor =
      internal_static_inference_ModelEnsembling_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelEnsembling_Step_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelEnsembling_Step_descriptor,
        new String[] { "ModelName", "ModelVersion", "InputMap", "OutputMap", });
    internal_static_inference_ModelEnsembling_Step_InputMapEntry_descriptor =
      internal_static_inference_ModelEnsembling_Step_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelEnsembling_Step_InputMapEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelEnsembling_Step_InputMapEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelEnsembling_Step_OutputMapEntry_descriptor =
      internal_static_inference_ModelEnsembling_Step_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelEnsembling_Step_OutputMapEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelEnsembling_Step_OutputMapEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelParameter_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_inference_ModelParameter_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelParameter_descriptor,
        new String[] { "StringValue", });
    internal_static_inference_ModelWarmup_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_inference_ModelWarmup_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelWarmup_descriptor,
        new String[] { "Name", "BatchSize", "Inputs", });
    internal_static_inference_ModelWarmup_Input_descriptor =
      internal_static_inference_ModelWarmup_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelWarmup_Input_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelWarmup_Input_descriptor,
        new String[] { "DataType", "Dims", "ZeroData", "RandomData", "InputDataFile", "InputDataType", });
    internal_static_inference_ModelWarmup_InputsEntry_descriptor =
      internal_static_inference_ModelWarmup_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelWarmup_InputsEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelWarmup_InputsEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelOperations_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_inference_ModelOperations_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelOperations_descriptor,
        new String[] { "OpLibraryFilename", });
    internal_static_inference_ModelTransactionPolicy_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_inference_ModelTransactionPolicy_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelTransactionPolicy_descriptor,
        new String[] { "Decoupled", });
    internal_static_inference_ModelConfig_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_inference_ModelConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelConfig_descriptor,
        new String[] { "Name", "Platform", "Backend", "VersionPolicy", "MaxBatchSize", "Input", "Output", "Optimization", "DynamicBatching", "SequenceBatching", "EnsembleScheduling", "InstanceGroup", "DefaultModelFilename", "CcModelFilenames", "MetricTags", "Parameters", "ModelWarmup", "ModelOperations", "ModelTransactionPolicy", "SchedulingChoice", });
    internal_static_inference_ModelConfig_CcModelFilenamesEntry_descriptor =
      internal_static_inference_ModelConfig_descriptor.getNestedTypes().get(0);
    internal_static_inference_ModelConfig_CcModelFilenamesEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelConfig_CcModelFilenamesEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelConfig_MetricTagsEntry_descriptor =
      internal_static_inference_ModelConfig_descriptor.getNestedTypes().get(1);
    internal_static_inference_ModelConfig_MetricTagsEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelConfig_MetricTagsEntry_descriptor,
        new String[] { "Key", "Value", });
    internal_static_inference_ModelConfig_ParametersEntry_descriptor =
      internal_static_inference_ModelConfig_descriptor.getNestedTypes().get(2);
    internal_static_inference_ModelConfig_ParametersEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_inference_ModelConfig_ParametersEntry_descriptor,
        new String[] { "Key", "Value", });
  }

  // @@protoc_insertion_point(outer_class_scope)
}
